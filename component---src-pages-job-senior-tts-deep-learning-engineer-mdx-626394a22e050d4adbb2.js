(window.webpackJsonp=window.webpackJsonp||[]).push([[30],{IcHn:function(e,t,a){"use strict";a.r(t),a.d(t,"pageQuery",(function(){return l})),a.d(t,"_frontmatter",(function(){return r})),a.d(t,"default",(function(){return b}));var n=a("zLVn"),i=(a("q1tI"),a("7ljp")),o=a("W/kl"),l="3484569904",r={},s={pageQuery:l,_frontmatter:r},c=o.a;function b(e){var t=e.components,a=Object(n.a)(e,["components"]);return Object(i.b)(c,Object.assign({},s,a,{components:t,mdxType:"MDXLayout"}),Object(i.b)("p",null,"The future is already here, it’s just not evenly distributed… join us and let’s change that. Let’s make\nVoice AI available to everyone and in every language!"),Object(i.b)("p",null,"At Coqui we’re looking to refine human-computer interaction through speech. This is only possible with computers\nthat speak naturally—in different languages, accents, and emotions—like humans do and with CoquiTTS we aim to\ncreate the best open-source, accessible text-to-speech engine to make that happen."),Object(i.b)("p",null,"If this sounds interesting to you, we are looking for a Deep Learning Engineer to join our TTS team, and we’re\nexcited to hear from you."),Object(i.b)("h3",{id:"at-coqui-you-will",style:{position:"relative"}},Object(i.b)("a",Object.assign({parentName:"h3"},{href:"#at-coqui-you-will","aria-label":"at coqui you will permalink",className:"anchor before"}),Object(i.b)("svg",Object.assign({parentName:"a"},{xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",focusable:"false",viewBox:"0 0 16 16"}),"\n  ",Object(i.b)("path",Object.assign({parentName:"svg"},{fill:"currentColor",d:"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"})))),"At Coqui you will:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Develop and maintain Coqui TTS and make it the best TTS solution"),Object(i.b)("li",{parentName:"ul"},"Build, train, optimize, and deploy deep learning models"),Object(i.b)("li",{parentName:"ul"},"Read/write papers, learn and implement the SOTA techniques that solve real-life problems"),Object(i.b)("li",{parentName:"ul"},"Write quality code and documentation"),Object(i.b)("li",{parentName:"ul"},"Work together with MLOps to integrate CoquiTTS into our ML pipeline"),Object(i.b)("li",{parentName:"ul"},"Learn new things and solve different problems everyday. (Start-up Life)"),Object(i.b)("li",{parentName:"ul"},"Listen to computers talking… Quite frequently!")),Object(i.b)("h3",{id:"your-professional-profile",style:{position:"relative"}},Object(i.b)("a",Object.assign({parentName:"h3"},{href:"#your-professional-profile","aria-label":"your professional profile permalink",className:"anchor before"}),Object(i.b)("svg",Object.assign({parentName:"a"},{xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",focusable:"false",viewBox:"0 0 16 16"}),"\n  ",Object(i.b)("path",Object.assign({parentName:"svg"},{fill:"currentColor",d:"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"})))),"Your professional profile:"),Object(i.b)("h4",{id:"requirements",style:{position:"relative"}},Object(i.b)("a",Object.assign({parentName:"h4"},{href:"#requirements","aria-label":"requirements permalink",className:"anchor before"}),Object(i.b)("svg",Object.assign({parentName:"a"},{xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",focusable:"false",viewBox:"0 0 16 16"}),"\n  ",Object(i.b)("path",Object.assign({parentName:"svg"},{fill:"currentColor",d:"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"})))),"Requirements"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Coqui TTS, PyTorch, TF, ONNX, TfLite, DeepSpeed, fair scale"),Object(i.b)("li",{parentName:"ul"},"Fast ML prototyping and productization"),Object(i.b)("li",{parentName:"ul"},"Text-to-speech and speech-to-text deep learning research, models, and libraries"),Object(i.b)("li",{parentName:"ul"},"Python, C and C++"),Object(i.b)("li",{parentName:"ul"},"Love and experience in open-source"),Object(i.b)("li",{parentName:"ul"},"Remote work-life across time zones with a distributed team"),Object(i.b)("li",{parentName:"ul"},"Agility to work at a start-up"),Object(i.b)("li",{parentName:"ul"},"Passion for speech tech")),Object(i.b)("h3",{id:"about-coqui",style:{position:"relative"}},Object(i.b)("a",Object.assign({parentName:"h3"},{href:"#about-coqui","aria-label":"about coqui permalink",className:"anchor before"}),Object(i.b)("svg",Object.assign({parentName:"a"},{xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",focusable:"false",viewBox:"0 0 16 16"}),"\n  ",Object(i.b)("path",Object.assign({parentName:"svg"},{fill:"currentColor",d:"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"})))),"About Coqui:"),Object(i.b)("p",null,"Coqui was founded by the creators of Mozilla’s text-to-speech and speech-to-text engines (over 500K downloads and\n22K GitHub stars), has the backing of fantastic investors from around the globe (London, San Francisco, and Berlin),\nhas a friendly & diverse developer community, and we’re just getting started."),Object(i.b)("p",null,"At Coqui we are redefining how humans interact with computers through that most natural of interfaces, speech."),Object(i.b)("p",null,"Also we believe that open and free is better than closed and controlled. So our core speech-to-text and text-to-speech\nengines are open to all, providing an evermore critical technology, speech, to the world. So when you join Coqui\nyou have the opportunity to make a dent in the universe, bringing voice to the world."),Object(i.b)("p",null,"Coqui is privately held, founded in 2021, and is headquartered in Berlin. We are a remote-friendly company with lots\nof experience working with distributed teams."),Object(i.b)("p",null,"We are an equal opportunity employer and value diversity. We do not discriminate on the basis of race, religion,\ncolor, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status."),Object(i.b)("h3",{id:"how-to-apply",style:{position:"relative"}},Object(i.b)("a",Object.assign({parentName:"h3"},{href:"#how-to-apply","aria-label":"how to apply permalink",className:"anchor before"}),Object(i.b)("svg",Object.assign({parentName:"a"},{xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",focusable:"false",viewBox:"0 0 16 16"}),"\n  ",Object(i.b)("path",Object.assign({parentName:"svg"},{fill:"currentColor",d:"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"})))),"How to Apply:"),Object(i.b)("p",null,"Send your CV in PDF format to ",Object(i.b)("a",Object.assign({parentName:"p"},{href:"mailto:jobs@coqui.ai"}),"jobs@coqui.ai")))}b.isMDXComponent=!0},"W/kl":function(e,t,a){"use strict";var n=a("q1tI"),i=a.n(n),o=a("O9mE"),l=a("v+Ly"),r=a("mrST"),s=a("1Yd/"),c=a("ozyN"),b=a("7cfw"),u=a("t4Fg");t.a=function(e){var t=e.children,a=e.data,p=e.pageContext,m=a.mdx;return Object(n.useEffect)((function(){Object(u.a)()})),i.a.createElement(o.a,null,i.a.createElement(s.a,{title:p.frontmatter.title+" / Open Position",description:p.frontmatter.description||m.excerpt}),i.a.createElement(l.a,null,i.a.createElement(r.a,{title:p.frontmatter.title,subtitle:p.frontmatter.description,name:p.frontmatter.name,picture:p.frontmatter.picture,date:p.frontmatter.date,toc:m.tableOfContents.items},i.a.createElement(c.a,null,t))),i.a.createElement(b.a,null))}}}]);
//# sourceMappingURL=component---src-pages-job-senior-tts-deep-learning-engineer-mdx-626394a22e050d4adbb2.js.map