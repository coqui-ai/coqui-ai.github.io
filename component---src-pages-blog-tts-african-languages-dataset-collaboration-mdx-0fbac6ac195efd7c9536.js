(window.webpackJsonp=window.webpackJsonp||[]).push([[24],{KLL9:function(e,a,t){"use strict";var n=t("q1tI"),l=t.n(n),r=t("O9mE"),o=t("v+Ly"),i=t("mrST"),s=t("1Yd/"),c=t("ozyN"),b=t("7cfw"),h=t("t4Fg");a.a=function(e){var a=e.children,t=e.data,u=e.pageContext,d=t.mdx;return Object(n.useEffect)((function(){Object(h.a)()})),l.a.createElement(r.a,null,l.a.createElement(s.a,{title:u.frontmatter.title+" / Blog",description:u.frontmatter.description||d.excerpt}),l.a.createElement(o.a,null,l.a.createElement(i.a,{title:u.frontmatter.title,subtitle:u.frontmatter.description,name:u.frontmatter.name,picture:u.frontmatter.picture,date:u.frontmatter.date,toc:d.tableOfContents.items},l.a.createElement(c.a,null,a))),l.a.createElement(b.a,null))}},w2nj:function(e,a,t){"use strict";t.r(a),t.d(a,"_frontmatter",(function(){return i})),t.d(a,"default",(function(){return b}));var n=t("zLVn"),l=(t("q1tI"),t("7ljp")),r=t("KLL9"),o=["components"],i={},s={pageQuery:"3484569904",_frontmatter:i},c=r.a;function b(e){var a=e.components,t=Object(n.a)(e,o);return Object(l.b)(c,Object.assign({},s,t,{components:a,mdxType:"MDXLayout"}),Object(l.b)("p",null,"üëâ ",Object(l.b)("a",{parentName:"p",href:"https://huggingface.co/spaces/coqui/CoquiTTS"},"Try out the new African TTS models!")),Object(l.b)("h3",{id:"introduction",style:{position:"relative"}},Object(l.b)("a",{parentName:"h3",href:"#introduction","aria-label":"introduction permalink",className:"anchor before"},Object(l.b)("svg",{parentName:"a",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",focusable:"false",viewBox:"0 0 16 16"},"\n  ",Object(l.b)("path",{parentName:"svg",fill:"currentColor",d:"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"}))),"Introduction"),Object(l.b)("p",null,"Over the course of several months, researchers from Coqui collaborated with a global team of academics, language\nactivists, and technologists in order to create high quality Text-to-Speech for six African languages. This blog post\ncovers who this excellent team was, what we did, and how you can use these new voices for yourself. All the synthetic\nvoices discussed here are available under a Creative Commons BY-SA 4.0 License ‚Äî a free, open, and commercial friendly\nlicense."),Object(l.b)("p",null,"There are literally thousands of languages spoken in Africa, and as such this current work is only the tip of the\niceberg. Nevertheless, we hope our work inspires others to create new open, synthetic voices for as many of Africa‚Äôs\nlanguages as possible. Coqui‚Äôs TTS can be fine-tuned to any new language, even with tiny amounts of data, regardless\nof the alphabet or grammar or linguistic attributes. The more data the better, as you will see (and hear) here. Data\nis almost always the bottleneck in deep learning, and in this blogpost we‚Äôll discuss how we found raw data that wasn‚Äôt\nready for TTS, and massaged it into a place where beautiful, high-fidelity synthetic voices could be built. Once the\ndata was ready, training the models was a piece of cake."),Object(l.b)("p",null,"This project wouldn‚Äôt have been possible without our collaborators. Specifically, the excellent Masakhane NLP community\nis what brought us all together in the first place. We eagerly look forward to more Coqui + Masakhane collaborations\nin the future! If you want to see the future of natural language technology (especially for African languages),\n",Object(l.b)("a",{parentName:"p",href:"https://www.masakhane.io/"},"Masakhane")," is the place to be."),Object(l.b)("h3",{id:"collaborators",style:{position:"relative"}},Object(l.b)("a",{parentName:"h3",href:"#collaborators","aria-label":"collaborators permalink",className:"anchor before"},Object(l.b)("svg",{parentName:"a",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",focusable:"false",viewBox:"0 0 16 16"},"\n  ",Object(l.b)("path",{parentName:"svg",fill:"currentColor",d:"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"}))),"Collaborators"),Object(l.b)("p",null,"Without further ado, here‚Äôs the team of individuals that brought these voices into reality (in alphabetical order):"),Object(l.b)("ul",null,Object(l.b)("li",{parentName:"ul"},"Alp √ñktem, Apelete Agbolo, Bernard Opoku, Chris Emezue, Colin Leong, Daniel Whitenack, David Ifeoluwa Adelani,\nEdresson Casanova, Elizabeth Salesky, Iroro Orife, Jesujoba Alabi, Jonathan Mukiibi, Josh Meyer, Julian Weber, Perez\nOgayo, Salomey Osei, Salomon Kabongo, Samuel Olanrewaju, Shamsuddeen Muhammad, Victor Akinode")),Object(l.b)("p",null,"Featuring activists and technologists from:"),Object(l.b)("ul",null,Object(l.b)("li",{parentName:"ul"},"CLEAR Global, Col¬∑lectivaT, Ewegbe Akademi, Masakhane, Niger-Volta LTI, SIL International")),Object(l.b)("p",null,"Featuring academic researchers from:"),Object(l.b)("ul",null,Object(l.b)("li",{parentName:"ul"},"Carnegie Mellon University, Johns Hopkins University, Kwame Nkrumah University of Science and Technology, Leibniz\nUniversit√§t, Makerere University, Saarland University, Technical University of Munich, University of S√£o Paulo")),Object(l.b)("h3",{id:"the-languages",style:{position:"relative"}},Object(l.b)("a",{parentName:"h3",href:"#the-languages","aria-label":"the languages permalink",className:"anchor before"},Object(l.b)("svg",{parentName:"a",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",focusable:"false",viewBox:"0 0 16 16"},"\n  ",Object(l.b)("path",{parentName:"svg",fill:"currentColor",d:"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"}))),"The Languages"),Object(l.b)("p",null,"The six new languages added to TTS are:"),Object(l.b)("table",null,Object(l.b)("thead",{parentName:"table"},Object(l.b)("tr",{parentName:"thead"},Object(l.b)("th",{parentName:"tr",align:null},"Language"),Object(l.b)("th",{parentName:"tr",align:null},"Classification"),Object(l.b)("th",{parentName:"tr",align:null},"African region"),Object(l.b)("th",{parentName:"tr",align:null},"Number of Speakers"),Object(l.b)("th",{parentName:"tr",align:null}))),Object(l.b)("tbody",{parentName:"table"},Object(l.b)("tr",{parentName:"tbody"},Object(l.b)("td",{parentName:"tr",align:null},"Ewe"),Object(l.b)("td",{parentName:"tr",align:null},"Niger-Congo / Kwa"),Object(l.b)("td",{parentName:"tr",align:null},"West"),Object(l.b)("td",{parentName:"tr",align:null},"5.5M"),Object(l.b)("td",{parentName:"tr",align:null})),Object(l.b)("tr",{parentName:"tbody"},Object(l.b)("td",{parentName:"tr",align:null},"Hausa"),Object(l.b)("td",{parentName:"tr",align:null},"Afro-Asiatic / Chadic"),Object(l.b)("td",{parentName:"tr",align:null},"West"),Object(l.b)("td",{parentName:"tr",align:null},"77M"),Object(l.b)("td",{parentName:"tr",align:null})),Object(l.b)("tr",{parentName:"tbody"},Object(l.b)("td",{parentName:"tr",align:null},"Lingala"),Object(l.b)("td",{parentName:"tr",align:null},"Niger-Congo / Bantu"),Object(l.b)("td",{parentName:"tr",align:null},"Central"),Object(l.b)("td",{parentName:"tr",align:null},"40M"),Object(l.b)("td",{parentName:"tr",align:null})),Object(l.b)("tr",{parentName:"tbody"},Object(l.b)("td",{parentName:"tr",align:null},"Akuapem Twi"),Object(l.b)("td",{parentName:"tr",align:null},"Niger-Congo / Akan"),Object(l.b)("td",{parentName:"tr",align:null},"West"),Object(l.b)("td",{parentName:"tr",align:null},"626k"),Object(l.b)("td",{parentName:"tr",align:null})),Object(l.b)("tr",{parentName:"tbody"},Object(l.b)("td",{parentName:"tr",align:null},"Asante Twi"),Object(l.b)("td",{parentName:"tr",align:null},"Niger-Congo / Akan"),Object(l.b)("td",{parentName:"tr",align:null},"West"),Object(l.b)("td",{parentName:"tr",align:null},"3.8M"),Object(l.b)("td",{parentName:"tr",align:null})),Object(l.b)("tr",{parentName:"tbody"},Object(l.b)("td",{parentName:"tr",align:null},"Yoruba"),Object(l.b)("td",{parentName:"tr",align:null},"Niger-Congo / Volta-Niger"),Object(l.b)("td",{parentName:"tr",align:null},"West"),Object(l.b)("td",{parentName:"tr",align:null},"46M"),Object(l.b)("td",{parentName:"tr",align:null})))),Object(l.b)("p",null,"Both the ‚ÄúNumber of Speakers‚Äù and ‚ÄúClassification‚Äù columns come from Ethnologue. These six languages are all\n",Object(l.b)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Tone_(linguistics)"},"tonal"),", come from two of the largest language families in Africa\n(Niger-Congo and Afro-Asiatic), and are spoken primarily in Central and West Africa. Needless to say, there are a lot\nof people speaking these languages in a huge geographic area. By releasing these models under an open Creative Commons\nlicense, we hope they will be immediately useful to speakers of these languages."),Object(l.b)("h3",{id:"the-collaboration-story",style:{position:"relative"}},Object(l.b)("a",{parentName:"h3",href:"#the-collaboration-story","aria-label":"the collaboration story permalink",className:"anchor before"},Object(l.b)("svg",{parentName:"a",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",focusable:"false",viewBox:"0 0 16 16"},"\n  ",Object(l.b)("path",{parentName:"svg",fill:"currentColor",d:"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"}))),"The Collaboration Story"),Object(l.b)("p",null,"As with all machine learning projects, data is the starting point. This entire collaboration spawned from a short URL\nposted into a chatroom: ",Object(l.b)("a",{parentName:"p",href:"https://open.bible"},"open.bible"),". A researcher from Coqui was hanging out with the folks from\nMasakhane in their slack group when someone posted the link saying something like ‚Äúlooks like some cool data!‚Äú. In no\ntime at all, a lively discussion ensued. The data was absolutely beautiful. All the data was explicitly licensed under\nCC-BY-SA, made of hours and hours of high-quality recordings from professional voice actors. This was without\nexaggeration the highest-quality voice data for speech synthesis Coqui had ever found in the open ‚Äî for any language."),Object(l.b)("p",null,"There was only one problem ‚Äî the original audio files are too long for training TTS models. The audio was saved as\nchapters (from the Bible), which were several minutes long each. It‚Äôs best to train synthetic voices with audio clips\nunder 30 seconds long, so we couldn‚Äôt use the data out of the box. The intuitively simple task of breaking chapters\ninto verses is not so simple in practice, and it requires significant compute power. Nevertheless, over a couple months\nand more than a couple cups of coffee, we aligned the recordings to the verse-level, and then we extracted only the\nbest data. The resulting datasets will be released under the same CC-BY-SA 4.0 license, as well as our research paper\ndetailing how we made it possible. Both the dataset release and publication of our methods are slated for INTERSPEECH 2022."),Object(l.b)("h3",{id:"use-the-models",style:{position:"relative"}},Object(l.b)("a",{parentName:"h3",href:"#use-the-models","aria-label":"use the models permalink",className:"anchor before"},Object(l.b)("svg",{parentName:"a",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",focusable:"false",viewBox:"0 0 16 16"},"\n  ",Object(l.b)("path",{parentName:"svg",fill:"currentColor",d:"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"}))),"Use the Models"),Object(l.b)("p",null,"All models discussed here can be used from:"),Object(l.b)("ol",null,Object(l.b)("li",{parentName:"ol"},"Our official ",Object(l.b)("a",{parentName:"li",href:"https://huggingface.co/spaces/coqui/CoquiTTS"},"Coqui Huggingface space")),Object(l.b)("li",{parentName:"ol"},"Your browser with ",Object(l.b)("a",{parentName:"li",href:"https://tts.readthedocs.io/en/latest/inference.html#on-the-demo-server-tts-server"},Object(l.b)("inlineCode",{parentName:"a"},"tts-server"))),Object(l.b)("li",{parentName:"ol"},"Your command line with ",Object(l.b)("a",{parentName:"li",href:"https://tts.readthedocs.io/en/latest/inference.html#on-the-commandline-tts"},Object(l.b)("inlineCode",{parentName:"a"},"tts")))),Object(l.b)("h3",{id:"conclusion",style:{position:"relative"}},Object(l.b)("a",{parentName:"h3",href:"#conclusion","aria-label":"conclusion permalink",className:"anchor before"},Object(l.b)("svg",{parentName:"a",xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",focusable:"false",viewBox:"0 0 16 16"},"\n  ",Object(l.b)("path",{parentName:"svg",fill:"currentColor",d:"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"}))),"Conclusion"),Object(l.b)("p",null,"Keep an eye our for our INTERSPEECH paper for all the technical details on how we created the datasets and trained the\nmodels. Until then, take the models and do something great! We want to thank again all the folks who helped make this\npossible, especially the Masakhane community for bringing us all together. We want to also acknowledge the individuals\nwho spent hours and hours narrarating the Bible in these languages for the Open.Bible project, and for releasing the\nrecordings under a Creative Commons license in the first place. We also want to thank the team of folks at Biblica for\ntaking such care to record, organize, and release the raw data. They did not participate in this research, but it would\nnot have been possible without them. On a last, but important note, anyone using these synthetic voices should be using\nthem to create more good in the world, and no more harm. Out of respect to the original voice actors and the nature of\nthe original recordings, we want the voices to be used to help people, and we‚Äôre sure they can find great use in places\nlike education and accessibility. For example, these voices can easily be used to create audiobooks for people who can‚Äôt\nsee or read well, and make reading more fun for students. If you use these models, let us know what great things you‚Äôre\ncreating in the world!"))}b.isMDXComponent=!0}}]);
//# sourceMappingURL=component---src-pages-blog-tts-african-languages-dataset-collaboration-mdx-0fbac6ac195efd7c9536.js.map