<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.30e990850292b7da350c.css" id="gatsby-global-css">/*!
 * Copyright Zendesk, Inc.
 *
 * Use of this source code is governed under the Apache License, Version 2.0
 * found at http://www.apache.org/licenses/LICENSE-2.0.
 */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden],template{display:none}html{background-color:#fff;min-height:100%;box-sizing:border-box;overflow-y:scroll;line-height:20px;color:#2f3941;-webkit-font-feature-settings:"kern","kern";font-feature-settings:"kern","kern";font-kerning:normal;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,Arial,sans-serif;font-size:14px}*{font-weight:inherit}*,:after,:before{box-sizing:inherit}a{color:#1f73b7}a,ins,u{text-decoration:none}a:focus,a:hover{text-decoration:underline;color:#1f73b7}a:focus{outline:none}b{font-weight:600}button{cursor:pointer;padding:0}button,input,optgroup,select,textarea{line-height:inherit;font-family:inherit}code{font-size:.95em}code,kbd,pre,samp{font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace}em{font-style:inherit}fieldset,iframe{border:0}h1,h2,h3,h4,h5,h6{font-size:inherit}blockquote,dd,dl,fieldset,figure,h1,h2,h3,h4,h5,h6,hr,ol,p,pre,ul{margin:0;padding:0}hr{border:none;border-top:1px solid}ol,ul{list-style:none}img{max-width:100%}strong{font-weight:inherit}svg{max-height:100%}[tabindex="-1"]:focus{outline:none!important}</style><meta name="generator" content="Gatsby 2.27.5"/><title data-react-helmet="true">Double Decoder Consistency / Blog / Coqui</title><link data-react-helmet="true" rel="mask-icon" href="/mask-icon.svg" color="#03363d"/><link data-react-helmet="true" rel="apple-touch-icon" href="/apple-touch-icon.png"/><link data-react-helmet="true" rel="shortcut icon" href="/favicon.ico"/><meta data-react-helmet="true" name="application-name" content="Coqui"/><meta data-react-helmet="true" name="description" content="Despite the success of the latest attention based end2end text2speech (TTS)
models, they suffer from attention alignment problems at…"/><meta data-react-helmet="true" name="msapplication-config" content="/browserconfig.xml"/><meta data-react-helmet="true" property="og:title" content="Coqui"/><meta data-react-helmet="true" property="og:description" content="Coqui, Freeing Speech."/><meta data-react-helmet="true" property="og:image" content="https://coqui.ai/og-image.png"/><meta data-react-helmet="true" property="og:image:alt" content="Coqui"/><meta data-react-helmet="true" property="og:image:width" content="1280"/><meta data-react-helmet="true" property="og:image:height" content="640"/><meta data-react-helmet="true" property="twitter:card" content="summary_large_image"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css"/><link rel="sitemap" type="application/xml" href="/sitemap.xml"/><style data-styled="boRYJl frPItv  hJGfqI gbWTPN esrYoz iTpVGQ iqDliS Fwlym eGBoZs kpuXOb ifalUs jIHHbm ZurFO dmeNDE dEzVDV fqXuiB hJmzvI bJsLke tqxgC gKyVMe fOLerP cEEVdI jJwXiO iARHbT cxJGyA hKRDwX jnzUYZ hUigtZ cdcKhH bSMrqM cgPVmz gBLfIq dYOvul aYPWv jDwDPA ZLMZX fWmrzw EQyIi jeeFUs bINUcJ gGFgqj fbGZzl hmdGyC gjZoLh kKEUTC lmFVlv gHyCyg jLOitN bPqEGj ceqIaD kbQOIb jCZXmA hCsyko dcLymE kdJXOp dIPvJZ jOzwVI dSuWUw kPitly bRvpwy kNCRIy iRhBUd cyVuQe dAyBhk jUlaGX jJClhf gXlMSe mZaVr gnMBjg iBbHyF dJVuoI cVciVx dJejfB" data-styled-version="4.4.1">
/* sc-component-id: gatsby-theme___StyledDiv-x2kfdx-0 */
.boRYJl{width:100%;height:100%;}
/* sc-component-id: sc-htoDjs */
.gbWTPN{-webkit-transition:opacity 0.2s ease-out,clip 0s linear 0.2s;transition:opacity 0.2s ease-out,clip 0s linear 0.2s;opacity:0;-webkit-clip:rect(0,0,0,0);clip:rect(0,0,0,0);display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;position:absolute;left:50%;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-transform:translateX(-50%);-ms-transform:translateX(-50%);transform:translateX(-50%);z-index:2;border:1px solid;border-radius:4px;-webkit-text-decoration:underline;text-decoration:underline;white-space:nowrap;top:26px;padding:20px;padding-left:16px;line-height:1.4285714285714286;font-size:14px;border-color:#d8dcde;box-shadow:0 20px 28px 0 rgba(23,73,77,0.15);background-color:#fff;color:#1f73b7;} .gbWTPN:focus{-webkit-transition:opacity 0.2s ease-in-out;transition:opacity 0.2s ease-in-out;-webkit-animation:0.2s cubic-bezier(0.15,0.85,0.35,1.2) jtXLs;animation:0.2s cubic-bezier(0.15,0.85,0.35,1.2) jtXLs;opacity:1;-webkit-clip:auto;clip:auto;} .gbWTPN:focus{outline:none;} .gbWTPN:hover,.gbWTPN:focus{color:#1f73b7;}
/* sc-component-id: sc-dnqmqq */
.esrYoz{color:#68737d;margin-right:8px;width:16px;height:16px;}
/* sc-component-id: sc-hSdWYo */
.ZurFO{-webkit-transition:-webkit-transform 0.25s ease-in-out;-webkit-transition:transform 0.25s ease-in-out;transition:transform 0.25s ease-in-out;}
/* sc-component-id: sc-cvbbAY */
.bINUcJ{display:inline;-webkit-transition: border-color 0.25s ease-in-out, box-shadow 0.1s ease-in-out, background-color 0.25s ease-in-out, color 0.25s ease-in-out;transition: border-color 0.25s ease-in-out, box-shadow 0.1s ease-in-out, background-color 0.25s ease-in-out, color 0.25s ease-in-out;margin:0;border:none;border-radius:0;cursor:pointer;overflow:hidden;-webkit-text-decoration:none;text-decoration:none;text-overflow:ellipsis;font-family:inherit;font-weight:inherit;-webkit-font-smoothing:subpixel-antialiased;box-sizing:border-box;-webkit-touch-callout:none;padding:0;font-size:inherit;background-color:transparent;color:#1f73b7;} .bINUcJ::-moz-focus-inner{border:0;padding:0;} .bINUcJ:focus{outline:none;-webkit-text-decoration:none;text-decoration:none;} .bINUcJ:hover{-webkit-text-decoration:underline;text-decoration:underline;} .bINUcJ[data-garden-focus-visible]{-webkit-text-decoration:underline;text-decoration:underline;} .bINUcJ:active,.bINUcJ[aria-pressed='true'],.bINUcJ[aria-pressed='mixed']{-webkit-transition: border-color 0.1s ease-in-out, background-color 0.1s ease-in-out, color 0.1s ease-in-out;transition: border-color 0.1s ease-in-out, background-color 0.1s ease-in-out, color 0.1s ease-in-out;-webkit-text-decoration:underline;text-decoration:underline;} .bINUcJ:hover,.bINUcJ:focus,.bINUcJ[data-garden-focus-visible]{color:#144a75;} .bINUcJ:active,.bINUcJ[aria-pressed='true'],.bINUcJ[aria-pressed='mixed']{color:#0f3554;} .bINUcJ:disabled{color:#5293c7;} .bINUcJ:disabled{cursor:default;-webkit-text-decoration:none;text-decoration:none;} .bINUcJ .sc-hSdWYo{width:16px;min-width:16px;height:16px;vertical-align:middle;} .sc-iAyFgw .bINUcJ{position:relative;margin-left:-1px;} .sc-iAyFgw .bINUcJ:hover,.sc-iAyFgw .bINUcJ:active{z-index:1;} .sc-iAyFgw .bINUcJ:disabled{z-index:-1;border-top-width:0;border-bottom-width:0;border-right-color:#fff;border-left-color:#fff;} .sc-iAyFgw .bINUcJ:first-of-type:not(:last-of-type){margin-left:0;border-top-right-radius:0;border-bottom-right-radius:0;} .sc-iAyFgw .bINUcJ:last-of-type:not(:first-of-type){border-top-left-radius:0;border-bottom-left-radius:0;} .sc-iAyFgw .bINUcJ:not(:first-of-type):not(:last-of-type){border-radius:0;}
/* sc-component-id: sc-jWBwVP */
.kKEUTC{margin-bottom:-0.085em;padding-left:0.25em;box-sizing:content-box;width:0.85em;height:0.85em;}
/* sc-component-id: sc-brqgnP */
.jIHHbm{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-transition: border-color 0.25s ease-in-out, box-shadow 0.1s ease-in-out, background-color 0.25s ease-in-out, color 0.25s ease-in-out;transition: border-color 0.25s ease-in-out, box-shadow 0.1s ease-in-out, background-color 0.25s ease-in-out, color 0.25s ease-in-out;margin:0;border:1px solid transparent;border-radius:4px;cursor:pointer;overflow:hidden;-webkit-text-decoration:none;text-decoration:none;text-overflow:ellipsis;white-space:nowrap;font-family:inherit;font-weight:400;-webkit-font-smoothing:subpixel-antialiased;box-sizing:border-box;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-touch-callout:none;padding:0 1.3571428571428572em;height:48px;line-height:46px;font-size:14px;background-color:transparent;color:#1f73b7;border:none;padding:0;width:48px;min-width:48px;color:#68737d;} .jIHHbm::-moz-focus-inner{border:0;padding:0;} .jIHHbm:focus{outline:none;} .jIHHbm:hover{-webkit-text-decoration:none;text-decoration:none;} .jIHHbm[data-garden-focus-visible]{-webkit-text-decoration:none;text-decoration:none;} .jIHHbm:active,.jIHHbm[aria-pressed='true'],.jIHHbm[aria-pressed='mixed']{-webkit-transition: border-color 0.1s ease-in-out, background-color 0.1s ease-in-out, color 0.1s ease-in-out;transition: border-color 0.1s ease-in-out, background-color 0.1s ease-in-out, color 0.1s ease-in-out;-webkit-text-decoration:none;text-decoration:none;} .jIHHbm:hover{background-color:rgba(31,115,183,0.08);color:#144a75;} .jIHHbm[data-garden-focus-visible]{box-shadow:  0 0 0 3px rgba(31,115,183,0.35);} .jIHHbm:active,.jIHHbm[aria-pressed='true'],.jIHHbm[aria-pressed='mixed']{background-color:rgba(31,115,183,0.2);color:#0f3554;} .jIHHbm:disabled{border-color:transparent;background-color:#cee2f2;color:#5293c7;} .jIHHbm:disabled{cursor:default;} .jIHHbm .sc-hSdWYo{width:16px;min-width:16px;height:16px;} .sc-iAyFgw .jIHHbm{position:relative;margin-left:-1px;} .sc-iAyFgw .jIHHbm:hover,.sc-iAyFgw .jIHHbm:active{z-index:1;} .sc-iAyFgw .jIHHbm:disabled{z-index:-1;border-top-width:0;border-bottom-width:0;border-right-color:#fff;border-left-color:#fff;} .sc-iAyFgw .jIHHbm:first-of-type:not(:last-of-type){margin-left:0;border-top-right-radius:0;border-bottom-right-radius:0;} .sc-iAyFgw .jIHHbm:last-of-type:not(:first-of-type){border-top-left-radius:0;border-bottom-left-radius:0;} .sc-iAyFgw .jIHHbm:not(:first-of-type):not(:last-of-type){border-radius:0;} .jIHHbm:hover{color:#49545c;} .jIHHbm:active,.jIHHbm[aria-pressed='true'],.jIHHbm[aria-pressed='mixed']{color:#2f3941;} .jIHHbm .sc-hSdWYo{width:16px;height:16px;} .jIHHbm .sc-hSdWYo > svg{-webkit-transition:opacity 0.15s ease-in-out;transition:opacity 0.15s ease-in-out;}
/* sc-component-id: MaxWidth__MaxWidthLayout-sc-1rbvyso-0 */
.tqxgC{margin-right:auto;margin-left:auto;max-width:2880px;}
/* sc-component-id: Footer__StyledFooterItem-owx86q-0 */
.dJVuoI{margin-right:20px;color:#fff;} @media (max-width:767.98px){.dJVuoI{margin-left:20px;}} .dJVuoI:hover,.dJVuoI:focus{color:inherit;}
/* sc-component-id: Footer___StyledFooter-owx86q-1 */
.jOzwVI{background-color:#03363d;padding:20px;line-height:20px;color:#fff;font-size:14px;}
/* sc-component-id: Footer___StyledDiv-owx86q-2 */
.dSuWUw{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding-bottom:20px;} @media (max-width:767.98px){.dSuWUw{-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding-right:36px;padding-left:36px;text-align:center;}}
/* sc-component-id: Footer___StyledDiv2-owx86q-3 */
.kPitly{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
/* sc-component-id: Footer___StyledGitHubIcon-owx86q-4 */
.bRvpwy{margin-right:32px;width:26px;height:26px;color:#fff;}
/* sc-component-id: Footer___StyledDiv3-owx86q-5 */
.kNCRIy{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
/* sc-component-id: Footer___StyledTwitterIcon-owx86q-6 */
.iRhBUd{margin-right:32px;width:26px;height:26px;color:#fff;}
/* sc-component-id: Footer___StyledDiv4-owx86q-7 */
.cyVuQe{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
/* sc-component-id: Footer___StyledFacebookIcon-owx86q-8 */
.dAyBhk{margin-right:32px;width:26px;height:26px;color:#fff;}
/* sc-component-id: Footer___StyledDiv5-owx86q-9 */
.jUlaGX{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
/* sc-component-id: Footer___StyledLinkedInIcon-owx86q-10 */
.jJClhf{margin-right:32px;width:26px;height:26px;color:#fff;}
/* sc-component-id: Footer___StyledDiv6-owx86q-11 */
.gXlMSe{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
/* sc-component-id: Footer___StyledGitterIcon-owx86q-12 */
.mZaVr{width:26px;height:26px;color:#fff;}
/* sc-component-id: Footer___StyledDiv7-owx86q-13 */
.gnMBjg{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-top:1px solid #467b7c;padding-top:12px;} @media (max-width:767.98px){.gnMBjg{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;text-align:center;}}
/* sc-component-id: Footer___StyledDiv8-owx86q-14 */
.iBbHyF{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-basis:36px;-ms-flex-preferred-size:36px;flex-basis:36px;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
/* sc-component-id: Footer___StyledDiv9-owx86q-15 */
.cVciVx{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-basis:36px;-ms-flex-preferred-size:36px;flex-basis:36px;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
/* sc-component-id: Footer___StyledDiv10-owx86q-16 */
@media (max-width:767.98px){.dJejfB{margin-top:12px;width:100%;text-align:center;}}
/* sc-component-id: Header__StyledDesktopNavItem-sc-1bc1xqp-0 */
.dEzVDV{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-left:12px;}
/* sc-component-id: Header__StyledDesktopNavLink-sc-1bc1xqp-1 */
.fqXuiB{border-radius:4px;padding:6px 8px;color:#2f3941;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;} .fqXuiB:focus,.fqXuiB:hover,.fqXuiB:active{-webkit-text-decoration:none;text-decoration:none;color:inherit;} .fqXuiB.is-current{background-color:rgba(47,57,65,0.1);} .fqXuiB[data-garden-focus-visible]{box-shadow:0 0 0 3px rgba(82,147,199,0.35);} .fqXuiB:hover{background-color:rgba(47,57,65,0.05);} .fqXuiB:active{background-color:rgba(47,57,65,0.2);}
/* sc-component-id: Header__StyledHeader-sc-1bc1xqp-2 */
.iTpVGQ{z-index:1;box-shadow:0 16px 24px 0 rgba(47,57,65,0.05);padding:0 16px;height:80px;} .iTpVGQ[data-show-navigation='true']{border-bottom-color:#fff;} @media (max-width:767.98px){.iTpVGQ{padding:0;height:60px;}}
/* sc-component-id: Header___StyledDiv-sc-1bc1xqp-3 */
.Fwlym{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:left;-webkit-justify-content:left;-ms-flex-pack:left;justify-content:left;} @media (max-width:767.98px){.Fwlym{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;padding-left:20px;}}
/* sc-component-id: Header___StyledDiv2-sc-1bc1xqp-4 */
.eGBoZs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
/* sc-component-id: Header___StyledImg-sc-1bc1xqp-5 */
@media (max-width:575.98px){.kpuXOb{height:26pxpx;}}
/* sc-component-id: Header___StyledDiv3-sc-1bc1xqp-6 */
.ifalUs{padding:6px;} @media (min-width:768px){.ifalUs{display:none;}}
/* sc-component-id: Header___StyledNav-sc-1bc1xqp-9 */
.dmeNDE{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;} @media (max-width:767.98px){.dmeNDE{display:none;}}
/* sc-component-id: Header___StyledMaxWidthLayout-sc-1bc1xqp-10 */
.iqDliS{margin-right:auto;margin-left:auto;max-width:2880px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:100%;min-height:100%;}
/* sc-component-id: sc-global-2373854496 */
*{-ms-overflow-style:-ms-autohiding-scrollbar;}
/* sc-component-id: Root___StyledDiv-k2xmz5-0 */
.frPItv{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;min-height:100vh;}
/* sc-component-id: Root___StyledSkipNav-k2xmz5-1 */
.hJGfqI{top:40px;box-shadow:0 16px 24px 0 rgba(47,57,65,0.05);}
/* sc-component-id: Root___StyledMain-k2xmz5-2 */
.hJmzvI{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-flex-shrink:1;-ms-flex-negative:1;flex-shrink:1;}
/* sc-component-id: sc-cMljjf */
.jnzUYZ{box-sizing:border-box;width:100%;padding-right:10px;padding-left:10px;} @media (min-width:0px){} @media (min-width:576px){} @media (min-width:768px){} @media (min-width:992px){.jnzUYZ{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;max-width:100%;}} @media (min-width:1200px){.jnzUYZ{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;max-width:75%;}}.hUigtZ{box-sizing:border-box;width:100%;padding-right:10px;padding-left:10px;} @media (min-width:0px){} @media (min-width:576px){} @media (min-width:768px){} @media (min-width:992px){.hUigtZ{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;max-width:100%;}} @media (min-width:1200px){.hUigtZ{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;max-width:25%;}}
/* sc-component-id: sc-jAaTju */
.cxJGyA{margin-right:auto;margin-left:auto;width:100%;box-sizing:border-box;padding-right:10px;padding-left:10px;}
/* sc-component-id: sc-jDwBTQ */
.hKRDwX{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-10px;margin-left:-10px;} @media (min-width:0px){} @media (min-width:576px){} @media (min-width:768px){} @media (min-width:992px){} @media (min-width:1200px){}
/* sc-component-id: sc-iRbamj */
.bSMrqM{line-height:44px;font-size:36px;font-weight:400;direction:ltr;}.cgPVmz{line-height:24px;font-size:18px;font-weight:400;direction:ltr;}.gBLfIq{line-height:20px;font-size:14px;font-weight:400;direction:ltr;}.dYOvul{line-height:32px;font-size:26px;font-weight:400;direction:ltr;}.aYPWv{line-height:28px;font-size:22px;font-weight:400;direction:ltr;}.jDwDPA{direction:ltr;}
/* sc-component-id: sc-gipzik */
.jLOitN{margin:0;padding:12px;overflow:auto;direction:ltr;white-space:pre;counter-reset:linenumber;background-color:#1a1f23;color:#d8dcde;}
/* sc-component-id: sc-csuQGl */
.bPqEGj{line-height:20px;font-family:SFMono-Regular,Consolas,"Liberation Mono",Menlo,Courier,monospace;font-size:13px;font-weight:400;direction:ltr;display:table-row;height:20px;direction:ltr;} .bPqEGj::after{display:inline-block;width:12px;content:'';}
/* sc-component-id: sc-Rmtcm */
.ceqIaD{display:inline-block;} .ceqIaD.bold{font-weight:600;} .ceqIaD.italic{font-style:italic;} .ceqIaD.builtin,.ceqIaD.class-name,.ceqIaD.tag:not(.punctuation):not(.attr-name):not(.attr-value):not(.script){color:#02a191;} .ceqIaD.doctype,.ceqIaD.prolog,.ceqIaD.tag.punctuation:not(.attr-value):not(.script):not(.spread){color:#68737d;} .ceqIaD.attribute.value,.ceqIaD.attr-value,.ceqIaD.atrule,.ceqIaD.cdata,.ceqIaD.string,.ceqIaD.url.content{color:#cc6c5b;} .ceqIaD.constant,.ceqIaD.interpolation-punctuation{color:#337fbd;} .ceqIaD.attr-name,.ceqIaD.attr-value.spread,.ceqIaD.environment,.ceqIaD.interpolation,.ceqIaD.parameter,.ceqIaD.property,.ceqIaD.property-access,.ceqIaD.variable{color:#adcce4;} .ceqIaD.parameter.punctuation,.ceqIaD.attr-name + .attr-value.punctuation{color:inherit;} .ceqIaD.regex{color:#e35b66;} .ceqIaD.boolean,.ceqIaD.bold,.ceqIaD.entity,.ceqIaD.important,.ceqIaD.tag:not(.punctuation):not(.attr-name):not(.attr-value):not(.script):not(.class-name){color:#3091ec;} .ceqIaD.number,.ceqIaD.unit{color:#aecfc2;} .ceqIaD.assign-left,.ceqIaD.function,.ceqIaD.selector:not(.attribute){color:#fed6a8;} .ceqIaD.atrule.rule,.ceqIaD.keyword{color:#cf62a8;} .ceqIaD.blockquote,.ceqIaD.comment,.ceqIaD.shebang{color:#00a656;} .sc-gipzik.language-css .ceqIaD.plain{color:#cc6c5b;}
/* sc-component-id: sc-caSCKo */
.fbGZzl{margin:0;padding:0;direction:ltr;} blockquote + .fbGZzl,.fbGZzl + .fbGZzl{margin-top:20px;}
/* sc-component-id: Anchor__StyledAnchor-sc-1q3ov98-0 */
.gjZoLh.anchor.before{position:relative;margin-left:-32px;border-radius:4px;padding:0 16px;color:transparent;} @media (max-width:991.98px){.gjZoLh.anchor.before{margin-left:-24px;padding:0 12px;}} .gjZoLh.anchor.before[data-garden-focus-visible]{box-shadow:inset 0 0 0 2px rgba(31,115,183,0.35);color:inherit;} .gjZoLh.anchor.before > svg{position:absolute;top:50%;-webkit-transform:translate(-50%,-50%);-ms-transform:translate(-50%,-50%);transform:translate(-50%,-50%);}
/* sc-component-id: Typography__StyledH2-xo896r-1 */
.cdcKhH{margin-bottom:12px;color:#03363d;font-weight:600;margin-top:20px;margin-bottom:20px;} .cdcKhH:hover .Anchor__StyledAnchor-sc-1q3ov98-0{color:inherit;}
/* sc-component-id: Typography__StyledH3-xo896r-2 */
.hmdGyC{margin-bottom:12px;color:#03363d;font-weight:600;} .hmdGyC:hover .Anchor__StyledAnchor-sc-1q3ov98-0{color:inherit;}
/* sc-component-id: Typography__StyledH4-xo896r-3 */
.lmFVlv{margin-bottom:12px;color:#03363d;font-weight:600;} .lmFVlv:hover .Anchor__StyledAnchor-sc-1q3ov98-0{color:inherit;}
/* sc-component-id: Typography__StyledHr-xo896r-7 */
.fWmrzw{margin:20px 0;border-top:1px solid #e9ebed;}
/* sc-component-id: Typography__StyledParagraph-xo896r-8 */
.gGFgqj{margin-bottom:20px;}
/* sc-component-id: Typography__StyledEmphasis-xo896r-10 */
.kbQOIb{font-style:italic;}
/* sc-component-id: DesktopSidebar___StyledNav-sc-1ezn4du-0 */
.fOLerP{background-color:#fff;padding:32px 20px 32px 0;min-width:220px;} @media (max-width:1440px){.fOLerP{padding:32px 20px;}} @media (max-width:1199.98px){.fOLerP{display:none;}}
/* sc-component-id: DesktopSidebar___StyledDiv-sc-1ezn4du-1 */
.cEEVdI{position:absolute;top:0;right:50%;bottom:0;left:0;z-index:-1;background-color:#fff;} @media (max-width:1199.98px){.cEEVdI{display:none;}}
/* sc-component-id: Sidebar___StyledDiv-q5rdfu-1 */
.bJsLke{position:relative;}
/* sc-component-id: Sidebar___StyledDiv2-q5rdfu-2 */
.gKyVMe{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:calc(100vh - 204px);}
/* sc-component-id: Sidebar___StyledDiv3-q5rdfu-3 */
.jJwXiO{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;background-color:#fff;padding:32px 20px;max-width:100vw;} @media (max-width:991.98px){.jJwXiO{padding:32px 12px;}}
/* sc-component-id: Sidebar___StyledDiv4-q5rdfu-4 */
.iARHbT{margin-right:auto;margin-left:auto;max-width:992px;}
/* sc-component-id: sc-kjoXOD */
.ZLMZX{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;position:relative;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-transition:box-shadow 0.25s ease-in-out,color 0.1s ease-in-out;transition:box-shadow 0.25s ease-in-out,color 0.1s ease-in-out;margin:0;vertical-align:middle;box-sizing:border-box;border-radius:50%;width:40px !important;height:40px !important;box-shadow:0 0 0 2px transparent;background-color:transparent;color:transparent;} .ZLMZX::before{box-shadow:inset 0 0 0 2px;} .ZLMZX > svg{font-size:16px;} .ZLMZX .sc-gisBJw{line-height:40px;font-size:18px;} .ZLMZX > svg,.ZLMZX .sc-gisBJw{color:#fff;} .ZLMZX::after{background-color:transparent;-webkit-text-fill-color:#fff;} .ZLMZX _:-ms-input-placeholder,.ZLMZX::after{color:#fff;} .ZLMZX::before{position:absolute;top:0;left:0;-webkit-transition:box-shadow 0.25s ease-in-out;transition:box-shadow 0.25s ease-in-out;content:'';} .ZLMZX::before,.ZLMZX.ZLMZX > img{border-radius:inherit;width:100%;height:100%;} .ZLMZX.ZLMZX > img{box-sizing:inherit;vertical-align:bottom;object-fit:cover;} .ZLMZX.ZLMZX > svg{width:1em;height:1em;} .ZLMZX::after{display:inline-block;position:absolute;right:2px;bottom:2px;-webkit-transition:all 0.25s ease-in-out,color 0s;transition:all 0.25s ease-in-out,color 0s;opacity:0;border:2px solid;border-radius:100px;padding:0 0;min-width:0;max-width:2em;height:0;box-sizing:content-box !important;overflow:hidden;text-align:center;text-overflow:ellipsis;line-height:1px;white-space:nowrap;font-size:0;font-weight:600;content:'';}
/* sc-component-id: SectionCallout__StyledSectionHeader-sc-6sz3ai-0 */
.jeeFUs{text-transform:uppercase;line-height:16px;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;color:#68737d;font-size:10px;font-weight:600;}
/* sc-component-id: TOC___StyledStyledAnchor-sc-1hj7fxm-3 */
.dIPvJZ{display:block;margin:4px 0;text-align:left;padding-left:20px;}
/* sc-component-id: TOC___StyledDiv-sc-1hj7fxm-4 */
.hCsyko{position:-webkit-sticky;position:sticky;top:32px;margin-left:60px;padding-right:12px;max-height:calc(100vh - 64px);overflow-y:auto;}
/* sc-component-id: TOC___StyledStyledSectionHeader-sc-1hj7fxm-5 */
.dcLymE{text-transform:uppercase;line-height:16px;-webkit-letter-spacing:0.5px;-moz-letter-spacing:0.5px;-ms-letter-spacing:0.5px;letter-spacing:0.5px;color:#68737d;font-size:10px;font-weight:600;margin-bottom:8px;margin-left:20px;}
/* sc-component-id: TOC___StyledUl2-sc-1hj7fxm-6 */
.kdJXOp{border-left:1px solid #e9ebed;}
/* sc-component-id: Titled___StyledTOCBlock-sc-16c5y7v-0 */
@media (min-width:1200px){.EQyIi{display:none;}}
/* sc-component-id: Titled___StyledCol-sc-16c5y7v-1 */
@media (max-width:1199.98px){.jCZXmA{display:none;}}
/* sc-component-id: CodeBlock__StyledCodeBlock-sc-1er5mkx-0 */
.gHyCyg{margin:20px 0;border-radius:4px;}</style><style data-styled="jtXLs" data-styled-version="4.4.1">
/* sc-component-id: sc-keyframes-jtXLs */
@-webkit-keyframes jtXLs{0%{-webkit-transform:translate(-50%,-50%);-ms-transform:translate(-50%,-50%);transform:translate(-50%,-50%);}} @keyframes jtXLs{0%{-webkit-transform:translate(-50%,-50%);-ms-transform:translate(-50%,-50%);transform:translate(-50%,-50%);}}</style><link as="script" rel="preload" href="/webpack-runtime-0d6cdee3981973b7f840.js"/><link as="script" rel="preload" href="/framework-25679e2f2e739b4a55ca.js"/><link as="script" rel="preload" href="/app-ba1c07c82d50bc77ba8a.js"/><link as="script" rel="preload" href="/styles-e9d24b1846c7d6eb9685.js"/><link as="script" rel="preload" href="/commons-3846d04eddd05b3df926.js"/><link as="script" rel="preload" href="/3ffa677eea931b87951924687953dbca4dfdb241-e88e164e0a1f11a752e3.js"/><link as="script" rel="preload" href="/1728d3ef4ec5b8879051de3c149660cde7777519-adb06edc144b2e1c7b86.js"/><link as="script" rel="preload" href="/336ed6c8c131f2234f4a1a401bee3ac110638f3f-6c814d1dd0a279113390.js"/><link as="script" rel="preload" href="/3eec2993ab5d4a15f72d1d355f43d49bb49a1278-d2a992b53c28489b22a9.js"/><link as="script" rel="preload" href="/8e8edb548d22e34764571af9805b81c99598043e-936f40607f5ec89ed29e.js"/><link as="script" rel="preload" href="/4826355d3ca8414095694303dcbe670927871743-7332373f0fb285e5a783.js"/><link as="script" rel="preload" href="/component---src-pages-blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-mdx-68164f4687844e2e87b7.js"/><link as="fetch" rel="preload" href="/page-data/blog/tts/solving-attention-problems-of-tts-models-with-double-decoder-consistency/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/1942088059.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3709355695.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div><div class="gatsby-theme___StyledDiv-x2kfdx-0 boRYJl"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="Root___StyledDiv-k2xmz5-0 frPItv"><a href="#main-content" class="sc-htoDjs gbWTPN Root___StyledSkipNav-k2xmz5-1 hJGfqI" data-garden-id="chrome.skipnav" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" focusable="false" role="presentation" theme="[object Object]" data-garden-id="chrome.skipnav_icon" data-garden-version="8.31.0" class="sc-dnqmqq esrYoz"><path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg>Skip to main content</a><header role="banner" class="Header__StyledHeader-sc-1bc1xqp-2 iTpVGQ"><div class="MaxWidth__MaxWidthLayout-sc-1rbvyso-0 Header___StyledMaxWidthLayout-sc-1bc1xqp-10 iqDliS"><div class="Header___StyledDiv-sc-1bc1xqp-3 Fwlym"><a aria-label="Coqui" href="/"><div class="Header___StyledDiv2-sc-1bc1xqp-4 eGBoZs"><div class="Header___StyledImg-sc-1bc1xqp-5 kpuXOb gatsby-image-wrapper" style="position:relative;overflow:hidden;display:inline-block;width:95px;height:26px"><noscript><picture><source srcset="/static/38a06ec53309f617be3eb3b8b9367abf/598c3/logo-wordmark.png 1x,
/static/38a06ec53309f617be3eb3b8b9367abf/e3b64/logo-wordmark.png 1.5x,
/static/38a06ec53309f617be3eb3b8b9367abf/5aa2f/logo-wordmark.png 2x" /><img loading="lazy" width="95" height="26" srcset="/static/38a06ec53309f617be3eb3b8b9367abf/598c3/logo-wordmark.png 1x,
/static/38a06ec53309f617be3eb3b8b9367abf/e3b64/logo-wordmark.png 1.5x,
/static/38a06ec53309f617be3eb3b8b9367abf/5aa2f/logo-wordmark.png 2x" src="/static/38a06ec53309f617be3eb3b8b9367abf/598c3/logo-wordmark.png" alt="" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div></div></a></div><div class="Header___StyledDiv3-sc-1bc1xqp-6 ifalUs"><button aria-label="Global navigation" aria-expanded="false" data-garden-id="buttons.icon_button" data-garden-version="8.31.0" type="button" class="sc-eHgmQL sc-brqgnP jIHHbm"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" focusable="false" role="presentation" data-garden-id="buttons.icon" data-garden-version="8.31.0" class="sc-hSdWYo ZurFO"><path fill="currentColor" d="M9.5 2.5a1.5 1.5 0 11-3 0 1.5 1.5 0 013 0zm0 5.5a1.5 1.5 0 11-3 0 1.5 1.5 0 013 0zm0 5.5a1.5 1.5 0 11-3 0 1.5 1.5 0 013 0z"></path></svg></button></div><nav role="navigation" aria-label="Global" class="Header___StyledNav-sc-1bc1xqp-9 dmeNDE"><div class="Header__StyledDesktopNavItem-sc-1bc1xqp-0 dEzVDV"><a class="StyledNavigationLink-sc-1a9tae1-0 Header__StyledDesktopNavLink-sc-1bc1xqp-1 fqXuiB" href="/about">About</a></div><div class="Header__StyledDesktopNavItem-sc-1bc1xqp-0 dEzVDV"><a class="StyledNavigationLink-sc-1a9tae1-0 Header__StyledDesktopNavLink-sc-1bc1xqp-1 fqXuiB is-current" href="/blog">Blog</a></div><div class="Header__StyledDesktopNavItem-sc-1bc1xqp-0 dEzVDV"><a class="StyledNavigationLink-sc-1a9tae1-0 Header__StyledDesktopNavLink-sc-1bc1xqp-1 fqXuiB" href="/code">Code</a></div><div class="Header__StyledDesktopNavItem-sc-1bc1xqp-0 dEzVDV"><a class="StyledNavigationLink-sc-1a9tae1-0 Header__StyledDesktopNavLink-sc-1bc1xqp-1 fqXuiB" href="/demo">Demo</a></div><div class="Header__StyledDesktopNavItem-sc-1bc1xqp-0 dEzVDV"><a class="StyledNavigationLink-sc-1a9tae1-0 Header__StyledDesktopNavLink-sc-1bc1xqp-1 fqXuiB" href="/jobs">Jobs</a></div><div class="Header__StyledDesktopNavItem-sc-1bc1xqp-0 dEzVDV"><a class="StyledNavigationLink-sc-1a9tae1-0 Header__StyledDesktopNavLink-sc-1bc1xqp-1 fqXuiB" href="/models">Models</a></div></nav></div></header><main class="Root___StyledMain-k2xmz5-2 hJmzvI"><div class="Sidebar___StyledDiv-q5rdfu-1 bJsLke"><div class="MaxWidth__MaxWidthLayout-sc-1rbvyso-0 tqxgC"><div class="Sidebar___StyledDiv2-q5rdfu-2 gKyVMe"><nav aria-label="Primary" class="DesktopSidebar___StyledNav-sc-1ezn4du-0 fOLerP"><div class="DesktopSidebar___StyledDiv-sc-1ezn4du-1 cEEVdI"></div></nav><div class="Sidebar___StyledDiv3-q5rdfu-3 jJwXiO"><div id="main-content" class="Sidebar___StyledDiv4-q5rdfu-4 iARHbT"><div data-garden-id="grid.grid" data-garden-version="8.31.0" class="sc-jAaTju cxJGyA"><div data-garden-id="grid.row" data-garden-version="8.31.0" class="sc-jDwBTQ hKRDwX"><div data-garden-id="grid.col" data-garden-version="8.31.0" class="sc-cMljjf jnzUYZ"><h2 class="sc-iRbamj bSMrqM Typography__StyledH2-xo896r-1 cdcKhH" data-garden-id="typography.font" data-garden-version="8.31.0">Double Decoder Consistency</h2><div><figure aria-atomic="true" aria-live="polite" data-garden-id="avatars.avatar" data-garden-version="8.31.0" class="sc-kjoXOD ZLMZX"><img alt="avatar" src="https://avatars.githubusercontent.com/u/1402048?s=460&amp;v=4"/></figure><div data-garden-id="typography.font" data-garden-version="8.31.0" class="sc-iRbamj cgPVmz">Eren Gölge</div><div data-garden-id="typography.font" data-garden-version="8.31.0" class="sc-iRbamj gBLfIq">June 3, 2020</div></div><hr class="Typography__StyledHr-xo896r-7 fWmrzw"/><div class="Titled___StyledTOCBlock-sc-16c5y7v-0 EQyIi"><div class="SectionCallout__StyledSectionHeader-sc-6sz3ai-0 jeeFUs">Table of Contents</div><ul><li><a href="#end-to-end-tts-models-with-attention" data-garden-id="buttons.anchor" data-garden-version="8.31.0" class="sc-eHgmQL sc-cvbbAY bINUcJ">End-to-End TTS Models with Attention</a></li><li><a href="#double-decoder-consistency" data-garden-id="buttons.anchor" data-garden-version="8.31.0" class="sc-eHgmQL sc-cvbbAY bINUcJ">Double Decoder Consistency</a></li><li><a href="#other-model-update" data-garden-id="buttons.anchor" data-garden-version="8.31.0" class="sc-eHgmQL sc-cvbbAY bINUcJ">Other Model Update</a></li><li><a href="#related-work" data-garden-id="buttons.anchor" data-garden-version="8.31.0" class="sc-eHgmQL sc-cvbbAY bINUcJ">Related Work</a></li><li><a href="#results-and-experiments" data-garden-id="buttons.anchor" data-garden-version="8.31.0" class="sc-eHgmQL sc-cvbbAY bINUcJ">Results and Experiments</a></li><li><a href="#future-work" data-garden-id="buttons.anchor" data-garden-version="8.31.0" class="sc-eHgmQL sc-cvbbAY bINUcJ">Future Work</a></li><li><a href="#conclusion" data-garden-id="buttons.anchor" data-garden-version="8.31.0" class="sc-eHgmQL sc-cvbbAY bINUcJ">Conclusion</a></li></ul><hr class="Typography__StyledHr-xo896r-7 fWmrzw"/></div><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">Despite the success of the latest attention based end2end text2speech (TTS)
models, they suffer from attention alignment problems at inference time. They
occur especially with long-text inputs or out-of-domain character sequences.
Here I’d like to propose a novel technique to fight against these alignment
problems which I call Double Decoder Consistency (DDC) (with a limited
creativity). DDC consists of two decoders that learn synchronously with
different reduction factors. We use the level of consistency of these decoders
to attain better attention performance.</p><div align="center"><iframe width="560" height="315" src="https://www.youtube.com/embed/ADnBCz0Wd1U" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><h3 id="end-to-end-tts-models-with-attention" style="position:relative" class="sc-iRbamj dYOvul Typography__StyledH3-xo896r-2 hmdGyC" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#end-to-end-tts-models-with-attention" aria-label="end to end tts models with attention permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>End-to-End TTS Models with Attention</h3><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">Good examples of attention based TTS models are Tacotron and Tacotron2
[<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1703.10135" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">1<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>][<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1712.05884" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">2<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>].
Tacotron2 is also the main architecture used in this work. These models
comprise a sequence-to-sequence architecture with an encoder, an
attention-module, a decoder and an additional stack of layers called Postnet.
The encoder takes an input text and computes a hidden representation from which
the decoder computes predictions of the target acoustic feature frames. A
context-based attention mechanism is used to align the input text with the
predictions. Finally, decoder predictions are passed over the Postnet which
predicts residual information to improve the reconstruction performance of the
model. In general, mel-spectrograms are used as acoustic features to represent
audio signals in a lower temporal resolution and perceptually meaningful way.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">Tacotron proposes to compute multiple non-overlapping output frames by the
decoder. You are able to set the number of output frames per decoder step which
is called “reduction rate” (r). Larger the reduction rate, fewer the number of
decoder steps required for the model to produce the same length output.
Thereby, the model achieves faster training convergence and easier attention
alignment, as explained in [<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1703.10135" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">1<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>]. However,
larger r values also produce smoother output frames and therefore, reduce the
frame-level details.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">Although these models are used in TTS systems for more natural-sounding speech,
they frequently suffer from attention alignment problems, especially at
inference time, because of out-of-domain words, long input texts, or
intricacies of the target language. One solution is to use larger r for a
better alignment however, as noted above, it reduces the quality of the
predicted frames. DDC tries to mitigate these attention problems by introducing
a new architecture.</p><div align="center"><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:413px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:151.2%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAeCAYAAAAsEj5rAAAACXBIWXMAAAsTAAALEwEAmpwYAAADIElEQVRIx6VWaU8qQRDc//97+GKMERBNQI6ATw4FEQQ5BVGOvftV9WPIiivic5LJLrs9NTXV1b1Y8sUIw1Anh+/7sl6vpVgsytnZmTw8PEgQBLu46LDkwDDBruvK4+OjDIdDabfb0uv1PsV8C2gCl8uljMdj6XQ6MhgMxHGcTyf4EeDLy4tcX19LKpWSZDKpTKPvf8yQV+p3d3enYK+vr7FARwOa8fz8LNVqVTzP+x0gGXW7Xc3sfD7XhER1PAowKniz2ZSrqyvJZDKSz+elUqnI+/v7/wOS1WQy0cQ8PT3JYrFQX/4IME5HepAa2rb9Ow3NdTqdqp5kF62S6FTA/YdxQa1WS05OTuT09FR1jAMz0zqmllkt5+fnkk6n5e3t7fCRA1gg2GzEh3n91Uo8TF5DPAv02VIgnCyQmCWqhvceNjCxvPeQKE5l6GFHf7OW/f1YHWwKIfRi4Gw2O6idB31DmN5SNttAZpALWQ3sKiw3JoLg/F2v179MmjJUQNy4oL0AU1YDQdhdVtiIg1dqSNuwYrjBPtMPgDZ0maOc2ij8RqOhi5hVtioupKlZKYlEQnK5nL6PJmbXM1EAAQEd7Djv92UCnzVwJC5iyzLlNRqN9LiFQkF7IgEpwf5wsSaA5hapBtjRg2GLWMSFLDEelaDUlZpSCtMUDDtuZKRxQEgBXWYPLKfYIQmvEZCJ4WIemWDMNpmZxeaYlGiOWAWENP8AAWTjB8cGRyErAm7gQyapUi5LHo3h8vJSMhcXks1mpYcTrAE+5CdhW9sOEklPK6ALuvp1A6MNAv6gCYwQMMbzKnStYVZubqRxfy/3SNgMCfDB0otUy05DZseBJfyt40MwdMBwgQ5NS9GwPmYDUqzGI60UYSyeOYjhUW1egUE/WyGSwbJj+fE+8Fz1EwRUG9h45wGkCb360NGhLKwKvF+j+a448c7f6hvfYM0xAEjb1LGgVqtJDlpmYasOrQMC0ViTLOtQ22KFMLu3t7fqT7auMpLE70o04x/64aHmSsuYT0CpVNINaGpj7NgGe+xnlLV86P23H6l9BmS7zybu78hf8VIRuiBoTcEAAAAASUVORK5CYII=&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image" alt="IMAGE" title="IMAGE" src="/static/e4c7359592414d8f0b25f9c24e75284e/e1a93/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-model-overview.png" srcSet="/static/e4c7359592414d8f0b25f9c24e75284e/43fa5/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-model-overview.png 250w,/static/e4c7359592414d8f0b25f9c24e75284e/e1a93/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-model-overview.png 413w" sizes="(max-width: 413px) 100vw, 413px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p></div><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">The bare-bone model used in this work is formalized as follows:</p><div align="center"><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:455px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:92.4%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB2ElEQVQ4y32U547DMAyD+/7Plh8FinTv3bRN9x46fMIx8OXSGjAcKxZNkUpK9jve77ev5/PZttutrddre71edjqdbLVa2X6/99hms8nW4/Foh8PhT34pD5imqXU6Het2uw6i/Ww2s16vZ8vl0vfMfr/v+0LAMMh4PB7OFFDAYJkkiTOjCp19Pp/fGWql1MVi4SVNJhMbjUbOiBig9/vdJVFOIcMQ8HK52HQ6dYYAUe54PPZnaSj9wtyPgJQMKEwol2QkYKIrhux2u0wCzn5lyCG0AwCD2u22z8FgYNVqNWPNO2nsgKF2oRasapv5fO7iw5Y1NE/VSM9SHkjjer26ATgbRZENh0NnKCZFef80JKA2CEde/E/DAXFRrVCr1axcLlur1XJ9EJ6hr4MJS9iTTFMzMQmDvGR0wQBYyFVWLhFbgG+3WxbnLHviEMI4dHRAbm02m1av101sYYdmJLKP49jdrFQq7iguNxoNZ4ammJaVLPe4Uf3EzRzU16CVBC7FeUqEDDnMQlNIQkdup89UIntYskpfnmHL16RyHTC0X30HELpQMjFYMXmGFXGM4lOEKec//hw0KBMHYYHG6ku0pkQq4VLA0DYzJf+nyTcsrOS29OZdWKZijB/1dGxxHQvMlAAAAABJRU5ErkJggg==&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image" alt="IMAGE" title="IMAGE" src="/static/62f5e5526dd116e8aa7c2ac1736457e6/d2e8e/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-equation-1.png" srcSet="/static/62f5e5526dd116e8aa7c2ac1736457e6/43fa5/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-equation-1.png 250w,/static/62f5e5526dd116e8aa7c2ac1736457e6/d2e8e/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-equation-1.png 455w" sizes="(max-width: 455px) 100vw, 455px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p></div><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">where y<sub>k</sub> is a sequence of acoustic feature frames. x<sub>l</sub> is
a sequence of characters or phonemes, from which we compute sequence of encoder
outputs h<sub>l</sub>. r is the reduction factor which defines the number of
output frames per decoder step. Attention alignments, query vector and encoder
output at decoder step t are donated by a<sub>t</sub>, q<sub>t</sub>, and
o<sub>t</sub> respectively. Also, o<sub>t</sub> defines a set of output frames
whose size changed by r. Total number of decoder steps is donated by T.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">Note that teacher forcing is applied at training. Therefore, K=Tr at training
time. However, the decoder is instructed to stop at inference by a separate
network (Stopnet) which predicts a value in a range <!-- -->[0, 1]<!-- -->. If its prediction
is larger than a defined threshold, the decoder stops inference.</p><h3 id="double-decoder-consistency" style="position:relative" class="sc-iRbamj dYOvul Typography__StyledH3-xo896r-2 hmdGyC" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#double-decoder-consistency" aria-label="double decoder consistency permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>Double Decoder Consistency</h3><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">DDC is based on two decoders working simultaneously with different reduction
factors (r). One decoder (coarse) works with a large, and the other decoder
(fine) works with a small reduction factor.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">DDC is designed to settle the trade-off between the attention alignment and the
predicted frame quality tunned by the reduction factor. In general, standard
models have more robust attention performance with a larger r but due to the
smoothing effect of multiple-frames prediction per iteration, final acoustic
features are coarser compared to lower reduction factor models.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">DDC combines these two properties at training time as it uses the coarse
decoder to guide the fine decoder to preserve the attention performance without
a loss of precision in acoustic features. DDC achieves this by introducing an
additional loss function comparing the attention vectors of these two decoders.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">For each training step, both decoders compute their relative attention vectors
and the outputs. Due to the differences in their respective r values, their
attention vectors are different lengths. The coarse decoder produces a shorter
vector compared to the fine decoder. In order to mitigate this, we interpolate
the coarse attention vector to match the length of the fine attention vector.
After coercing them in the same length we use a loss function to penalize the
difference in the alignments. This loss is able to synchronize two decoders
with respect to their alignments.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:1000px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:79.6%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAACMUlEQVQ4y3VUiXaiQBD0/z9t80yyxvXEgyjigdwIDEdvVb81QeLOe/0YmJnqquoeBoLRtq30n8/m/XFf68agu3gfruvKarV6AMvzXMIwlDRNJY5jqev6aZJBn8XhcJDRaCRZlj0kIQgBgyCQ4/GogMYYqapKyrLU/Uz6AzCKIpnP53ogSRJltF6vZb/fi+d5Ot9utzpfLpdiWZaqmUwmcrlcvgHvT26eTqe6SDAyul6vGkxApvzGxI7jaAKukaV62DWUg0yGw6HK6w9KvN1uKpPATHo6nTTRg4ddliUOjcdj9aOC7KIoJEfQIwKRPdf+V/FBi0NNXQmf+CIGh8coSn7LJGYRICeFvBgyDdh9vL1JinmDfYZJslTqIv8CHTQG2ptaSrYFNtZgGEehJigAoAF5lMvBYpEpmdNjA+9q7PkCLPCR5m5QDBrNlngFiwgglMqDSeCrVN/3ZTabqb9N04ht21rEPAy6gInMsYkHWKnz+SxTtECOrCwATfcOjvx+f1cgAhJY/cS+5WIhVRJ/A7YA2W42skW2DABHAFjoqxBsU3iUQEENPymV7/bnp4aDC7BnoCsakGrvgIYv8CdAo3oEA4MRJLv7nRahovlxJBnCB/sDwNzdTjxYY3gFURRidIpiRAvDatNsgNho1gCyCkhMrIVWEqaxItoJGtgb/hlLBjse2kZf/vUSjV7Ak18vLyqbnja8Afde6wUJtEzU6eMfN4UNzFvQ69qnv6r+peDzL6oh0h8mn7MgAAAAAElFTkSuQmCC&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image" alt="IMAGE" title="IMAGE" src="/static/ef79d367f6ad0564ef7c89cf33a51067/da8b6/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-ddc-overview.png" srcSet="/static/ef79d367f6ad0564ef7c89cf33a51067/43fa5/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-ddc-overview.png 250w,/static/ef79d367f6ad0564ef7c89cf33a51067/c6e3d/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-ddc-overview.png 500w,/static/ef79d367f6ad0564ef7c89cf33a51067/da8b6/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-ddc-overview.png 1000w,/static/ef79d367f6ad0564ef7c89cf33a51067/f1720/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-ddc-overview.png 1024w" sizes="(max-width: 1000px) 100vw, 1000px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">The two decoders take the same input from the encoder. They also compute the
outputs in the same way except they use different reduction factors. The coarse
decoder uses a larger reduction factor compared to the fine decoder. These two
decoders are trained with separate loss functions comparing their respective
outputs with the real feature frames. The only interaction between these two
decoders is the attention loss applied to compare their respective attention
alignments.</p><div align="center"><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:706px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:33.199999999999996%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAAA0UlEQVQoz32RiQqEMAxE+/9/WZB6X/U+s7xAiyxioMaE5s1ETVEU0ratdF0nzjl9H8dR0jSVLMukqirNTdNo33svxH3fev7DhAEul2WpwGVZpO97HSYDoz9Nk977BFprBZfrukqSJFLXtYIQeToEyBmGIQLfwvAAhpM8z9UNDgFRk1kfMYSv64ru3o4JStu26TAugAIBSEbsue5XmOe3CN+QtYHhlB4gtjjPU+Z51rWpMUGN2HEcei86ZBWcAcNR+CnUQBlCjLXp7fsehekDZv4HoP4cKys79uIAAAAASUVORK5CYII=&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image" alt="IMAGE" title="IMAGE" src="/static/370c32ce06b13bf6e357b23241e24ab6/a1ee8/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-equation-2.png" srcSet="/static/370c32ce06b13bf6e357b23241e24ab6/43fa5/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-equation-2.png 250w,/static/370c32ce06b13bf6e357b23241e24ab6/c6e3d/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-equation-2.png 500w,/static/370c32ce06b13bf6e357b23241e24ab6/a1ee8/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-equation-2.png 706w" sizes="(max-width: 706px) 100vw, 706px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p></div><h3 id="other-model-update" style="position:relative" class="sc-iRbamj dYOvul Typography__StyledH3-xo896r-2 hmdGyC" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#other-model-update" aria-label="other model update permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>Other Model Update</h3><h4 id="batch-norm-prenet" style="position:relative" class="sc-iRbamj aYPWv Typography__StyledH4-xo896r-3 lmFVlv" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#batch-norm-prenet" aria-label="batch norm prenet permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>Batch Norm Prenet</h4><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">The Prenet is an important part of Tacotron-like auto-regressive models. It
projects model output frames before passing to the decoder. Essentially, it
computes an embedding space of the feature (spectrogram) frames by which the
model de-factors the distribution of upcoming frames.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">I replaced the original Prenet (PrenetDropout) with the one using Batch
Normalization [<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1502.03167" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">3<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>] (PrenetBN) after each
dense layer, and I removed the Dropout layers. Dropout is necessary for
learning attention, especially when the data quality is low. However, it causes
problems at inference due to distributional differences between training and
inference time. Using Batch Normalization is a good alternative. It avoids the
issues of Dropout and also provides a certain level of regularization due to
the noise of batch-level statistics. It also normalizes computed embedding
vectors and generates a well-shaped embedding space.</p><h4 id="gradual-training" style="position:relative" class="sc-iRbamj aYPWv Typography__StyledH4-xo896r-3 lmFVlv" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#gradual-training" aria-label="gradual training permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>Gradual Training</h4><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">I used a gradual training scheme for the model training. I’ve introduced
gradual training in a previous <a href="/blog/tts/gradual-training-with-tacotron-for-faster-convergence">blog
post</a>. In short, we start the model training with a larger reduction
factor and gradually reduce it as the model saturates.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">Gradual Training shortens the total training time significantly and yields
better attention performance due to its progression from coarse to fine
information levels.</p><h4 id="recurrent-postnet-at-inference" style="position:relative" class="sc-iRbamj aYPWv Typography__StyledH4-xo896r-3 lmFVlv" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#recurrent-postnet-at-inference" aria-label="recurrent postnet at inference permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>Recurrent PostNet at Inference</h4><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">The Postnet is the part of the network applied after the Decoder to improve the
Decoder predictions before the vocoder. Its output is summed with the Decoder’s
to form the final output of the model. Therefore, it predicts a residual which
improves the Decoder output. So we can also apply Postnet more than one time,
assuming it computes useful residual information each time. I applied this
trick only at inference and observe that, up to a certain number of iterations,
it improves the performance. For my experiments, I set the number of iterations
to 2.</p><h4 id="mb-melgan-vocoder-with-multiple-random-window-discriminator" style="position:relative" class="sc-iRbamj aYPWv Typography__StyledH4-xo896r-3 lmFVlv" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#mb-melgan-vocoder-with-multiple-random-window-discriminator" aria-label="mb melgan vocoder with multiple random window discriminator permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>MB-Melgan Vocoder with Multiple Random Window Discriminator</h4><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">As a vocoder, I use Multi-Band Melgan [<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/2005.05106" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">11<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>]
generator. It is trained with Multiple Random Window Discriminator
(RWD)[<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1909.11646" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">13<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>] which is different than in the
original work [<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/2005.05106" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">11<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>] where they used
Multi-Scale Melgan Discriminator (MSMD)[<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1909.11646" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">12<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>].</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">The main difference between these two is that RWD uses audio level information
and MSMD uses spectrogram level information. More specifically, RWD comprises
multiple convolutional networks each takes different length audio segments with
different sampling rates and performs classification whereas MSMD uses
convolutional networks to perform the same classification on STFT output of the
target voice signal.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">In my experiments, I observed RWD yields better results with more natural and
less abberated voice.</p><h3 id="related-work" style="position:relative" class="sc-iRbamj dYOvul Typography__StyledH3-xo896r-2 hmdGyC" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#related-work" aria-label="related work permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>Related Work</h3><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">Guided attention [<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1710.08969" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">4<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>] uses a soft diagonal
mask to force the attention alignment to be diagonal. As we do, it uses this
constant mask at training time to penalize the model with an additional loss
term. However, due to its constant nature, it dictates a constant prior to the
model which does not always to be true, especially long sentences with various
pauses. It also causes skipping in my experiments which are tried to be solved
by using a windowing approach at inference time in their work.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">Using multiple decoders is initially introduced by
[<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1907.09006" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">5<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>]. They use two decoders that run in
forward and backward directions through the encoder output. The main problem
with this approach is that because of the use of two decoders with identical
reduction factors, it is almost 2 times slower to train compared to a vanilla
model. We solve the problem by using the second decoder with a higher reduction
rate. It accelerates the training significantly and also gives the user the
opportunity to choose between the two decoders depending on run-time
requirements. DDC also does not use any complex scheduling or multiple loss
signals that aggravates the model training.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">Lately, new TTS models introduced by
[<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1905.0926" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">7<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>][<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/2005.11129" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">8<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>][<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/2006.04558" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">9<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>][<a target="_blank" rel="noopener noreferrer" href="https://doi.org/10.1109/icassp40776.2020.9054484" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">10<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>]
predict output duration directly from the input characters. These models train
a duration-predictor or use approximation algorithms to find the duration of
each input character. However, as you listen to their samples, one can observe
that these models lead to degraded timbre and naturalness. This is because of
the indirect hard alignment produced by these models. However, models with
soft-attention modules can adaptively emphasize different parts of the speech
producing a more natural speech.</p><h3 id="results-and-experiments" style="position:relative" class="sc-iRbamj dYOvul Typography__StyledH3-xo896r-2 hmdGyC" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#results-and-experiments" aria-label="results and experiments permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>Results and Experiments</h3><h4 id="experiment-setup" style="position:relative" class="sc-iRbamj aYPWv Typography__StyledH4-xo896r-3 lmFVlv" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#experiment-setup" aria-label="experiment setup permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>Experiment Setup</h4><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">All the experiments are performed using LJspeech dataset
[<a target="_blank" rel="noopener noreferrer" href="https://keithito.com/LJ-Speech-Dataset/" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">6<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>] . I use a sampling-rate of 22050
Hz and mel-scale spectrograms as the acoustic features. Mel-spectrograms are
computed with hop-length 256, window-length 1024. Mel-spectrograms are
normalized into <!-- -->[-4, 4]<!-- -->. You can see the used audio parameters below in our TTS
config format.</p><pre class="sc-gipzik jLOitN CodeBlock__StyledCodeBlock-sc-1er5mkx-0 gHyCyg language-js" data-garden-id="typography.codeblock" data-garden-version="8.31.0"><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// AUDIO PARAMETERS</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">    </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;audio&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">{</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// stft parameters</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;num_freq&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">513</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">         </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// number of stft frequency levels. Size of the linear spectogram frame.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;win_length&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">1024</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">      </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// stft window length in ms.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;hop_length&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">256</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">       </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// stft window hop-lengh in ms.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;frame_length_ms&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token keyword null nil" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">null</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// stft window length in ms.If null, &#x27;win_length&#x27; is used.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;frame_shift_ms&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token keyword null nil" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">null</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">  </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// stft window hop-lengh in ms. If null, &#x27;hop_length&#x27; is used.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">
</span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// Audio processing parameters</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;sample_rate&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">22050</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">   </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// DATASET-RELATED: wav sample-rate. If different than the original data,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">                                </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">//   it is resampled.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;preemphasis&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">0.0</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">     </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// pre-emphasis to reduce spec noise and make it more structured.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">                                </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">//  If 0.0, no -pre-emphasis.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;ref_level_db&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">20</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">     </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// reference level db, theoretically 20db is the sound of air.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">
</span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// Silence trimming</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;do_trim_silence&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token boolean" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">true</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// enable trimming of slience of audio as you load it. LJspeech (false),</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">                                </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">//  TWEB (false), Nancy (true)</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;trim_db&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">60</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">          </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// threshold for timming silence. Set this according to your dataset.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">
</span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// MelSpectrogram parameters</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;num_mels&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">80</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">         </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// size of the mel spec frame.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;mel_fmin&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">0.0</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// minimum freq level for mel-spec. ~50 for male and ~95 for female voices.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">                                </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">//   Tune for dataset!!</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;mel_fmax&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">8000.0</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">     </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// maximum freq level for mel-spec. Tune for dataset!!</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">
</span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// Normalization parameters</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;signal_norm&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token boolean" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">true</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">    </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// normalize spec values. Mean-Var normalization if &#x27;stats_path&#x27; is defined otherwise</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">                                </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">//   range normalization defined by the other params.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;min_level_db&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">-</span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">100</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">   </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// lower bound for normalization</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;symmetric_norm&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token boolean" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">true</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// move normalization to range [-1, 1]</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;max_norm&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">4.0</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// scale normalization to range [-max_norm, max_norm] or [0, max_norm]</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">        </span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;clip_norm&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token boolean" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">true</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">      </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// clip normalized values into the range.</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">    </span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">}</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span></code></pre><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">I used Tacotron2[<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1712.05884" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">2<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>] as the base architecture
with location-sensitive attention and applied all the model updates expressed
above. The model is trained for 330k iterations and it took 5 days with a
single GPU although the model seems to produce satisfying quality after only 2
days of training with DDC. I used a gradual training schedule shown below. The
model starts with r=7 and batch-size 64 and gradually reduces to r=1 and
batch-size 32. The coarse decoder is set r=7 for the whole training.</p><pre class="sc-gipzik jLOitN CodeBlock__StyledCodeBlock-sc-1er5mkx-0 gHyCyg language-js" data-garden-id="typography.codeblock" data-garden-version="8.31.0"><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">{</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span><span class="sc-Rmtcm ceqIaD token string" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">&quot;gradual_training&quot;</span><span class="sc-Rmtcm ceqIaD token operator" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">:</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">[</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">[</span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">0</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">7</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">64</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">]</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">[</span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">1</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">5</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">64</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">]</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">[</span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">50000</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">3</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">32</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">]</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">[</span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">130000</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">2</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">32</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">]</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">[</span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">290000</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">1</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token number" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">32</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">]</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">]</span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">,</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"> </span><span class="sc-Rmtcm ceqIaD token comment" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">// [first_step, r, batch_size]</span><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span></code><code class="sc-iRbamj sc-csuQGl bPqEGj token-line" data-garden-id="typography.codeblock_code" data-garden-version="8.31.0"><span class="sc-Rmtcm ceqIaD token plain" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0"></span><span class="sc-Rmtcm ceqIaD token punctuation" data-garden-id="typography.codeblock_token" data-garden-version="8.31.0">}</span></code></pre><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">I trained MB-Melgan vocoder using real spectrograms up to 1.5M steps, which
took 10 days on a single GPU machine. For the first 600K iterations, it is
pre-trained with only the supervised loss as in
[<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/2005.05106" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">11<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>] and than the discriminator is enabled
for the rest of the training. I do not apply any learning rate schedule and I
used 1e-4 for the whole training.</p><h4 id="ddc-attention-performance" style="position:relative" class="sc-iRbamj aYPWv Typography__StyledH4-xo896r-3 lmFVlv" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#ddc-attention-performance" aria-label="ddc attention performance permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>DDC Attention Performance</h4><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">The image below shows the validation alignments of the fine and the coarse
decoders which have r=1 and r=7 respectively. We observe that two decoders show
almost identical attention alignments with a slight roughness with the coarse
decoder due to the interpolation.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">DDC significantly shortens the time required to learn the attention alignmet.
In my experiments, the model is able to align just after 1k steps as opposed to
~8k steps with normal location-sensitive attention.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:1000px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:30%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABmUlEQVQY002QT0hUURSHj5iUoq1a5R/CbYERVMZYOjrPN+orx9LnjEENNKWCRUWmFYajjrQR0k0rIdCFTLmQoTZBhDWWtBhdFDhkugwhce+MX+e9EfLCj7s4H9/9nSvzUwmaioKEKrqxSyPYxyN0lt+mrfQWg9YTtneWcc676Q9YR68TrLjznytTrjzC3dpH/N35plQGmRmNc0Z8+PLa8UpAcxXvERuPXOHGqT5Wt1Zd4duXCc5KIw1yTZm2HHfYpkZascsipP6kyLrCsTjnxY95yMZXoCkMYuhdp+DN0/dZ3PyVE04muCDNmPkO14GvqHOfCxCq7OHTRppdVcps7A3VKvTrOkZxCCO/A1NBp2246iHJn79dofM1HmnBXxLKcVrAKVGvbbsqe/n8Y53dvT3kdXSOk9LAJR14xHJTI5c5JybBE718XUq7wvjEAlVicFEfOsg52wWOhVlKrpHJasOP80nueYd4Zo0z0DTCY3+Up1aM/sZhJrpfkV7ZdIVf3n/ngfFcuZjL9ZvD+1yUF+Ep1lIbZDNZ/gG2qRGhZ08LsQAAAABJRU5ErkJggg==&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image" alt="IMAGE" title="IMAGE" src="/static/b2806805fe690ce3e06f39c3cb3e635e/da8b6/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-alignment.png" srcSet="/static/b2806805fe690ce3e06f39c3cb3e635e/43fa5/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-alignment.png 250w,/static/b2806805fe690ce3e06f39c3cb3e635e/c6e3d/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-alignment.png 500w,/static/b2806805fe690ce3e06f39c3cb3e635e/da8b6/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-alignment.png 1000w,/static/b2806805fe690ce3e06f39c3cb3e635e/99b7b/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-alignment.png 1360w" sizes="(max-width: 1000px) 100vw, 1000px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">At inference time, we ignore the coarse decoder and use only the fine decoder.
The image below depicts the model outputs and attention alignments at inference
time with 4 different sentences that are not seen at training time. This shows
us that the fine decoder is able to generalize successfully on novel sentences.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:1000px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:39.6%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAACHklEQVQoz1WR60uTcRTHHwiiP6BQgiRp2gVasm6GYAyE6VpO5mWWkruY6HTpKtGFecm5WjqjbC1TNIrqXS/7h4Rmbu6ic27P8+z59Nt8Uy++HM73fOCcw1caNDzFKNkwHuvEddPHdj5Fx/QGdT0B6u4v0D4ZIavs4zVMcPt4O8ZKBz1XR4jnUtiWv3LRE+KSb4luR5h4Mo7kuODlhmSmXshe62FrP4N5YZXavll07jlM4+9JHxwwcMXH9RNWwdmwnnYTywju3TpnvXNUPQtievSG2M4u0sy9JXrPD/NA58FvCbKT3MPz8zOWyGvMHxbpX90gmzpkfixCr36EvnPDPDHNkdzdw/drk5a1EM2bYZxf1olvZ5CKahFVVlFVIUVF0zTkolJWQTuqJU8tcQXlP04V84J6xMiK4IoakiIguSBTOJRRxBCKKHkFpdRnZYp5WXga/3JqmSt5atmTS4sUwYklkt8cwF7ppqt6iIneF6TzCQbCP7A2+TE9XMQ7ExUXZJi6G6KzwoVdJ17umiIjpxgKf8PSNk2TfwXPTIS9gwRSnwjlmmQVwbRirxliK5em5dUn9LfGqB6cpXl0hXQuS/9lHwbJIkJppbWqn5gIzzq9ht7wmBpXgDvOZWKJJNJ4R5C2M25sJx2MNj7nTzqN83uURm+QxuV57G+j7Kdy+LtDWCscdJxyMlg/yW4yg2tznQbXSxrCQTqDH9n5neIvQKfD2Urvl0EAAAAASUVORK5CYII=&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image" alt="IMAGE" title="IMAGE" src="/static/09e724b596058252333f24f77120914e/da8b6/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-alignments.png" srcSet="/static/09e724b596058252333f24f77120914e/43fa5/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-alignments.png 250w,/static/09e724b596058252333f24f77120914e/c6e3d/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-alignments.png 500w,/static/09e724b596058252333f24f77120914e/da8b6/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-alignments.png 1000w,/static/09e724b596058252333f24f77120914e/2e9ed/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-alignments.png 1500w,/static/09e724b596058252333f24f77120914e/9fabd/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-alignments.png 2000w,/static/09e724b596058252333f24f77120914e/7b24f/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-alignments.png 2048w" sizes="(max-width: 1000px) 100vw, 1000px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">I used 50 hard-sentences introduced by [<a target="_blank" rel="noopener noreferrer" href="http://arxiv.org/abs/1905.09263" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">7<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>]
to check the attention quality of the DDC model. As you see in the
<a target="_blank" rel="noopener noreferrer" href="https://colab.research.google.com/gist/erogol/32d22e21eaa1d0cc0cb52f0fd0c72c55/ddc_sentece_test_330k.ipynb" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">notebook<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>
(Open it on Colab to listen to Griffin-Lim based voice samples), the DDC model
performs without any alignment problems. It is the first model, to my
knowledge, which performs flawlessly on these sentences.</p><h4 id="recurrent-postnet" style="position:relative" class="sc-iRbamj aYPWv Typography__StyledH4-xo896r-3 lmFVlv" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#recurrent-postnet" aria-label="recurrent postnet permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>Recurrent Postnet</h4><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">In the image below we see the average L1 difference between the real
mel-spectrogram and the model prediction for each Postnet iteration. The
results improve until the 3rd iteration. We also observe that some of the
artifacts after the first iteration are removed by the second iteration that
yields a better L1 value. Therefore, we see here how effective the iterative
application of the Posnet to improve the final model predictions.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:1000px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:70%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADiUlEQVQ4yyVT209TBxzu25K5l6k4NAg4vA2VobTFwjmnt9PTlspkm8JkoAXaQlvOaemNUi7uYYBSkIK36LIs0QcTl/mibFnM4mXZYmJcZEOjJsseZvawPZBsf8C375w+fPmd3zm/3/e7fcfUsTsF9+ZBHNmRgL9Ghb9WRVu1ikCtBrkyioh7Bq/X72MiXIKzku/3pOHfOQI/83Qb2JWCXD2MobYF/PH3CkxKZQzNb5yCs2IIDhI7KohNg3BuDMO2oQ+9zVN4/s+PGOkuwrohBMd2FfZtcTiqhuHYSjD/8NthBO0zePLX9zC1s5KdZP6aBLwM9tZo8FZr8BHOrXGEnJ/j/us1pPovkEiFb08Gys4UFOYpu9LwEfYdSXZYxJ3fn8AU2J2GtHkI3toEPLVJIgGlSoVCa982jAHnNO6+fIFE3yVIVRqUvVnIOkjsIbGHz2LdCAYDRdxaXWWH/GCviMJflypXZjUv4aPvIGHINY17T18iFbwEOwt594/Co0Pv9L0svPW5coft87j9868wyQyyvtln7ELSsSUKiQXstIffGkCv7TQePHiG+LESrBsjkDiFyPWIXI+4XYNEa+WEQXkGKyscOXNsEVHvLEY65qG1z0H9YA5a4CyS9OO+WUzHvsRvj15hefImou1FJI+XoH10DqoOxiSYH+P7M+lrePzDGkyjA1egdi4h03MBia4S1K5F+otI91yE1lnCbO4G/v3vMa6WvkH8xEVkOLr26XkMdy9B7V5GOnjZsGfGv8b6+kOY3NybmS2LdRyFhxDeLY8k8cqWd6Lo5lGeUTZa3yKatsQhUIcCc1p5ZYF7Frk/c1Ucvb5iWTYBywREilNpLBjLlt8nGvJQCGlfFv1HF3DvzzUkY1cg8qIe8wTkxjHIB8fgJjwHCxCYE+lcxm1dNr7mSbSwqnyoAJcOPfBA3ghubcgh2LFgyEaNXUVLfRbu5gk4rYR53Ih1WcZhO5RHqGupLJs2fhSoRQ+JXXw2KjcVIDNBPJBD/4cLhmwSsS/QSt8tfQanMGXEumyTcNum0NI0hvCJ5bJs3I15WPjfSg2jEPbnINRniCwkwsq99hyZw0PKJjZwGU17uTdLgQR5tLIrnUigNe/L4CSP+d23v8AU+2QJp9rOYvDjc4iwGwNH5xGhHyTZpPoVnv70AsWpmzhJmUSohBBVEKYCwsdp9XzmnM5dx6O7q/gfk0JYhvkA5uEAAAAASUVORK5CYII=&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image" alt="IMAGE" title="IMAGE" src="/static/e4a0e3fe77a7f947321db273f2d8b2ea/da8b6/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-recurrent-postnet.png" srcSet="/static/e4a0e3fe77a7f947321db273f2d8b2ea/43fa5/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-recurrent-postnet.png 250w,/static/e4a0e3fe77a7f947321db273f2d8b2ea/c6e3d/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-recurrent-postnet.png 500w,/static/e4a0e3fe77a7f947321db273f2d8b2ea/da8b6/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-recurrent-postnet.png 1000w,/static/e4a0e3fe77a7f947321db273f2d8b2ea/2e9ed/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-recurrent-postnet.png 1500w,/static/e4a0e3fe77a7f947321db273f2d8b2ea/9fabd/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-recurrent-postnet.png 2000w,/static/e4a0e3fe77a7f947321db273f2d8b2ea/0404f/blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-recurrent-postnet.png 2044w" sizes="(max-width: 1000px) 100vw, 1000px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><h3 id="future-work" style="position:relative" class="sc-iRbamj dYOvul Typography__StyledH3-xo896r-2 hmdGyC" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#future-work" aria-label="future work permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>Future Work</h3><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">First of all I hope this section would not be “here are the things we’ve not
tried and will not try” section.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">However, there are specifically three aspects of DDC which I like to
investigate more. The first is sharing the weights between the fine and the
coarse decoders to reduce the total number of model parameters and observing
how the shared weights benefit from different resolutions.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">The second is to measure the level of complexity required by the coarse
decoder. That is, how much simpler the coarse architecture can get without
performance loss.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">Finally, I like to try DDC with the different model architectures.</p><h3 id="conclusion" style="position:relative" class="sc-iRbamj dYOvul Typography__StyledH3-xo896r-2 hmdGyC" data-garden-id="typography.font" data-garden-version="8.31.0"><a href="#conclusion" aria-label="conclusion permalink" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh anchor before" data-garden-id="buttons.anchor" data-garden-version="8.31.0"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" focusable="false" viewBox="0 0 16 16">
  <path fill="currentColor" d="M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z"></path></svg></a>Conclusion</h3><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">Here I tried to summarize a new method that significantly accelerates model
training, provides steadfast attention alignment and provides a choice in a
spectrum of quality and speed switching between the fine and the coarse
decoders at inference. The user can choose depending on run-time requirements.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">You can replicate all this work using our
<a target="_blank" rel="noopener noreferrer" href="https://github.com/coqui-ai/TTS" class="sc-eHgmQL sc-cvbbAY bINUcJ Anchor__StyledAnchor-sc-1q3ov98-0 gjZoLh" data-garden-id="buttons.anchor" data-garden-version="8.31.0">TTS<svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" theme="[object Object]" data-garden-id="buttons.external_icon" data-garden-version="8.31.0" class="sc-jWBwVP kKEUTC"><path fill="none" stroke="currentColor" stroke-linecap="round" d="M10.5 8.5V10c0 .3-.2.5-.5.5H2c-.3 0-.5-.2-.5-.5V2c0-.3.2-.5.5-.5h1.5M6 6l4-4m-3.5-.5H10c.3 0 .5.2.5.5v3.5"></path></svg></a>. You can also see voice samples and
Colab Notebooks from the links above. Let me know how it goes if you try DDC in
your project.</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0">If you would like to cite this work, please use:</p><p class="sc-caSCKo fbGZzl Typography__StyledParagraph-xo896r-8 gGFgqj" data-garden-id="typography.paragraph" data-garden-version="8.31.0"><em class="sc-iRbamj jDwDPA Typography__StyledEmphasis-xo896r-10 kbQOIb" data-garden-id="typography.font" data-garden-version="8.31.0">Gölge E. (2020) Solving Attention Problems of TTS models with Double Decoder Consistency.
erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/</em></p></div><div class="sc-cMljjf hUigtZ Titled___StyledCol-sc-16c5y7v-1 jCZXmA" data-garden-id="grid.col" data-garden-version="8.31.0"><div class="TOC___StyledDiv-sc-1hj7fxm-4 hCsyko"><div class="SectionCallout__StyledSectionHeader-sc-6sz3ai-0 TOC___StyledStyledSectionHeader-sc-1hj7fxm-5 dcLymE">Table of Contents</div><ul class="TOC___StyledUl2-sc-1hj7fxm-6 kdJXOp"><li><a href="#end-to-end-tts-models-with-attention" class="sc-eHgmQL sc-cvbbAY bINUcJ TOC__StyledAnchor-sc-1hj7fxm-1 TOC___StyledStyledAnchor-sc-1hj7fxm-3 dIPvJZ" data-garden-id="buttons.anchor" data-garden-version="8.31.0">End-to-End TTS Models with Attention</a></li><li><a href="#double-decoder-consistency" class="sc-eHgmQL sc-cvbbAY bINUcJ TOC__StyledAnchor-sc-1hj7fxm-1 TOC___StyledStyledAnchor-sc-1hj7fxm-3 dIPvJZ" data-garden-id="buttons.anchor" data-garden-version="8.31.0">Double Decoder Consistency</a></li><li><a href="#other-model-update" class="sc-eHgmQL sc-cvbbAY bINUcJ TOC__StyledAnchor-sc-1hj7fxm-1 TOC___StyledStyledAnchor-sc-1hj7fxm-3 dIPvJZ" data-garden-id="buttons.anchor" data-garden-version="8.31.0">Other Model Update</a></li><li><a href="#related-work" class="sc-eHgmQL sc-cvbbAY bINUcJ TOC__StyledAnchor-sc-1hj7fxm-1 TOC___StyledStyledAnchor-sc-1hj7fxm-3 dIPvJZ" data-garden-id="buttons.anchor" data-garden-version="8.31.0">Related Work</a></li><li><a href="#results-and-experiments" class="sc-eHgmQL sc-cvbbAY bINUcJ TOC__StyledAnchor-sc-1hj7fxm-1 TOC___StyledStyledAnchor-sc-1hj7fxm-3 dIPvJZ" data-garden-id="buttons.anchor" data-garden-version="8.31.0">Results and Experiments</a></li><li><a href="#future-work" class="sc-eHgmQL sc-cvbbAY bINUcJ TOC__StyledAnchor-sc-1hj7fxm-1 TOC___StyledStyledAnchor-sc-1hj7fxm-3 dIPvJZ" data-garden-id="buttons.anchor" data-garden-version="8.31.0">Future Work</a></li><li><a href="#conclusion" class="sc-eHgmQL sc-cvbbAY bINUcJ TOC__StyledAnchor-sc-1hj7fxm-1 TOC___StyledStyledAnchor-sc-1hj7fxm-3 dIPvJZ" data-garden-id="buttons.anchor" data-garden-version="8.31.0">Conclusion</a></li></ul></div></div></div></div></div></div></div></div></div></main><footer class="Footer___StyledFooter-owx86q-1 jOzwVI"><div class="MaxWidth__MaxWidthLayout-sc-1rbvyso-0 tqxgC"><div class="Footer___StyledDiv-owx86q-2 dSuWUw"><a href="https://github.com/coqui-ai" aria-label="Coqui" data-garden-id="buttons.anchor" data-garden-version="8.31.0" class="sc-eHgmQL sc-cvbbAY bINUcJ"><div class="Footer___StyledDiv2-owx86q-3 kPitly"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" class="Footer___StyledGitHubIcon-owx86q-4 bRvpwy"><path fill="currentColor" d="M6 0C2.687 0 0 2.754 0 6.152c0 2.718 1.719 5.024 4.103 5.837.3.057.41-.133.41-.296 0-.146-.005-.533-.008-1.046-1.669.371-2.021-.825-2.021-.825-.273-.711-.666-.9-.666-.9-.545-.382.04-.374.04-.374.603.044.92.634.92.634.535.94 1.404.668 1.746.511.055-.397.21-.669.381-.822-1.332-.155-2.733-.683-2.733-3.04 0-.672.234-1.221.618-1.651-.062-.156-.268-.781.058-1.629 0 0 .504-.165 1.65.631A5.614 5.614 0 016 2.975a5.58 5.58 0 011.502.207c1.146-.796 1.649-.63 1.649-.63.327.847.121 1.472.06 1.628.384.43.616.979.616 1.65 0 2.364-1.403 2.884-2.74 3.036.216.19.408.565.408 1.14 0 .821-.007 1.485-.007 1.687 0 .164.108.356.412.296 2.382-.816 4.1-3.12 4.1-5.837C12 2.754 9.313 0 6 0"></path></svg></div></a><a href="https://twitter.com/coqui_ai" aria-label="Coqui" data-garden-id="buttons.anchor" data-garden-version="8.31.0" class="sc-eHgmQL sc-cvbbAY bINUcJ"><div class="Footer___StyledDiv3-owx86q-5 kNCRIy"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" class="Footer___StyledTwitterIcon-owx86q-6 iRhBUd"><path fill="currentColor" d="M12 2.184a4.83 4.83 0 01-1.415.397 2.52 2.52 0 001.083-1.396 4.87 4.87 0 01-1.564.612A2.428 2.428 0 008.308 1c-1.36 0-2.463 1.13-2.463 2.524 0 .198.023.39.065.576C3.863 3.994 2.05 2.99.835 1.46a2.564 2.564 0 00-.332 1.27 2.54 2.54 0 001.094 2.102 2.413 2.413 0 01-1.115-.316v.032c0 1.224.849 2.243 1.974 2.476-.363.1-.743.115-1.112.042.314 1.002 1.223 1.734 2.3 1.754A4.857 4.857 0 010 9.866 6.83 6.83 0 003.774 11c4.528 0 7.005-3.847 7.005-7.182 0-.11-.003-.22-.007-.327.482-.358.898-.8 1.228-1.308z"></path></svg></div></a><a href="https://www.facebook.com/coquiai" aria-label="Coqui" data-garden-id="buttons.anchor" data-garden-version="8.31.0" class="sc-eHgmQL sc-cvbbAY bINUcJ"><div class="Footer___StyledDiv4-owx86q-7 cyVuQe"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" class="Footer___StyledFacebookIcon-owx86q-8 dAyBhk"><path fill="currentColor" d="M6 0a6 6 0 01.813 11.945V7.63h1.552l.244-1.585H6.812v-.867c0-.658.214-1.242.827-1.242h.985V2.55c-.173-.024-.538-.075-1.23-.075-1.444 0-2.29.767-2.29 2.513v1.055H3.618v1.585h1.484v4.304A6.001 6.001 0 016 0z"></path></svg></div></a><a href="https://www.linkedin.com/company/coqui-ai" aria-label="Coqui" data-garden-id="buttons.anchor" data-garden-version="8.31.0" class="sc-eHgmQL sc-cvbbAY bINUcJ"><div class="Footer___StyledDiv5-owx86q-9 jUlaGX"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12" focusable="false" role="presentation" class="Footer___StyledLinkedInIcon-owx86q-10 jJClhf"><path fill="currentColor" d="M10.8 0A1.2 1.2 0 0112 1.2v9.6a1.2 1.2 0 01-1.2 1.2H1.2A1.2 1.2 0 010 10.8V1.2A1.2 1.2 0 011.2 0h9.6zM8.09 4.356a1.87 1.87 0 00-1.598.792l-.085.133h-.024v-.783H4.676v5.727h1.778V7.392c0-.747.142-1.47 1.068-1.47.913 0 .925.854.925 1.518v2.785h1.778V7.084l-.005-.325c-.05-1.38-.456-2.403-2.13-2.403zm-4.531.142h-1.78v5.727h1.78V4.498zm-.89-2.846a1.032 1.032 0 100 2.064 1.032 1.032 0 000-2.064z"></path></svg></div></a><a href="https://gitter.im/coqui-ai/community" aria-label="Coqui" data-garden-id="buttons.anchor" data-garden-version="8.31.0" class="sc-eHgmQL sc-cvbbAY bINUcJ"><div class="Footer___StyledDiv6-owx86q-11 gXlMSe"><svg xmlns="http://www.w3.org/2000/svg" height="26" viewBox="0 0 26 26" focusable="false" role="presentation" class="Footer___StyledGitterIcon-owx86q-12 mZaVr"><path d="M5.2 1.04a.52.52 0 00-.52.52V15.6a.52.52 0 00.52.52h2.08a.52.52 0 00.52-.52V1.56a.52.52 0 00-.52-.52H5.2zm4.68 3.64a.52.52 0 00-.52.52v19.24a.52.52 0 00.52.52h2.08a.52.52 0 00.52-.52V5.2a.52.52 0 00-.52-.52H9.88zm4.68 0a.52.52 0 00-.52.52v19.24a.52.52 0 00.52.52h2.08a.52.52 0 00.52-.52V5.2a.52.52 0 00-.52-.52h-2.08zm4.68 0a.52.52 0 00-.52.52v10.4a.52.52 0 00.52.52h2.08a.52.52 0 00.52-.52V5.2a.52.52 0 00-.52-.52h-2.08z" fill="currentColor"></path></svg></div></a></div><div class="Footer___StyledDiv7-owx86q-13 gnMBjg"><div class="Footer___StyledDiv8-owx86q-14 iBbHyF"><a class="Footer__StyledFooterItem-owx86q-0 dJVuoI" href="/privacy">Privacy Policy</a></div><div class="Footer___StyledDiv9-owx86q-15 cVciVx"><a href="https://berlinlovesyou.com/" class="sc-eHgmQL sc-cvbbAY bINUcJ Footer__StyledFooterItem-owx86q-0 dJVuoI" data-garden-id="buttons.anchor" data-garden-version="8.31.0">Made with<!-- --> <span role="img" aria-label="heart">❤️</span> <!-- -->in Berlin!</a></div><div class="Footer___StyledDiv10-owx86q-16 dJejfB">© Coqui <!-- -->2022</div></div></div></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/blog/tts/solving-attention-problems-of-tts-models-with-double-decoder-consistency";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-08a9551b33692ba3ee75.js"],"app":["/app-ba1c07c82d50bc77ba8a.js"],"component---src-pages-404-tsx":["/component---src-pages-404-tsx-928728914659cc774d47.js"],"component---src-pages-about-tsx":["/component---src-pages-about-tsx-bd14553fdec0f3ef6f51.js"],"component---src-pages-blog-stt-a-journey-to-10-word-error-rate-mdx":["/component---src-pages-blog-stt-a-journey-to-10-word-error-rate-mdx-d5971715db960e8f68ed.js"],"component---src-pages-blog-stt-deepspeech-0-6-speech-to-text-engine-mdx":["/component---src-pages-blog-stt-deepspeech-0-6-speech-to-text-engine-mdx-d1e8be9c6932439d8e2f.js"],"component---src-pages-blog-stt-speech-recognition-deepspeech-mdx":["/component---src-pages-blog-stt-speech-recognition-deepspeech-mdx-a675e18b9131ae4e571f.js"],"component---src-pages-blog-tsx":["/component---src-pages-blog-tsx-0983255fd7c855a0642f.js"],"component---src-pages-blog-tts-african-languages-dataset-collaboration-mdx":["/component---src-pages-blog-tts-african-languages-dataset-collaboration-mdx-03429ad23b25b295f3c8.js"],"component---src-pages-blog-tts-gradual-training-with-tacotron-for-faster-convergence-mdx":["/component---src-pages-blog-tts-gradual-training-with-tacotron-for-faster-convergence-mdx-890c43da763381ad0b3c.js"],"component---src-pages-blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-mdx":["/component---src-pages-blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-mdx-68164f4687844e2e87b7.js"],"component---src-pages-blog-tts-two-methods-for-better-attention-in-tacotron-mdx":["/component---src-pages-blog-tts-two-methods-for-better-attention-in-tacotron-mdx-fb263f8322d6da1e53a0.js"],"component---src-pages-blog-tts-yourtts-zero-shot-text-synthesis-low-resource-languages-mdx":["/component---src-pages-blog-tts-yourtts-zero-shot-text-synthesis-low-resource-languages-mdx-23dce274fd867908a05e.js"],"component---src-pages-code-tsx":["/component---src-pages-code-tsx-5c3cb2b9d9012054a828.js"],"component---src-pages-data-tsx":["/component---src-pages-data-tsx-b75f8b0165228a67371e.js"],"component---src-pages-demo-tsx":["/component---src-pages-demo-tsx-3aabbe865895754b6896.js"],"component---src-pages-index-tsx":["/component---src-pages-index-tsx-b3c43aeaff22349d2b2a.js"],"component---src-pages-job-head-of-product-mdx":["/component---src-pages-job-head-of-product-mdx-c4ef4fe04edecb71dfa2.js"],"component---src-pages-job-senior-full-stack-engineer-mdx":["/component---src-pages-job-senior-full-stack-engineer-mdx-9895c031fece7167401c.js"],"component---src-pages-job-senior-mlops-deployment-engineer-mdx":["/component---src-pages-job-senior-mlops-deployment-engineer-mdx-d0579ac77276c3b08a30.js"],"component---src-pages-job-senior-mlops-provisioning-engineer-mdx":["/component---src-pages-job-senior-mlops-provisioning-engineer-mdx-864eb35e7a6160a52a8b.js"],"component---src-pages-job-senior-mlops-training-pipeline-engineer-mdx":["/component---src-pages-job-senior-mlops-training-pipeline-engineer-mdx-7e1462a64a4ccc6f0a6b.js"],"component---src-pages-job-senior-stt-deep-learning-engineer-mdx":["/component---src-pages-job-senior-stt-deep-learning-engineer-mdx-1256d0fdff0029a93ae1.js"],"component---src-pages-job-senior-ui-ux-engineer-mdx":["/component---src-pages-job-senior-ui-ux-engineer-mdx-391e55eb83433ab9c7da.js"],"component---src-pages-jobs-tsx":["/component---src-pages-jobs-tsx-eb08b7c27567bb2bb80b.js"],"component---src-pages-models-tsx":["/component---src-pages-models-tsx-431e6f1e2725e236636b.js"],"component---src-pages-newsletter-01-11-2021-mdx":["/component---src-pages-newsletter-01-11-2021-mdx-9717d9ed7b230143b5f2.js"],"component---src-pages-newsletter-02-08-2021-mdx":["/component---src-pages-newsletter-02-08-2021-mdx-1c2e4cd967eee5af884f.js"],"component---src-pages-newsletter-03-01-2022-mdx":["/component---src-pages-newsletter-03-01-2022-mdx-9b22f5e0a64f3da134c6.js"],"component---src-pages-newsletter-03-05-2021-mdx":["/component---src-pages-newsletter-03-05-2021-mdx-751561c34ecf66cd0f66.js"],"component---src-pages-newsletter-04-04-2022-mdx":["/component---src-pages-newsletter-04-04-2022-mdx-998795f4f9d99c9ed42a.js"],"component---src-pages-newsletter-04-10-2021-mdx":["/component---src-pages-newsletter-04-10-2021-mdx-886af58a050234002737.js"],"component---src-pages-newsletter-05-04-2021-mdx":["/component---src-pages-newsletter-05-04-2021-mdx-2510a5032a54897b0cce.js"],"component---src-pages-newsletter-05-07-2021-mdx":["/component---src-pages-newsletter-05-07-2021-mdx-b2d9ab9d0c1f1a702913.js"],"component---src-pages-newsletter-06-06-2021-mdx":["/component---src-pages-newsletter-06-06-2021-mdx-d6e94b634478fe718ec3.js"],"component---src-pages-newsletter-06-09-2021-mdx":["/component---src-pages-newsletter-06-09-2021-mdx-e8ade1fcf2b905582275.js"],"component---src-pages-newsletter-06-12-2021-mdx":["/component---src-pages-newsletter-06-12-2021-mdx-5b5de9974085b79e888a.js"],"component---src-pages-newsletter-07-02-2022-mdx":["/component---src-pages-newsletter-07-02-2022-mdx-c69c06835122ec86c8d8.js"],"component---src-pages-newsletter-07-03-2022-mdx":["/component---src-pages-newsletter-07-03-2022-mdx-1707ccbbb5dc63312da8.js"],"component---src-pages-ovh-tsx":["/component---src-pages-ovh-tsx-4213ff2b53eb7fcf5dad.js"],"component---src-pages-privacy-tsx":["/component---src-pages-privacy-tsx-83b9b18c1b6e95ffa4b7.js"],"component---src-templates-model-card-template-tsx":["/component---src-templates-model-card-template-tsx-a9a83f41eb61349f3c53.js"]};/*]]>*/</script><script src="/polyfill-08a9551b33692ba3ee75.js" nomodule=""></script><script src="/component---src-pages-blog-tts-solving-attention-problems-of-tts-models-with-double-decoder-consistency-mdx-68164f4687844e2e87b7.js" async=""></script><script src="/4826355d3ca8414095694303dcbe670927871743-7332373f0fb285e5a783.js" async=""></script><script src="/8e8edb548d22e34764571af9805b81c99598043e-936f40607f5ec89ed29e.js" async=""></script><script src="/3eec2993ab5d4a15f72d1d355f43d49bb49a1278-d2a992b53c28489b22a9.js" async=""></script><script src="/336ed6c8c131f2234f4a1a401bee3ac110638f3f-6c814d1dd0a279113390.js" async=""></script><script src="/1728d3ef4ec5b8879051de3c149660cde7777519-adb06edc144b2e1c7b86.js" async=""></script><script src="/3ffa677eea931b87951924687953dbca4dfdb241-e88e164e0a1f11a752e3.js" async=""></script><script src="/commons-3846d04eddd05b3df926.js" async=""></script><script src="/styles-e9d24b1846c7d6eb9685.js" async=""></script><script src="/app-ba1c07c82d50bc77ba8a.js" async=""></script><script src="/framework-25679e2f2e739b4a55ca.js" async=""></script><script src="/webpack-runtime-0d6cdee3981973b7f840.js" async=""></script></body></html>