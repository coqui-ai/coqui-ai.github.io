{"componentChunkName":"component---src-templates-model-card-template-tsx","path":"/spanish/jaco-assistant/v0.0.1","result":{"data":{"allGithubData":{"nodes":[{"data":{"repository":{"releases":{"nodes":[{"description":"# Ukrainian STT v0.4 (Yurii Paniv)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Yurii Paniv](https://github.com/robinhad) and released under the [voice-recognition-ua](https://github.com/robinhad/voice-recognition-ua) project.\r\n- Model language: Ukrainian / —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –º–æ–≤–∞ / `uk`\r\n- Model date: Accessed from [Github](https://github.com/robinhad/voice-recognition-ua/releases/tag/v0.4) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.4`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [voice-recognition-ua](https://github.com/robinhad/voice-recognition-ua)\r\n- License: CC BY-NC 4.0\r\n- Citation details: `@misc{ukrainian-stt-paniv,\r\nauthor = {Paniv,Yurii},\r\ntitle = {Ukrainian STT},\r\npublisher = {voice-recognition-ua},\r\njournal = {Github},\r\nhowpublished = {\\url{https://github.com/robinhad/voice-recognition-ua/releases/tag/v0.4}},\r\ncommit={1252a9e9337ceeff52fe9772dc8802f4337ccff3}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Ukrainian Language](https://en.wikipedia.org/wiki/Ukrainian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Github](https://github.com/robinhad/voice-recognition-ua/releases/tag/v0.4).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|57.2\\%|16.3\\%|\r\n\t\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.76`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model is trained on a total of 1,230 hours from the Ukrainian Dataset at Academic torrents and Common Voice Ukrainian 6.1.\r\n\r\n## Evaluation data\r\n\r\nThis model was tested on Common Voice Ukrainian 6.1.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be misused to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Ukrainian STT v0.4","tagName":"ukrainian/robinhad/v0.4","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/ukrainian/robinhad/v0.4/alphabet.txt","name":"alphabet.txt","size":378},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/ukrainian/robinhad/v0.4/LICENSE","name":"LICENSE","size":57},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/ukrainian/robinhad/v0.4/model.pbmm","name":"model.pbmm","size":188973767},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/ukrainian/robinhad/v0.4/model.tflite","name":"model.tflite","size":47346544},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/ukrainian/robinhad/v0.4/MODEL_CARD","name":"MODEL_CARD","size":4464},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/ukrainian/robinhad/v0.4/kenlm.scorer","name":"kenlm.scorer","size":420827024}]}},{"description":"# Welsh STT v21.03 (Dewi Bryn Jones)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Dewi Bryn Jones](https://github.com/DewiBrynJones) and released by the [Techiaith Language Technologies Unit](https://github.com/techiaith)\r\n- Model language: Welsh / Cymraeg / `cy`\r\n- Model date: Accessed from [Github](https://github.com/techiaith/docker-deepspeech-cy/releases/tag/21.03) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v21.03`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [docker-deepspeech-cy](https://github.com/techiaith/docker-deepspeech-cy)\r\n- License: MIT\r\n- Citation details: `@misc{welsh-stt-dewibrynjones,\r\nauthor = {Dewi Bryn Jones},\r\ntitle = {Docker DeepSpeech Cymraeg},\r\npublisher = {Techiaith},\r\njournal = {docker-deepspeech-cy},\r\nhowpublished = {\\url{https://github.com/techiaith/docker-deepspeech-cy/releases/tag/21.03}}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Welsh Language](https://en.wikipedia.org/wiki/Welsh_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nWord Error Rates and Character Error Rates were not reported for this model.\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.76`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThese models were trained with the Welsh dataset from the [Common Voice Corpus 6.1](https://commonvoice.mozilla.org/datasets) in addition to a small dataset of validated recordings donated by the first users of Bangor University's Language Technology Unit's online automatic transcription website service: [Trawsgrifiwr Ar-lein](https://trawsgrifiwr.techiaith.cymru). [Detailed release notes here](https://github.com/techiaith/docker-deepspeech-cy/releases/tag/21.03).\r\n\r\n## Evaluation data\r\n\r\nWith a language model, the Welsh STT model had a Word Error Rate of 11\\%. [Detailed release notes here](https://github.com/techiaith/docker-deepspeech-cy/releases/tag/21.03).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Welsh STT v21.03","tagName":"welsh/techiaith/v21.03","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/welsh/techiaith/v21.03/alphabet.txt","name":"alphabet.txt","size":100},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/welsh/techiaith/v21.03/LICENSE","name":"LICENSE","size":1067},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/welsh/techiaith/v21.03/model.pbmm","name":"model.pbmm","size":189039018},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/welsh/techiaith/v21.03/model.tflite","name":"model.tflite","size":47362992},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/welsh/techiaith/v21.03/MODEL_CARD","name":"MODEL_CARD","size":4723},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/welsh/techiaith/v21.03/techiaith_bangor_transcribe_21.03.scorer","name":"techiaith_bangor_transcribe_21.03.scorer","size":51242608}]}},{"description":"# Catalan STT v0.14.0 (Ciaran O'Reilly)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained and released by [Ciaran O'Reilly](https://github.com/ccoreilly)\r\n- Model language: Catalan / Catal√† / `ca`\r\n- Model date: Accessed from [Github](https://github.com/ccoreilly/deepspeech-catala/releases/tag/0.14.0) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.14.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [deepspeech-catala](https://github.com/ccoreilly/deepspeech-catala)\r\n- License: MIT\r\n- Citation details: `@misc{catalan-ccoreilly,\r\nauthor = {O'Reilly,Ciaran},\r\ntitle = {Deepspeech Catal√†},\r\npublisher = {Github},\r\njournal = {deepspeech-catala},\r\nhowpublished = {\\url{https://github.com/ccoreilly/deepspeech-catala}}\r\ncommit = {21da2be7cace9f87ac2445e51b82703d1fee0849}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Catalan Language](https://en.wikipedia.org/wiki/catalan_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Github](https://github.com/ccoreilly/deepspeech-catala#wer-del-dataset-test-de-cada-model).\r\n\r\n|Test Dataset | WER|\r\n|-------------|----|\r\n|Common Voice 6.1 + ParlamentParla | 13,29\\%|\r\n|Google Crowdsourced | 9,05\\%|\r\n|Sant Jordi | 18,84\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.71`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on [Catalan Common Voice 6.1](commonvoice.mozilla.org/datasets) and [ParlamentParla Clean](https://www.openslr.org/59/).\r\n\r\n## Evaluation data\r\n\r\nThe model was tested on [Catalan Common Voice 6.1](commonvoice.mozilla.org/datasets), [ParlamentParla Clean](https://www.openslr.org/59/), the [Catalan Google Crowdsourced Corpus](https://www.openslr.org/69/), and a private corpus ([Sant Jordi](https://github.com/ccoreilly/deepspeech-catala#corpus-emprats)).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Catalan STT v0.14.0","tagName":"catalan/ccoreilly/v0.14.0","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/catalan/ccoreilly/v0.14.0/LICENSE","name":"LICENSE","size":1067},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/catalan/ccoreilly/v0.14.0/model.pbmm","name":"model.pbmm","size":189014748},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/catalan/ccoreilly/v0.14.0/model.tflite","name":"model.tflite","size":47356808},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/catalan/ccoreilly/v0.14.0/alphabet.txt","name":"alphabet.txt","size":364},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/catalan/ccoreilly/v0.14.0/MODEL_CARD","name":"MODEL_CARD","size":4678},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/catalan/ccoreilly/v0.14.0/kenlm-aina-3-p10.scorer","name":"kenlm-aina-3-p10.scorer","size":304365616}]}},{"description":"# German STT v0.9.0 (Aashish Agarwal)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Aashish Agarwal](https://github.com/AASHISHAG) and released under the [deepspeech-german](https://github.com/AASHISHAG/deepspeech-german) project.\r\n- Model date: Accessed from [deepspeech-german](https://github.com/AASHISHAG/deepspeech-german) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.9.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [deepspeech-german](https://github.com/AASHISHAG/deepspeech-german)\r\n- License: Apache 2.0\r\n- Citation details: `@inproceedings{agarwal-zesch-2019-german,\r\nauthor = \"Aashish Agarwal and Torsten Zesch\",\r\ntitle = \"German End-to-end Speech Recognition based on DeepSpeech\",\r\nbooktitle = \"Preliminary proceedings of the 15th Conference on Natural Language Processing (KONVENS 2019): Long Papers\",\r\nyear = \"2019\",\r\naddress = \"Erlangen, Germany\",\r\npublisher = \"German Society for Computational Linguistics \\& Language Technology\",\r\npages = \"111--119\"\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [German Language](https://en.wikipedia.org/wiki/German_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nNo exact statistics on transcription accuracy, however, Word Error Rate was in the range of 10% to 20% on Mozilla and Tuda-De test set. Relevant discussion [here](https://github.com/AASHISHAG/deepspeech-german/issues/39#issuecomment-812829812).\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.69`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis German STT model was bootstrapped from a pre-trained English model, and fine-tuned to German via the following datasets: Common Voice 5.1 (750 hours) + SWC (248 hours) + MAILABS (233 hours) + Tuda-De (184 hours) + Voxforge (57 hours).\r\n\r\n## Evaluation data\r\n\r\nThis German STT model was evaluated on the following datasets: Common Voice 5.1 and Tuda-De.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"German STT v0.9.0","tagName":"german/AASHISHAG/v0.9.0","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/LICENSE","name":"LICENSE","size":11358},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/model.pbmm","name":"model.pbmm","size":188940932},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/model.tflite","name":"model.tflite","size":47338296},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/MODEL_CARD","name":"MODEL_CARD","size":4718},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/alphabet.txt","name":"alphabet.txt","size":338},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/de-aashishag-1-prune-kenlm.scorer","name":"de-aashishag-1-prune-kenlm.scorer","size":564845728}]}},{"description":"# Kinyarwanda STT v0.0.1 (Digital Umuganda)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally released by [Digital Umuganda](https://digitalumuganda.com/).\r\n- Model date: Accessed from [Github](https://github.com/Digital-Umuganda/Deepspeech-Kinyarwanda/tree/master/jan-8-2021-best-kinya-deepspeech) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [deepspeech-kinyarwanda](https://github.com/Digital-Umuganda/Deepspeech-Kinyarwanda)\r\n- License: MPL 2.0\r\n- Citation details: `@misc{deepspeech-kinyarwanda, author = {Digital Umuganda}, title = {Kinyarwanda STT}, publisher = {Digital Umuganda}, journal = {Github}, howpublished = {\\url{https://github.com/Digital-Umuganda/Deepspeech-Kinyarwanda}}, commit = {7dbf6705ee38d87138f3558a21f045c40b93f083}}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Kinyarwanda Language](https://en.wikipedia.org/wiki/Kinyarwanda_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|60.1\\%|23.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.69`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nTrain on approximately 1,200 hours from the Common Voice corpus.\r\n\r\n## Evaluation data\r\n\r\nEvaluated on the test set from the Common Voice corpus.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Kinyarwanda STT v0.0.1","tagName":"kinyarwanda/digital-umuganda/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kinyarwanda/digital-umuganda/v0.0.1/alphabet.txt","name":"alphabet.txt","size":329},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kinyarwanda/digital-umuganda/v0.0.1/LICENSE","name":"LICENSE","size":16726},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kinyarwanda/digital-umuganda/v0.0.1/model.pbmm","name":"model.pbmm","size":188916323},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kinyarwanda/digital-umuganda/v0.0.1/model.tflite","name":"model.tflite","size":47332120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kinyarwanda/digital-umuganda/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4160}]}},{"description":"# Spanish STT v0.0.1 (Jaco-Assistant)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [DANBER](https://gitlab.com/DANBER) and released under the [Jaco-Assistant](https://gitlab.com/Jaco-Assistant/Scribosermo) project.\r\n- Model date: Accessed from [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [scribosermo](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master/#old-experiments)\r\n- License: GNU Lesser General Public License\r\n- Citation details: `@misc{spanish-jaco,\r\nauthor = {DANBER},\r\ntitle = {Spanish Jaco-Assistant},\r\npublisher = {Jaco-Assistant},\r\njournal = {Gitlab},\r\nhowpublished = {\\url{https://gitlab.com/Jaco-Assistant/Scribosermo}},\r\ncommit = {dfc541d2}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Spanish Language](https://en.wikipedia.org/wiki/Spanish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|16.5\\%|7.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: CommonVoice + CssTen + LinguaLibre + Mailabs + Tatoeba + Voxforge.\r\n\r\n## Evaluation data\r\n\r\nThe model was tested on the Common Voice corpus.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Spanish STT v0.0.1","tagName":"spanish/jaco-assistant/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/alphabet.txt","name":"alphabet.txt","size":332},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/LICENSE","name":"LICENSE","size":7652},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/model.pbmm","name":"model.pbmm","size":188973740},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/model.tflite","name":"model.tflite","size":47346520},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4324},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/kenlm_es.scorer","name":"kenlm_es.scorer","size":279655392}]}},{"description":"# French STT v0.6 (commonvoice-fr)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained and released by the [commonvoice-fr](https://github.com/common-voice/commonvoice-fr) project\r\n- Model date: Accessed from [Github](https://github.com/common-voice/commonvoice-fr/releases/tag/fr-v0.6) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.6`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [commonvoice-fr](https://github.com/common-voice/commonvoice-fr)\r\n- License: MPL 2.0\r\n- Citation details: `@misc{commonvoice-fr,\r\nauthor = {commonvoice-fr Contributors},\r\ntitle = {Common Voice STT Model},\r\npublisher = {Github},\r\njournal = {GitHub repository},\r\nhowpublished = {\\url{https://github.com/common-voice/commonvoice-fr/releases/tag/fr-v0.6}},\r\ncommit = {5a0f61baf112620286b30319eb7000c57d8a20d0}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [French Language](https://en.wikipedia.org/wiki/French_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Github](https://github.com/common-voice/commonvoice-fr/releases/tag/fr-v0.6).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|African_Accented_French_test.csv|44.9\\%|24.2\\%|\r\n|M-AILABS|9.7\\%|2.7\\%|\r\n|trainingspeech|20.0\\%|6.0\\%|\r\n|Common Voice|30.1\\%|14.3\\%|\r\n|LinguaLibre|5.9\\%|1.8\\%|\r\n|CCPMF|48.7\\%|30.4\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis French STT model was trained on the following corpora:\r\n\r\n1. Lingua Libre (~40h)\r\n2. Common Voice FR (v2) (~490h, en autorisant jusqu'√† 32 duplicatas)\r\n3. Training Speech (~180h)\r\n4. African Accented French (~15h)\r\n5. M-AILABS French (~315h)\r\n6. Centre de Conf√©rence Pierre Mend√®s France (~300h)\r\n\r\nTotal : ~1340h\r\n\r\n## Evaluation data\r\n\r\nThe model was tested on the following corpora.\r\n\r\n1. Lingua Libre\r\n2. Common Voice FR (v2)\r\n3. Training Speech\r\n4. African Accented French\r\n5. M-AILABS French\r\n6. Centre de Conf√©rence Pierre Mend√®s France\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"French STT v0.6","tagName":"french/commonvoice-fr/v0.6","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/alphabet.txt","name":"alphabet.txt","size":248},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/LICENSE","name":"LICENSE","size":16726},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/model.pbmm","name":"model.pbmm","size":189408121},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/model.tflite","name":"model.tflite","size":47455616},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/MODEL_CARD","name":"MODEL_CARD","size":4818},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/fr-cvfr-2-prune-kenlm.scorer","name":"fr-cvfr-2-prune-kenlm.scorer","size":1007565072}]}},{"description":"# French STT v0.0.1 (Jaco-Assistant)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [DANBER](https://gitlab.com/DANBER) and released under the [Jaco-Assistant](https://gitlab.com/Jaco-Assistant) project.\r\n- Model date: Accessed from [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [scribosermo](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master/#old-experiments)\r\n- License: GNU Lesser General Public License\r\n- Citation details: `@misc{french-jaco,\r\nauthor = {DANBER},\r\ntitle = {French DeepSpeech for Jaco-Assistant},\r\npublisher = {Jaco-Assistant},\r\njournal = {Gitlab},\r\nhowpublished = {\\url{https://gitlab.com/Jaco-Assistant/Scribosermo}},\r\ncommit = {dfc541d2}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [French Language](https://en.wikipedia.org/wiki/French_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|19.5\\%|9.2\\%|\r\n\t\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis French STT model was trained on approximately 787 hours of Common Voice + CssTen + LinguaLibre + Mailabs + Tatoeba + Voxforge. [Read more about training here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Evaluation data\r\n\r\nThis French STT model was tested on approximately 25 hours of Common Voice. [Read more about testing here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"French STT v0.0.1","tagName":"french/jaco-assistant/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/jaco-assistant/v0.0.1/alphabet.txt","name":"alphabet.txt","size":329},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/jaco-assistant/v0.0.1/LICENSE","name":"LICENSE","size":7652},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/jaco-assistant/v0.0.1/model.pbmm","name":"model.pbmm","size":189047557},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/jaco-assistant/v0.0.1/model.tflite","name":"model.tflite","size":47365040},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/jaco-assistant/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4586},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/jaco-assistant/v0.0.1/kenlm_fr.scorer","name":"kenlm_fr.scorer","size":254972864}]}},{"description":"# German STT v0.0.1 (Jaco-Assistant)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [DANBER](https://gitlab.com/DANBER) and released under the [Jaco-Assistant](https://gitlab.com/Jaco-Assistant) project.\r\n- Model date: Accessed from [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [scribosermo](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master/#old-experiments)\r\n- License: GNU Lesser General Public License\r\n- Citation details: `@misc{german-jaco,\r\nauthor = {DANBER},\r\ntitle = {German STT for Jaco-Assistant},\r\npublisher = {Jaco-Assistant},\r\njournal = {Gitlab},\r\nhowpublished = {\\url{https://gitlab.com/Jaco-Assistant/Scribosermo}},\r\ncommit = {dfc541d2}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [German Language](https://en.wikipedia.org/wiki/German_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [Jaco-Assistant](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|12.8\\%|5.6\\%|\r\n|Tuda | 24.6\\%| 10.1\\%|\r\n|CommonVoice + Tuda + Voxforge |16.2\\%|6.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: BasFormtask, BasSprecherinnen, Common Voice, CssTen, Gothic, LinguaLibre, Kurzgesagt, Mailabs, MussteWissen, PulsReportage, SWC, Tatoeba, TerraX, Tuda, Voxforge, YKollektiv, ZamiaSpeech, and Common Voice Single Words. Read more about training [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Tuda and Common Voice. Read more about evaluation [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"German STT v0.0.1","tagName":"german/jaco-assistant/v0.0.1","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/jaco-assistant/v0.0.1/LICENSE","name":"LICENSE","size":7652},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/jaco-assistant/v0.0.1/model.pbmm","name":"model.pbmm","size":188916323},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/jaco-assistant/v0.0.1/model.tflite","name":"model.tflite","size":47332112},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/jaco-assistant/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4788},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/jaco-assistant/v0.0.1/alphabet.txt","name":"alphabet.txt","size":329},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/jaco-assistant/v0.0.1/kenlm_de.scorer","name":"kenlm_de.scorer","size":279121440}]}},{"description":"# Italian STT v0.0.1 (Jaco-Assistant)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [DANBER](https://gitlab.com/DANBER) and released under the [Jaco-Assistant](https://gitlab.com/Jaco-Assistant/Scribosermo) project.\r\n- Model date: Accessed from [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [scribosermo](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master/#old-experiments)\r\n- License: GNU Lesser General Public License\r\n- Citation details: `@misc{italian-jaco,\r\nauthor = {DANBER},\r\ntitle = {Italian Jaco-Assistant},\r\npublisher = {Jaco-Assistant},\r\njournal = {Gitlab},\r\nhowpublished = {\\url{https://gitlab.com/Jaco-Assistant/Scribosermo}},\r\ncommit = {dfc541d2}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Italian Language](https://en.wikipedia.org/wiki/Italian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|24.9\\%|9.4\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on approximately ~257 hours from the following corpora: Common Voice + LinguaLibre + Mailabs + Voxforge. Read more about training [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Evaluation data\r\n\r\nThe model was tested on approximately ~21 hours from Common Voice. Read more about testing [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Italian STT v0.0.1","tagName":"italian/jaco-assistant/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/jaco-assistant/v0.0.1/alphabet.txt","name":"alphabet.txt","size":329},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/jaco-assistant/v0.0.1/LICENSE","name":"LICENSE","size":7652},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/jaco-assistant/v0.0.1/model.pbmm","name":"model.pbmm","size":188916323},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/jaco-assistant/v0.0.1/model.tflite","name":"model.tflite","size":47332112},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/jaco-assistant/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4573},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/jaco-assistant/v0.0.1/kenlm_it.scorer","name":"kenlm_it.scorer","size":7746880}]}},{"description":"# Polish STT v0.0.1 (Jaco-Assistant)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [DANBER](https://gitlab.com/DANBER) and released under the [Jaco-Assistant](https://gitlab.com/Jaco-Assistant) project.\r\n- Model date: Accessed from [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [scribosermo](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master/#old-experiments)\r\n- License: GNU Lesser General Public License\r\n- Citation details: `@misc{polish-jaco,\r\nauthor = {DANBER},\r\ntitle = {Polish Jaco-Assistant},\r\npublisher = {Jaco-Assistant},\r\njournal = {Gitlab},\r\nhowpublished = {\\url{https://gitlab.com/Jaco-Assistant/Scribosermo}},\r\ncommit = {dfc541d2}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Polish Language](https://en.wikipedia.org/wiki/Polish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [Jaco-Assistant](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|3.4\\%|2.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: Common Voice + LinguaLibre + Mailabs. Read more about training [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on the Common Voice corpus. Read more about evaluation [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Polish STT v0.0.1","tagName":"polish/jaco-assistant/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/polish/jaco-assistant/v0.0.1/alphabet.txt","name":"alphabet.txt","size":354},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/polish/jaco-assistant/v0.0.1/LICENSE","name":"LICENSE","size":7652},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/polish/jaco-assistant/v0.0.1/model.pbmm","name":"model.pbmm","size":188981942},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/polish/jaco-assistant/v0.0.1/model.tflite","name":"model.tflite","size":47348576},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/polish/jaco-assistant/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4531},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/polish/jaco-assistant/v0.0.1/kenlm_pl.scorer","name":"kenlm_pl.scorer","size":4856464}]}},{"description":"# Komi-Zyrian STT v0.0.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Nils Hjortn√¶s](https://github.com/hjortnaes) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model date: March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@inproceedings{hjortnaes-etal-2020-towards,\r\ntitle = \"Towards a Speech Recognizer for {K}omi, an Endangered and Low-Resource Uralic Language\",\r\nauthor = \"Hjortnaes, Nils and Partanen, Niko and Rie{\\ss}ler, Michael and M. Tyers, Francis\",\r\nbooktitle = \"Proceedings of the Sixth International Workshop on Computational Linguistics of Uralic Languages\",\r\nmonth = \"1\",\r\nyear = \"2020\",\r\naddress = \"Wien, Austria\",\r\npublisher = \"Association for Computational Linguistics\",\r\nurl = \"https://www.aclweb.org/anthology/2020.iwclul-1.5\",\r\npages = \"31--37\"\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Komi-Zyryan Language](https://en.wikipedia.org/wiki/Komi_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported in the [paper](https://www.aclweb.org/anthology/2020.iwclul-1.5.pdf).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|70.9\\%|100\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.95`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: BasFormtask, BasSprecherinnen, Common Voice, CssTen, Gothic, LinguaLibre, Kurzgesagt, Mailabs, MussteWissen, PulsReportage, SWC, Tatoeba, TerraX, Tuda, Voxforge, YKollektiv, ZamiaSpeech, and Common Voice Single Words. Read more about training [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Tuda and Common Voice. Read more about evaluation [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Komi-Zyrian STT v0.0.1","tagName":"komi/itml/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/komi/itml/v0.0.1/alphabet.txt","name":"alphabet.txt","size":439},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/komi/itml/v0.0.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/komi/itml/v0.0.1/model.pbmm","name":"model.pbmm","size":189146005},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/komi/itml/v0.0.1/model.tflite","name":"model.tflite","size":47389768},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/komi/itml/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4837}]}},{"description":"# Chuvash STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Chuvash / –ß”ë–≤–∞—à–ª–∞ / `cv`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{chuvash-stt, author = {Tyers,Francis}, title = {Chuvash STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-CV-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Chuvash Language](https://en.wikipedia.org/wiki/Chuvash_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|97.0\\%|36.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Chuvash STT v0.1.0","tagName":"chuvash/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":115},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189006573},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.0/model.tflite","name":"model.tflite","size":47354776},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4129},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.0/Chuvash-digits-yesno.scorer","name":"Chuvash-digits-yesno.scorer","size":3232}]}},{"description":"# Basque STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Basque / Euskara / `eu`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{basque-stt, author = {Tyers,Francis}, title = {Basque STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-EU-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Basque Language](https://en.wikipedia.org/wiki/Basque_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/eu/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|81.0\\%|19.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Basque STT v0.1.0","tagName":"basque/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":57},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188916324},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.0/model.tflite","name":"model.tflite","size":47332120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4116}]}},{"description":"# Luganda STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Luganda / Lugdanda / `lg`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{luganda-stt, author = {Tyers,Francis}, title = {Luganda STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-LG-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Luganda Language](https://en.wikipedia.org/wiki/Luganda_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/lg/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|97.7\\%|33.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Luganda STT v0.1.0","tagName":"luganda/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":54},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188908121},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.0/model.tflite","name":"model.tflite","size":47330064},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4123}]}},{"description":"# Breton STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Breton / Brezhoneg / `br`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{breton-stt, author = {Tyers,Francis}, title = {Breton STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-BR-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Breton Language](https://en.wikipedia.org/wiki/Breton_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|94.9\\%|41.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Breton STT v0.1.0","tagName":"breton/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":82},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188990142},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.0/model.tflite","name":"model.tflite","size":47350640},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4118},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.0/Breton-digits-yesno.scorer","name":"Breton-digits-yesno.scorer","size":2976}]}},{"description":"# Dhivehi STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Dhivehi / ﬁãﬁ®ﬁàﬁ¨ﬁÄﬁ® / `dv`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{dhivehi-stt, author = {Tyers,Francis}, title = {Dhivehi STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-DV-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Dhivehi Language](https://en.wikipedia.org/wiki/Dhivehi_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|94.7\\%|33.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Dhivehi STT v0.1.0","tagName":"dhivehi/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":149},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189096796},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.0/model.tflite","name":"model.tflite","size":47377424},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4127}]}},{"description":"# Greek STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Greek / ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨ / `el`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{greek-stt, author = {Tyers,Francis}, title = {Greek STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-EL-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Greek Language](https://en.wikipedia.org/wiki/Greek_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|88.1\\%|36.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Greek STT v0.1.0","tagName":"greek/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":107},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188981968},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.0/model.tflite","name":"model.tflite","size":47348616},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4119},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.0/Greek-digits-yesno.scorer","name":"Greek-digits-yesno.scorer","size":3056}]}},{"description":"# Estonian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Estonian / Eesti / `et`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{estonian-stt, author = {Tyers,Francis}, title = {Estonian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-ET-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Estonian Language](https://en.wikipedia.org/wiki/Estonian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|92.2\\%|29.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Estonian STT v0.1.0","tagName":"estonian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":75},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188965538},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47344472},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4126},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.0/Estonian-digits-yesno.scorer","name":"Estonian-digits-yesno.scorer","size":2816}]}},{"description":"# Finnish STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Finnish / Suomi / `fi`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{finnish-stt, author = {Tyers,Francis}, title = {Finnish STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-FI-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Finnish Language](https://en.wikipedia.org/wiki/Finnish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|99.7\\%|39.1\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Finnish STT v0.1.0","tagName":"finnish/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":58},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188916325},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.0/model.tflite","name":"model.tflite","size":47332120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.0/Finnish-digits-yesno.scorer","name":"Finnish-digits-yesno.scorer","size":3424}]}},{"description":"# Frisian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Frisian / Frysk / `fy-NL`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{frisian-stt, author = {Tyers,Francis}, title = {Frisian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-FY_NL-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Chuvash Language](https://en.wikipedia.org/wiki/Chuvash_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|79.6.\\%|29.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Frisian STT v0.1.0","tagName":"frisian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":74},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188965537},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47344472},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4127},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.0/Frisian-digits-yesno.scorer","name":"Frisian-digits-yesno.scorer","size":2912}]}},{"description":"# Georgian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Georgian / ·É•·Éê·É†·Éó·É£·Éö·Éò ·Éî·Éú·Éê / `ka`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{georgian-stt, author = {Tyers,Francis}, title = {Georgian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-KA-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Georgian Language](https://en.wikipedia.org/wiki/Georgian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ka/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|98.1\\%|34.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Georgian STT v0.1.0","tagName":"georgian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":134},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188965597},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47344528},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4152}]}},{"description":"# Hakha Chin STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Hakha Chin / Hakha Lai / `cnh`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{hakhachin-stt, author = {Tyers,Francis}, title = {Hakha Chin STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-CNH-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Hakha Chin Language](https://en.wikipedia.org/wiki/Hakha_Chin_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cnh/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|77.8\\%|32.1\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Hakha Chin STT v0.1.0","tagName":"hakha-chin/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":56},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188908123},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.0/model.tflite","name":"model.tflite","size":47330064},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4144}]}},{"description":"# Hungarian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Hungarian / Magyar nyelv / `hu`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{hungarian-stt, author = {Tyers,Francis}, title = {Hungarian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-HU-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Hungarian Language](https://en.wikipedia.org/wiki/Chuvash_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/hu/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|89.2\\%|32.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Hungarian STT v0.1.0","tagName":"hungarian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":81},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188981942},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47348584},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4137},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.0/Hungarian-digits-yesno.scorer","name":"Hungarian-digits-yesno.scorer","size":2832}]}},{"description":"# Indonesian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Indonesian / Bahasa indonesia / `id`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{indonesian-stt, author = {Tyers,Francis}, title = {Indonesian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-ID-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Indonesian Language](https://en.wikipedia.org/wiki/Indonesian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/id/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|89.7\\%|30.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Indonesian STT v0.1.0","tagName":"indonesian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":52},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188899920},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47328008},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4149},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.0/Indonesian-digits-yesno.scorer","name":"Indonesian-digits-yesno.scorer","size":3088}]}},{"description":"# Irish STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Irish / Gaeilge / `ga-IE`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{irish-stt, author = {Tyers,Francis}, title = {Irish STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-GA_IE-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Irish Language](https://en.wikipedia.org/wiki/Irish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ga-IE/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|94.3\\%|57.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Irish STT v0.1.0","tagName":"irish/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":69},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188949134},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.0/model.tflite","name":"model.tflite","size":47340352},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4119},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.0/Irish-digits-yesno.scorer","name":"Irish-digits-yesno.scorer","size":2832}]}},{"description":"# Kyrgyz STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Kyrgyz / –ö—ã—Ä–≥—ã–∑—á–∞ / `ky`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{kyrgyz-stt, author = {Tyers,Francis}, title = {Kyrgyz STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-KY-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Kyrgyz Language](https://en.wikipedia.org/wiki/Kyrgyz_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ky/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|94.1\\%|36.8\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Kyrgyz STT v0.1.0","tagName":"kyrgyz/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":110},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188990170},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.0/model.tflite","name":"model.tflite","size":47350672},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4125}]}},{"description":"# Latvian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Latvian / Latvie≈°u valoda / `lv`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{latvian-stt, author = {Tyers,Francis}, title = {Latvian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-LV-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Latvian Language](https://en.wikipedia.org/wiki/Latvian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/lv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|88.3\\%|31.1\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Latvian STT v0.1.0","tagName":"latvian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":81},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188973743},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47346528},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4131},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.0/Latvian-digits-yesno.scorer","name":"Latvian-digits-yesno.scorer","size":3008}]}},{"description":"# Lithuanian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Lithuanian / Lietuvi≈≥ kalba / `lt`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{lithuanian-stt, author = {Tyers,Francis}, title = {Lithuanian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-LT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Lithuanian Language](https://en.wikipedia.org/wiki/Lithuanian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/lt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|98.9\\%|36.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Lithuanian STT v0.1.0","tagName":"lithuanian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":81},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188981942},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47348584},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4148},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.0/Lithuanian-digits-yesno.scorer","name":"Lithuanian-digits-yesno.scorer","size":3152}]}},{"description":"# Maltese STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Maltese / Malti / `mt`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{maltese-stt, author = {Tyers,Francis}, title = {Maltese STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-MT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Maltese Language](https://en.wikipedia.org/wiki/Maltese_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/mt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|93.6\\%|33.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Maltese STT v0.1.0","tagName":"maltese/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":85},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188998344},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.0/model.tflite","name":"model.tflite","size":47352704},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.0/Maltese-digits-yesno.scorer","name":"Maltese-digits-yesno.scorer","size":3152}]}},{"description":"# Mongolian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Mongolian / –ú–æ–Ω–≥–æ–ª —Ö—ç–ª / `mn`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{mongolian-stt, author = {Tyers,Francis}, title = {Mongolian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-MN-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Mongolian Language](https://en.wikipedia.org/wiki/Mongolian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/mn/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|96.7\\%|45.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Mongolian STT v0.1.0","tagName":"mongolian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":104},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188973766},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47346552},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4146},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.0/Mongolian-digits-yesno.scorer","name":"Mongolian-digits-yesno.scorer","size":2944}]}},{"description":"# Odia STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Odia / ‡¨ì‡¨°‡¨º‡¨ø‡¨Ü / `or`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{odia-stt, author = {Tyers,Francis}, title = {Odia STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-OR-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Odia Language](https://en.wikipedia.org/wiki/Odia_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/or/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|98.9\\%|55.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Odia STT v0.1.0","tagName":"odia/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":326},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189359341},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.0/model.tflite","name":"model.tflite","size":47443360},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4112},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.0/Odia-digits-yesno.scorer","name":"Odia-digits-yesno.scorer","size":2688}]}},{"description":"# Portuguese STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Portuguese / Portugu√™s / `pt`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{portuguese-stt, author = {Tyers,Francis}, title = {Portuguese STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-PT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Portuguese Language](https://en.wikipedia.org/wiki/Portuguese_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/pt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|84.1\\%|32.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Portuguese STT v0.1.0","tagName":"portuguese/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":97},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189031152},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.0/model.tflite","name":"model.tflite","size":47360936},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4143},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.0/pt-itml-0-prune-kenlm.scorer","name":"pt-itml-0-prune-kenlm.scorer","size":242241040}]}},{"description":"# English STT v0.9.3 (Coqui)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Maintained by [Coqui](https://coqui.ai/).\r\n- Model language: English / English / `en`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.9.3`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: MPL\r\n- Citation details: `@techreport{english-stt, author = {Coqui}, title = {English STT 0.9.3}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-EN-0.9.3} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [English Language](https://en.wikipedia.org/wiki/English_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nMore detail on model training and evaluation can be found in the [release notes](https://github.com/coqui-ai/STT/releases/tag/v0.9.3).\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `0.66`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: Fisher, LibriSpeech, Switchboard, Common Voice English, and 1,700 hours of transcribed NPR (WAMU) radio shows explicitly licensed to use as training corpora.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on the LibriSpeech clean dev corpus as validation data, and LibriSpeech clean test as testing data.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"English STT v0.9.3","tagName":"english/coqui/v0.9.3","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v0.9.3/alphabet.txt","name":"alphabet.txt","size":329},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v0.9.3/LICENSE","name":"LICENSE","size":16725},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v0.9.3/model.pbmm","name":"model.pbmm","size":188915987},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v0.9.3/model.tflite","name":"model.tflite","size":47331784},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v0.9.3/MODEL_CARD","name":"MODEL_CARD","size":4139},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v0.9.3/coqui-stt-0.9.3-models.scorer","name":"coqui-stt-0.9.3-models.scorer","size":953363776}]}},{"description":"# Romanian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Romanian / Rom√¢ne»ôte / `ro`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{romanian-stt, author = {Tyers,Francis}, title = {Romanian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-RO-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Romanian Language](https://en.wikipedia.org/wiki/Romanian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ro/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|92.9\\%|34.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Romanian STT v0.1.0","tagName":"romanian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":69},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188949134},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47340352},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4132},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.0/Romanian-digits-yesno.scorer","name":"Romanian-digits-yesno.scorer","size":2832}]}},{"description":"# Sakha STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Sakha / –°–∞—Ö–∞ —Ç—ã–ª–∞ / `sah`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{sakha-stt, author = {Tyers,Francis}, title = {Sakha STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-SAH-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Sakha Language](https://en.wikipedia.org/wiki/Sakha_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/sah/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|96.3\\%|37.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Sakha STT v0.1.0","tagName":"sakha/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":110},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188990170},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.0/model.tflite","name":"model.tflite","size":47350672},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4123}]}},{"description":"# Slovenian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Slovenian / Sloven≈°ƒçina / `sl`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{slovenian-stt, author = {Tyers,Francis}, title = {Slovenian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-SL-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Slovenian Language](https://en.wikipedia.org/wiki/Slovenian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/sl/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|90.2\\%|31.1\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Slovenian STT v0.1.0","tagName":"slovenian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":61},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188924528},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47334184},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4140},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.0/Slovenian-digits-yesno.scorer","name":"Slovenian-digits-yesno.scorer","size":2624}]}},{"description":"# Czech STT v0.1.0 (Vojtƒõch Dr√°bek)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Vojtƒõch Dr√°bek](https://github.com/comodoro).\r\n- Model language: Czech / ƒçe≈°tina / `cs`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: CC-BY-NC\r\n- Citation details: `@techreport{chuvash-stt, author = {Dr√°bek,Vojtƒõch}, title = {Czech STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CS-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Czech Language](https://en.wikipedia.org/wiki/Czech_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nMore information reported on [Github](https://github.com/comodoro/deepspeech-cs/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|44.6\\%|11.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora:\r\n\r\n1. Vystadial 2016 ‚Äì Czech data\r\n2. OVM ‚Äì Ot√°zky V√°clava Moravce\r\n3. Czech Parliament Meetings\r\n4. Large Corpus of Czech Parliament Plenary Hearings\r\n5. Common Voice Czech\r\n6. Some private recordings and parts of audioboooks\r\n\r\n## Evaluation data\r\n\r\nThe model was evaluated on Common Voice Czech.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Comodoro STT v0.1.0","tagName":"czech/comodoro/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.1.0/alphabet.txt","name":"alphabet.txt","size":114},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.1.0/LICENSE","name":"LICENSE","size":57},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.1.0/model.pbmm","name":"model.pbmm","size":189088562},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.1.0/model.tflite","name":"model.tflite","size":47375328},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4181}]}},{"description":"# Italian STT 2020.8.7 (Mozilla Italia)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained and released by the [Mozilla Italia](https://github.com/MozillaItalia) Community.\r\n- Model language: Italian / italiano / `it`\r\n- Model date: August 7, 2020\r\n- Model type: `Speech-to-Text`\r\n- Model version: `2020.8.7`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: CC0\r\n- Citation details: `@techreport{italian-stt, author = {Mozilla Italia}, title = {Italian STT 2020.8.7}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-IT-2020.8.7} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Italian Language](https://en.wikipedia.org/wiki/Italian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported by [Mozilla Italia](https://github.com/MozillaItalia/DeepSpeech-Italian-Model/releases/tag/2020.08.07) (the transfer learning model).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|28.7\\%|11.8\\%|\r\n|M-AILABS|15.0\\%|4.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `1.0`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on:\r\n\r\n1. ~130 hours of the Common Voice Italian dataset\r\n2. ~127 hours of the M-AILABS Italian dataset\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice and M-AILABS.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Italian STT 2020.8.7","tagName":"italian/mozillaitalia/2020.8.7","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/alphabet.txt","name":"alphabet.txt","size":86},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/LICENSE","name":"LICENSE","size":60},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/model.pbmm","name":"model.pbmm","size":188998006},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/model.tflite","name":"model.tflite","size":47352376},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/MODEL_CARD","name":"MODEL_CARD","size":4230},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/it-mzit-1-prune-kenlm.scorer","name":"it-mzit-1-prune-kenlm.scorer","size":390117712}]}},{"description":"# Breton STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Breton / Brezhoneg / `br`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{breton-stt, author = {Tyers,Francis}, title = {Breton STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-BR-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Breton Language](https://en.wikipedia.org/wiki/Breton_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/br/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|89.1\\%|37.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Breton STT v0.1.1","tagName":"breton/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":82},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188990142},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.1/model.tflite","name":"model.tflite","size":47350632},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4119},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.1/Breton-digits-yesno.scorer","name":"Breton-digits-yesno.scorer","size":2976}]}},{"description":"# Chuvash STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Chuvash / –ß”ë–≤–∞—à–ª–∞ / `cv`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{chuvash-stt, author = {Tyers,Francis}, title = {Chuvash STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-CV-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Chuvash Language](https://en.wikipedia.org/wiki/Chuvash_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|95.4\\%|33.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Chuvash STT v0.1.1","tagName":"chuvash/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":115},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":189006573},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.1/model.tflite","name":"model.tflite","size":47354776},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4130},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.1/Chuvash-digits-yesno.scorer","name":"Chuvash-digits-yesno.scorer","size":3232}]}},{"description":"# Dhivehi STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Dhivehi / ﬁãﬁ®ﬁàﬁ¨ﬁÄﬁ® / `dv`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{dhivehi-stt, author = {Tyers,Francis}, title = {Dhivehi STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-DV-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Dhivehi Language](https://en.wikipedia.org/wiki/Dhivehi_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|91.2\\%|29.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Dhivehi STT v0.1.1","tagName":"dhivehi/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":149},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":189096796},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.1/model.tflite","name":"model.tflite","size":47377416},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4128}]}},{"description":"# Estonian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Estonian / Eesti / `et`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{estonian-stt, author = {Tyers,Francis}, title = {Estonian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-ET-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Estonian Language](https://en.wikipedia.org/wiki/Estonian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|89.1\\%|27.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Estonian STT v0.1.1","tagName":"estonian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":75},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188965538},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47344464},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4127},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.1/Estonian-digits-yesno.scorer","name":"Estonian-digits-yesno.scorer","size":2816}]}},{"description":"# Finnish STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Finnish / Suomi / `fi`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{finnish-stt, author = {Tyers,Francis}, title = {Finnish STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-FI-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Finnish Language](https://en.wikipedia.org/wiki/Finnish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|96.6\\%|30.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Finnish STT v0.1.1","tagName":"finnish/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":58},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188916325},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.1/model.tflite","name":"model.tflite","size":47332112},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4121},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.1/Finnish-digits-yesno.scorer","name":"Finnish-digits-yesno.scorer","size":3424}]}},{"description":"# Frisian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Frisian / Frysk / `fy-NL`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{frisian-stt, author = {Tyers,Francis}, title = {Frisian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-FY_NL-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Frisian Language](https://en.wikipedia.org/wiki/Frisian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|74.0\\%|26.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Frisian STT v0.1.1","tagName":"frisian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":74},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188965537},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47344464},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4127},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.1/Frisian-digits-yesno.scorer","name":"Frisian-digits-yesno.scorer","size":2912}]}},{"description":"# Georgian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Georgian / ·É•·Éê·É†·Éó·É£·Éö·Éò ·Éî·Éú·Éê / `ka`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{georgian-stt, author = {Tyers,Francis}, title = {Georgian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-KA-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Georgian Language](https://en.wikipedia.org/wiki/Georgian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ka/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|95.8\\%|31.1\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Georgian STT v0.1.1","tagName":"georgian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":134},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188965597},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47344520},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4153},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.1/Georgian-digits-yesno.scorer","name":"Georgian-digits-yesno.scorer","size":2768}]}},{"description":"# Greek STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Greek / ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨ / `el`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{greek-stt, author = {Tyers,Francis}, title = {Greek STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-EL-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Greek Language](https://en.wikipedia.org/wiki/Greek_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|80.2\\%|31.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Greek STT v0.1.1","tagName":"greek/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":107},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188981968},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.1/model.tflite","name":"model.tflite","size":47348608},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.1/Greek-digits-yesno.scorer","name":"Greek-digits-yesno.scorer","size":3056}]}},{"description":"# Hakha Chin STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Hakha Chin / Hakha Lai / `cnh`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{hakhachin-stt, author = {Tyers,Francis}, title = {Hakha Chin STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-CNH-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Hakha Chin Language](https://en.wikipedia.org/wiki/Hakha_Chin_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cnh/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|67.4\\%|26.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Hakha Chin STT v0.1.1","tagName":"hakha-chin/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":56},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188908123},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.1/model.tflite","name":"model.tflite","size":47330056},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4145}]}},{"description":"# Hungarian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Hungarian / Magyar nyelv / `hu`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{hungarian-stt, author = {Tyers,Francis}, title = {Hungarian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-HU-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Hungarian Language](https://en.wikipedia.org/wiki/Chuvash_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/hu/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|87.1\\%|31.8\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Hungarian STT v0.1.1","tagName":"hungarian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":81},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188981942},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47348576},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4138},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.1/Hungarian-digits-yesno.scorer","name":"Hungarian-digits-yesno.scorer","size":2832}]}},{"description":"# Indonesian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Indonesian / Bahasa indonesia / `id`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{indonesian-stt, author = {Tyers,Francis}, title = {Indonesian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-ID-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Indonesian Language](https://en.wikipedia.org/wiki/Indonesian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/id/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|80.1\\%|25.8\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Indonesian STT v0.1.1","tagName":"indonesian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":52},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188899920},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47328000},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4150},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.1/Indonesian-digits-yesno.scorer","name":"Indonesian-digits-yesno.scorer","size":3088}]}},{"description":"# Irish STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Irish / Gaeilge / `ga-IE`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{irish-stt, author = {Tyers,Francis}, title = {Irish STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-GA_IE-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Irish Language](https://en.wikipedia.org/wiki/Irish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ga-IE/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|86.9\\%|40.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Irish STT v0.1.1","tagName":"irish/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":69},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188949134},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.1/model.tflite","name":"model.tflite","size":47340344},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.1/Irish-digits-yesno.scorer","name":"Irish-digits-yesno.scorer","size":2832}]}},{"description":"# Kyrgyz STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Kyrgyz / –ö—ã—Ä–≥—ã–∑—á–∞ / `ky`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{kyrgyz-stt, author = {Tyers,Francis}, title = {Kyrgyz STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-KY-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Kyrgyz Language](https://en.wikipedia.org/wiki/Kyrgyz_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ky/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|87.1\\%|30.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Kyrgyz STT v0.1.1","tagName":"kyrgyz/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":110},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188990170},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.1/model.tflite","name":"model.tflite","size":47350664},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4126},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.1/Kyrgyz-digits-yesno.scorer","name":"Kyrgyz-digits-yesno.scorer","size":2912}]}},{"description":"# Latvian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Latvian / Latvie≈°u valoda / `lv`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{latvian-stt, author = {Tyers,Francis}, title = {Latvian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-LV-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Latvian Language](https://en.wikipedia.org/wiki/Latvian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/lv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|82.8\\%|28.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Latvian STT v0.1.1","tagName":"latvian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":81},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188973743},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47346520},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4132},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.1/Latvian-digits-yesno.scorer","name":"Latvian-digits-yesno.scorer","size":3008}]}},{"description":"# Lithuanian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Lithuanian / Lietuvi≈≥ kalba / `lt`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{lithuanian-stt, author = {Tyers,Francis}, title = {Lithuanian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-LT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Lithuanian Language](https://en.wikipedia.org/wiki/Lithuanian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/lt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|94.6\\%|31.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Lithuanian STT v0.1.1","tagName":"lithuanian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":81},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188981942},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47348576},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4149},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.1/Lithuanian-digits-yesno.scorer","name":"Lithuanian-digits-yesno.scorer","size":3152}]}},{"description":"# Luganda STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Luganda / Lugdanda / `lg`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{luganda-stt, author = {Tyers,Francis}, title = {Luganda STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-LG-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Luganda Language](https://en.wikipedia.org/wiki/Luganda_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/lg/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|93.1\\%|30.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Luganda STT v0.1.1","tagName":"luganda/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":54},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188908121},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.1/model.tflite","name":"model.tflite","size":47330056},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4124},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.1/Luganda-digits-yesno.scorer","name":"Luganda-digits-yesno.scorer","size":3232}]}},{"description":"# Maltese STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Maltese / Malti / `mt`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{maltese-stt, author = {Tyers,Francis}, title = {Maltese STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-MT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Maltese Language](https://en.wikipedia.org/wiki/Maltese_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/mt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|86.4\\%|27.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Maltese STT v0.1.1","tagName":"maltese/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":85},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188998344},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.1/model.tflite","name":"model.tflite","size":47352696},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.1/Maltese-digits-yesno.scorer","name":"Maltese-digits-yesno.scorer","size":3152}]}},{"description":"# Mongolian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Mongolian / –ú–æ–Ω–≥–æ–ª —Ö—ç–ª / `mn`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{mongolian-stt, author = {Tyers,Francis}, title = {Mongolian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-MN-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Mongolian Language](https://en.wikipedia.org/wiki/Mongolian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/mn/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|90.8\\%|38.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Mongolian STT v0.1.1","tagName":"mongolian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":104},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188973766},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47346544},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4147},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.1/Mongolian-digits-yesno.scorer","name":"Mongolian-digits-yesno.scorer","size":2944}]}},{"description":"# Odia STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Odia / ‡¨ì‡¨°‡¨º‡¨ø‡¨Ü / `or`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{odia-stt, author = {Tyers,Francis}, title = {Odia STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-OR-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Odia Language](https://en.wikipedia.org/wiki/Odia_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/or/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|95.0\\%|35.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Odia STT v0.1.1","tagName":"odia/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":326},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":189359341},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.1/model.tflite","name":"model.tflite","size":47443352},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4113},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.1/Odia-digits-yesno.scorer","name":"Odia-digits-yesno.scorer","size":2688}]}},{"description":"# Portuguese STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Portuguese / Portugu√™s / `pt`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{portuguese-stt, author = {Tyers,Francis}, title = {Portuguese STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-PT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Portuguese Language](https://en.wikipedia.org/wiki/Portuguese_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/pt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|73.2\\%|26.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Portuguese STT v0.1.1","tagName":"portuguese/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":97},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":189031152},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/model.tflite","name":"model.tflite","size":47360928},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4144},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/pt-itml-0-prune-kenlm.scorer","name":"pt-itml-0-prune-kenlm.scorer","size":242241040}]}},{"description":"# Romanian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Romanian / Rom√¢ne»ôte / `ro`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{romanian-stt, author = {Tyers,Francis}, title = {Romanian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-RO-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Romanian Language](https://en.wikipedia.org/wiki/Romanian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ro/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|85.3\\%|29.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Romanian STT v0.1.1","tagName":"romanian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":69},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188949134},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47340344},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4133},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.1/Romanian-digits-yesno.scorer","name":"Romanian-digits-yesno.scorer","size":2832}]}},{"description":"# Sakha STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Sakha / –°–∞—Ö–∞ —Ç—ã–ª–∞ / `sah`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{sakha-stt, author = {Tyers,Francis}, title = {Sakha STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-SAH-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Sakha Language](https://en.wikipedia.org/wiki/Sakha_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/sah/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|94.5\\%|36.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Sakha STT v0.1.1","tagName":"sakha/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":110},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188990170},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.1/model.tflite","name":"model.tflite","size":47350664},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4124}]}},{"description":"# Slovenian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Slovenian / Sloven≈°ƒçina / `sl`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{slovenian-stt, author = {Tyers,Francis}, title = {Slovenian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-SL-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Slovenian Language](https://en.wikipedia.org/wiki/Slovenian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/sl/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|82.4\\%|26.8\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Slovenian STT v0.1.1","tagName":"slovenian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":61},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188924528},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47334176},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4141},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.1/Slovenian-digits-yesno.scorer","name":"Slovenian-digits-yesno.scorer","size":2624}]}},{"description":"# Tamil STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Tamil / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç / `ta`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{tamil-stt, author = {Tyers,Francis}, title = {Tamil STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-TA-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Tamil Language](https://en.wikipedia.org/wiki/Tamil_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ta/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|99.9\\%|46.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Tamil STT v0.1.0","tagName":"tamil/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tamil/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":194},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tamil/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tamil/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189088642},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tamil/itml/v0.1.0/model.tflite","name":"model.tflite","size":47375408},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tamil/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4119},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tamil/itml/v0.1.0/Tamil-digits-yesno.scorer","name":"Tamil-digits-yesno.scorer","size":3088}]}},{"description":"# Tatar STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Tatar / –¢–∞—Ç–∞—Ä—á–∞ / `tt`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{tatar-stt, author = {Tyers,Francis}, title = {Tatar STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-TT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Tatar Language](https://en.wikipedia.org/wiki/Tatar_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/tt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|85.8\\%|31.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Tatar STT v0.1.0","tagName":"tatar/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tatar/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":119},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tatar/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tatar/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189014776},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tatar/itml/v0.1.0/model.tflite","name":"model.tflite","size":47356840},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tatar/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4118},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tatar/itml/v0.1.0/Tatar-digits-yesno.scorer","name":"Tatar-digits-yesno.scorer","size":2912}]}},{"description":"# Thai STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Thai / ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ / `th`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{thai-stt, author = {Tyers,Francis}, title = {Thai STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-TH-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Thai Language](https://en.wikipedia.org/wiki/Thai_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ta/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|100\\%|36.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Thai STT v0.1.0","tagName":"thai/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/thai/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":270},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/thai/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/thai/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189244499},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/thai/itml/v0.1.0/model.tflite","name":"model.tflite","size":47414528},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/thai/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4118}]}},{"description":"# Turkish STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Turkish / T√ºrk√ße / `tr`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{turkish-stt, author = {Tyers,Francis}, title = {Turkish STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-TR-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Turkish Language](https://en.wikipedia.org/wiki/Turkish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/tr/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|89.3\\%|30.8\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Turkish STT v0.1.0","tagName":"turkish/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/turkish/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":75},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/turkish/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/turkish/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188965538},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/turkish/itml/v0.1.0/model.tflite","name":"model.tflite","size":47344464},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/turkish/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4124},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/turkish/itml/v0.1.0/Turkish-digits-yesno.scorer","name":"Turkish-digits-yesno.scorer","size":2912}]}},{"description":"# Basque STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Basque / Euskara / `eu`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{basque-stt, author = {Tyers,Francis}, title = {Basque STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-EU-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Basque Language](https://en.wikipedia.org/wiki/Basque_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/eu/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|68.7\\%|15.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Basque STT v0.1.1","tagName":"basque/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":57},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188916324},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.1/model.tflite","name":"model.tflite","size":47332112},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4117}]}},{"description":"# Romansh Vallader STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language:  Romansh Vallader / Rumantsch / `rm-vallader`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{rm-vallader-stt, author = {Tyers,Francis}, title = {Romansh Vallader STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-RM_VALLADER-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Romansh Vallader Language](https://en.wikipedia.org/wiki/Vallader_dialect) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|84.0\\%|26.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Romansh Vallader STT v0.1.0","tagName":"romansh-vallader/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-vallader/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":92},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-vallader/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-vallader/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189014749},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-vallader/itml/v0.1.0/model.tflite","name":"model.tflite","size":47356808},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-vallader/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4181}]}},{"description":"# Upper Sorbian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Upper Sorbian / Hornjoserb≈°ƒáina / `hsb`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{upper-sorbian-stt, author = {Tyers,Francis}, title = {Upper Sorbian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-HSB-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Upper Sorbian Language](https://en.wikipedia.org/wiki/Upper_Sorbian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ta/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|92.3\\%|32.4\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Upper Sorbian STT v0.1.0","tagName":"upper-sorbian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/upper-sorbian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":99},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/upper-sorbian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/upper-sorbian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189031154},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/upper-sorbian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47360928},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/upper-sorbian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4171}]}},{"description":"# Romansh Sursilvan STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language:  Romansh Sursilvan / romontsch sursilvan / `rm-sursilvan`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{rm-sursilvan-stt, author = {Tyers,Francis}, title = {Romansh Sursilvan STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-RM_SURSILVAN-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Romansh Sursilvan Language](https://en.wikipedia.org/wiki/Sursilvan) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|79.6\\%|23.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Romansh Sursilvan STT v0.1.1","tagName":"romansh-sursilvan/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-sursilvan/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":80},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-sursilvan/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-sursilvan/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188981941},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-sursilvan/itml/v0.1.0/model.tflite","name":"model.tflite","size":47348576},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-sursilvan/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4190}]}},{"description":"# Amharic STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Amharic / ·ä†·àõ·à≠·äõ / `am`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{amharic-stt, author = {Tyers,Francis}, title = {Amharic STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-ALFFA-AM-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Amharic Language](https://en.wikipedia.org/wiki/Amharic_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/am/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|ALFFA|75.1\\%|29.4\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the Amharic subset of the [ALFFA](http://openslr.org/25/) corpus.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on the Amharic subset of the [ALFFA](http://openslr.org/25/) corpus.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Amharic STT v0.1.0","tagName":"amharic/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/amharic/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":1150},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/amharic/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/amharic/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":191049162},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/amharic/itml/v0.1.0/model.tflite","name":"model.tflite","size":47867504},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/amharic/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4206}]}},{"description":"# Wolof STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Wolof / Wolof / `wo`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{wolof-stt, author = {Tyers,Francis}, title = {Wolof STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-ALFFA-WO-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Wolof Language](https://en.wikipedia.org/wiki/Wolof_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/am/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|ALFFA|57.1\\%|18.1\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the Wolof subset of the [ALFFA](http://openslr.org/25/) corpus.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on the Wolof subset of the [ALFFA](http://openslr.org/25/) corpus.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Wolof STT v0.1.0","tagName":"wolof/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/wolof/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":66},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/wolof/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/wolof/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188932732},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/wolof/itml/v0.1.0/model.tflite","name":"model.tflite","size":47336232},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/wolof/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4183}]}},{"description":"# Yoruba STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Yoruba / √àd√® Yor√πb√° / `yo`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{yoruba-stt, author = {Tyers,Francis}, title = {Yoruba STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-ALFFA-YO-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Yoruba Language](https://en.wikipedia.org/wiki/Yoruba_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/am/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|ALFFA|71.6\\%|23.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the Yoruba subset of the [ALFFA](http://openslr.org/25/) corpus.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on the Yoruba subset of the [ALFFA](http://openslr.org/25/) corpus.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Yoruba STT v0.1.0","tagName":"yoruba/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/yoruba/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":64},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/yoruba/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/yoruba/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188916331},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/yoruba/itml/v0.1.0/model.tflite","name":"model.tflite","size":47332120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/yoruba/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4200}]}},{"description":"# Dutch STT v0.0.1 (acabunoc)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally released by [Abigail Cabunoc Mayes](https://github.com/acabunoc).\r\n- Model language: Dutch / Nederlands / `nl`\r\n- Model date: July 12, 2020\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: MPL\r\n- Citation details: `@techreport{dutch-stt, author = {Cabunoc Mayes,Abigail}, title = {Dutch STT 0.0.1}, institution = {Coqui}, address = {\\url{https://coqui.ai/models}} year = {2020}, month = {July}, number = {STT-CV-NL-0.0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Dutch Language](https://en.wikipedia.org/wiki/Dutch_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported *using a language model*: [Github](https://github.com/acabunoc/Tutorial-train-dutch-model).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice 5.1|87.8\\%|65.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 660K\r\n`model.tflite`: 221K\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 5.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 5.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Dutch STT v0.0.1","tagName":"dutch/acabunoc/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/alphabet.txt","name":"alphabet.txt","size":472},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/LICENSE","name":"LICENSE","size":16725},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/model.pbmm","name":"model.pbmm","size":675757},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/model.tflite","name":"model.tflite","size":225512},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4039},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/nl-acabunoc-1-prune-kenlm.scorer","name":"nl-acabunoc-1-prune-kenlm.scorer","size":323345856}]}},{"description":"# Russian STT v0.1.0 (Joe Meyer)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Joe Meyer](https://www.linkedin.com/in/joe-meyer-25753951/).\r\n- Model language: Russian / —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ / `ru`\r\n- Model date: May 12, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: CC-0 \r\n- Citation details: `@techreport{russian-stt, author = {Meyer,Joe}, title = {Russian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {May}, number = {STT-CV6.1-RU-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Russian Language](https://en.wikipedia.org/wiki/Russian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported for a non-official held-out test set from Common Voice 6.1 *with the use of an external language model*. The official `validated.tsv` was re-processed by [CorporaCreator](https://github.com/mozilla/corporacreator) to include all repeat sentences.\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|32.3\\%|12.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on a non-official training set from Common Voice 6.1. The official `validated.tsv` was re-processed by [CorporaCreator](https://github.com/mozilla/corporacreator) to include all repeat sentences.\r\n\r\n## Evaluation data\r\n\r\nThis model was evaluated on a non-official testing set from Common Voice 6.1. The official `validated.tsv` was re-processed by [CorporaCreator](https://github.com/mozilla/corporacreator) to include all repeat sentences.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Russian STT v0.1.0","tagName":"russian/jemeyer/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/alphabet.txt","name":"alphabet.txt","size":101},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/LICENSE","name":"LICENSE","size":60},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4562},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/model.tflite","name":"model.tflite","size":47344496},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/model.pbmm","name":"model.pbmm","size":188965564},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/wiki-ru-6gram.scorer","name":"wiki-ru-6gram.scorer","size":719764672}]}}]}}}}]}},"pageContext":{"description":"# Spanish STT v0.0.1 (Jaco-Assistant)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [DANBER](https://gitlab.com/DANBER) and released under the [Jaco-Assistant](https://gitlab.com/Jaco-Assistant/Scribosermo) project.\r\n- Model date: Accessed from [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [scribosermo](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master/#old-experiments)\r\n- License: GNU Lesser General Public License\r\n- Citation details: `@misc{spanish-jaco,\r\nauthor = {DANBER},\r\ntitle = {Spanish Jaco-Assistant},\r\npublisher = {Jaco-Assistant},\r\njournal = {Gitlab},\r\nhowpublished = {\\url{https://gitlab.com/Jaco-Assistant/Scribosermo}},\r\ncommit = {dfc541d2}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Spanish Language](https://en.wikipedia.org/wiki/Spanish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|16.5\\%|7.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: CommonVoice + CssTen + LinguaLibre + Mailabs + Tatoeba + Voxforge.\r\n\r\n## Evaluation data\r\n\r\nThe model was tested on the Common Voice corpus.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Spanish STT v0.0.1","tagName":"spanish/jaco-assistant/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/alphabet.txt","name":"alphabet.txt","size":332},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/LICENSE","name":"LICENSE","size":7652},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/model.pbmm","name":"model.pbmm","size":188973740},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/model.tflite","name":"model.tflite","size":47346520},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4324},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/kenlm_es.scorer","name":"kenlm_es.scorer","size":279655392}]},"slug":"spanish/jaco-assistant/v0.0.1"}},"staticQueryHashes":["1942088059","3709355695"]}