{"componentChunkName":"component---src-pages-newsletter-05-07-2021-mdx","path":"/newsletter/05-07-2021","result":{"data":{"mdx":{"id":"a6a2ac1c-c562-528a-880a-e9382e9aebba","excerpt":"Welcome By  Kelly Davis üê∏TTS was on üî• this month bringing lots of improvements and updates your way. First, we‚Äôve\ncompletely re-written‚Ä¶","body":"var _excluded = [\"components\"];\n\nvar _templateObject;\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\nfunction _taggedTemplateLiteral(strings, raw) { if (!raw) { raw = strings.slice(0); } return Object.freeze(Object.defineProperties(strings, { raw: { value: Object.freeze(raw) } })); }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar pageQuery = graphql(_templateObject || (_templateObject = _taggedTemplateLiteral([\"\\n  query($fileAbsolutePath: String) {\\n    ...SidebarPageFragment\\n  }\\n\"])));\nvar _frontmatter = {\n  \"title\": \"Coqui's Fourth Mondays Newsletter\",\n  \"date\": \"July 5, 2021\"\n};\nvar layoutProps = {\n  pageQuery: pageQuery,\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"934px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"27.599999999999998%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAA3XAAAN1wFCKJt4AAABCElEQVQY042RQUsCcRDF/VB9g+59gk6eOhTRpaBbh5CgYCuiTkYGah6CSIwiyiRbiiyVFg+5EoS6LO1/XS0oXffXriC1atCDOcyDeW/mTQAXjuMwhFHcH/g9H/CaPqG/W5T0V1ShUTbqjDIb7L/abR/vE8y8KEjyMfv5NHuFS87kO0LhCBvxBOuxBPHTc0K7EVJZGV2YhI+SZAvF3qzd7f4I9h287WpNgfho8WzWWdjaZnFzh+DSMtMra0zMzTO7KjE2GewJj0/NcOKKe+jY9vCGWsvkvlom55ZqamhvBqnrG26fFDIPeYTVRIoecHiR5ir3iKJWMBqW/+TBbDynz46by/9/4sv1G2shujMHTg19AAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/c9103bc33c8add5ab1fa4fa1c49c90ef/ca463/logo-wordmark.png\",\n    \"srcSet\": [\"/static/c9103bc33c8add5ab1fa4fa1c49c90ef/43fa5/logo-wordmark.png 250w\", \"/static/c9103bc33c8add5ab1fa4fa1c49c90ef/c6e3d/logo-wordmark.png 500w\", \"/static/c9103bc33c8add5ab1fa4fa1c49c90ef/ca463/logo-wordmark.png 934w\"],\n    \"sizes\": \"(max-width: 934px) 100vw, 934px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"h3\", {\n    \"id\": \"welcome\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#welcome\",\n    \"aria-label\": \"welcome permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"Welcome\"), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/kdavis-coqui\"\n  }, \"Kelly Davis\")), mdx(\"p\", null, \"\\uD83D\\uDC38TTS was on \\uD83D\\uDD25 this month bringing lots of improvements and updates your way. First, we\\u2019ve\\ncompletely re-written the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://tts.readthedocs.io\"\n  }, \"TTS documentation\"), \". Now it\\u2019s easier\\nthan ever to start your TTS journey with the trusted guide of our new \\uD83D\\uDC38TTS documentation\\nby your side. Next, we introduced a new \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://tts.readthedocs.io/en/latest/main_classes/trainer_api.html\"\n  }, \"Trainer API\"), \"\\nwhich is a lightweight, extensible, and feature-complete training framework for \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"all\"), \" the\\n\\uD83D\\uDC38TTS models. If that wasn\\u2019t enough, we introduced a new char-to-phoneme model\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/rhasspy/gruut\"\n  }, \"Gruut\"), \" that makes \\uD83D\\uDC38TTS even more realistic.\"), mdx(\"p\", null, \"\\uD83D\\uDC38STT wasn\\u2019t sleeping either. Over the last month work began on a complete rewrite of\\n\\uD83D\\uDC38STT\\u2019s \\u201Cnative client\\u201D, a native library written in C++ focused solely on inference.\\nIn this rewrite we wanted to retain the performance, simplicity, ease-of-use, and\\navailability of the current \\u201Cnative client\\u201D, but set a path towards a new, unified\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://onnx.ai\"\n  }, \"ONNX\"), \" based \\u201Cnative client\\u201D that works for both \\uD83D\\uDC38STT \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"and\"), \" \\uD83D\\uDC38TTS.\\nThough it\\u2019s early days for the new \\u201Cnative client\\u201D, we\\u2019ve released an\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/coqui-ai/inference-engine\"\n  }, \"initial version\"), \" so you can kick the\\ntires, drive it around the block, and give us some feedback.\"), mdx(\"p\", null, \"Last but not least, Coqui gave a talk at\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://l3-ai.dev/\"\n  }, \"L3-AI: the conference for building next-level AI assistants\"), \".\\nThe slides are available \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.google.com/presentation/d/e/2PACX-1vQXtFe__a6P-r3lanv2CpZ0NzQzHDu_1E8uUhTaidnT-WtuPHPkKpiZsgc0gY4PmAZQ5d5CMw9fXAf9/pub?start=false&loop=false&delayms=3000\"\n  }, \"here\"), \";\\nthe video + audio will be available soon.\"), mdx(\"p\", null, \"Enjoy the newsletter!\"), mdx(\"h3\", {\n    \"id\": \"tts-v010-is-out\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#tts-v010-is-out\",\n    \"aria-label\": \"tts v010 is out permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83D\\uDC38TTS v0.1.0 is out\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"72%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wgARCAAOABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAQGAQP/xAAWAQEBAQAAAAAAAAAAAAAAAAAGBAX/2gAMAwEAAhADEAAAAX1ucmRTVxhLqf/EABkQAAMBAQEAAAAAAAAAAAAAAAMEBQIBIv/aAAgBAQABBQLPOMGVXC1o/glXpVk5Vgm7z9Pax//EABwRAAICAgMAAAAAAAAAAAAAAAECACESMSJR8P/aAAgBAwEBPwFODqrDHdDXqhJ7n//EAB4RAQABAwUBAAAAAAAAAAAAAAECAAMREiFBYbHh/9oACAECAQE/AWI2pysuQxvz37RqT61//8QAIhAAAgEEAgEFAAAAAAAAAAAAAQIDABESIQQxIiNBUWJx/9oACAEBAAY/ArxZABdtPpVH52aCxWSaLd3Hi9/kURLxuRl9DkKl5gl3Enpi3RrBjksyBDlWAQde1f/EAB4QAQEAAgICAwAAAAAAAAAAAAERACExUWFxkaHB/9oACAEBAAE/IdgmzaraPZ9GQJACHkHZe8kR+FPwn7vESWgGoyvq4dQxwLZb85JjBy1n/9oADAMBAAIAAwAAABC4/wD/xAAaEQEAAgMBAAAAAAAAAAAAAAABETEAUWGB/9oACAEDAQE/EGhqpBZIXvG3wTDn/8QAGxEBAAICAwAAAAAAAAAAAAAAAREhAIExcfD/2gAIAQIBAT8Qt8xKbAwvkjpW1ETxtz//xAAdEAEBAAMBAAMBAAAAAAAAAAABEQAhMUFhcYGR/9oACAEBAAE/EOPe1WRKjODEa3JPcYFeVAEOhBKMQQrykpBca06APcRkiFCLNGH5b9YR6aKQA4EP8+cWkFIu2xdl3L+5/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/1e77dc6fce06f5a577ab0e4d0674e779/dbdff/tts-v0.1.0-release.jpg\",\n    \"srcSet\": [\"/static/1e77dc6fce06f5a577ab0e4d0674e779/0988f/tts-v0.1.0-release.jpg 250w\", \"/static/1e77dc6fce06f5a577ab0e4d0674e779/d1f95/tts-v0.1.0-release.jpg 500w\", \"/static/1e77dc6fce06f5a577ab0e4d0674e779/dbdff/tts-v0.1.0-release.jpg 1000w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/erogol\"\n  }, \"Eren G\\xF6lge\")), mdx(\"p\", null, \"A ton of updates and improvements are in the new v0.1.0 version of \\uD83D\\uDC38TTS. Below we cover some of\\nthe important ones, and you can find more info in our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/coqui-ai/TTS/releases/tag/v0.1.0\"\n  }, \"release notes\"), \".\"), mdx(\"h4\", {\n    \"id\": \"-tts-documentation\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#-tts-documentation\",\n    \"aria-label\": \" tts documentation permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83D\\uDCDD TTS documentation\"), mdx(\"p\", null, \"We\\u2019ve created shinny, new \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://tts.readthedocs.io\"\n  }, \"TTS documentation\"), \" where you can find all\\nthe information you need to train or test your models, implement new models, load new datasets,\\nand much more.\"), mdx(\"p\", null, \"The new documentation also contains \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://tts.readthedocs.io/en/latest/tutorial_for_nervous_beginners.html\"\n  }, \"here\"), \"\\na new, beginner-friendly intro to \\uD83D\\uDC38TTS. Getting started is easier than ever.\"), mdx(\"p\", null, \"If you see something is missing, let us know! We\\u2019re dying for feedback.\"), mdx(\"h4\", {\n    \"id\": \"-trainer-api\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#-trainer-api\",\n    \"aria-label\": \" trainer api permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83D\\uDE80 Trainer API\"), mdx(\"p\", null, \"We\\u2019ve also introduced a new \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://tts.readthedocs.io/en/latest/main_classes/trainer_api.html\"\n  }, \"Trainer API\"), \".\\nIt provides a lightweight, extensible, and feature-complete training framework for all the \\uD83D\\uDC38TTS\\nmodels. It supports mixed precision and multi GPU training right out-of-the-box and requires no\\ncode changes in your model implementation to take advantage of these functionalities.\"), mdx(\"p\", null, \"With this new API, you can either keep your old way of training models on the terminal or use pure\\nPython to initialize your model and call the trainer. Using only \\uD83D\\uDC0DPython allows you to run an\\nexperiment on a Jupyter Notebook or customize as you like.\"), mdx(\"h4\", {\n    \"id\": \"Ô∏è-gruut-based-char-to-phoneme\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#%EF%B8%8F-gruut-based-char-to-phoneme\",\n    \"aria-label\": \"Ô∏è gruut based char to phoneme permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83D\\uDDE3\\uFE0F Gruut based Char-to-Phoneme\"), mdx(\"p\", null, \"v0.1.0 also comes with a new char-to-phoneme interface, based on \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/rhasspy/gruut\"\n  }, \"Gruut\"), \",\\nthat covers most of the European languages and has a very flexible API.\"), mdx(\"p\", null, \"Gruut currently supports the following languages, and the list is growing constantly:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Czech (cs or cs-cz)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"German (de or de-de)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"English (en or en-us)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Spanish (es or es-es)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Farsi/Persian (fa)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"French (fr or fr-fr)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Italian (it or it-it)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Dutch (nl)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Russian (ru or ru-ru)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Swedish (sv or sv-se)\")), mdx(\"p\", null, \"We also support Japanese and Chinese through \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"pypinyin\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"MeCab\"), \".\"), mdx(\"p\", null, \"If you need to target a language that is not listed above, let us know and we can work together to\\nmake it available under \\uD83D\\uDC38TTS.\"), mdx(\"p\", null, \"\\uD83D\\uDC4F Big thanks to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/synesthesiam\"\n  }, \"@synesthesiam\"), \" for his library and efforts in\\nbringing it to \\uD83D\\uDC38TTS.\"), mdx(\"h3\", {\n    \"id\": \"-monthly-tts-papers\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#-monthly-tts-papers\",\n    \"aria-label\": \" monthly tts papers permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83D\\uDD2C Monthly TTS Papers\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66.8%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wgARCAANABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAUGA//EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAG8fTjqGJiV/8QAGhAAAgMBAQAAAAAAAAAAAAAAAAECAxEhIv/aAAgBAQABBQKjsYYnqRTLzWzT/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGBAAAgMAAAAAAAAAAAAAAAAAABABETH/2gAIAQEABj8CKULD/8QAHRAAAgIBBQAAAAAAAAAAAAAAAREAITEQUXGhsf/aAAgBAQABPyHIa9jhO4KABXMVUMCFR30P/9oADAMBAAIAAwAAABCMz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EAB0QAQEAAgMAAwAAAAAAAAAAAAERACExQWFRgfD/2gAIAQEAAT8QE79Ycp9ayZ+Irb85V2jkm+5fmpmEui4RejKd/pkoKGl5c//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/ee7ae83975f5a8e36a44fa9649c1ad37/dbdff/monthly-papers.jpg\",\n    \"srcSet\": [\"/static/ee7ae83975f5a8e36a44fa9649c1ad37/0988f/monthly-papers.jpg 250w\", \"/static/ee7ae83975f5a8e36a44fa9649c1ad37/d1f95/monthly-papers.jpg 500w\", \"/static/ee7ae83975f5a8e36a44fa9649c1ad37/dbdff/monthly-papers.jpg 1000w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/erogol\"\n  }, \"Eren G\\xF6lge\")), mdx(\"p\", null, \"This month we\\u2019ve also read some really interesting TTS papers. A few, which we found to be of\\nparticular interest, are:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.15561\"\n  }, \"A Survey on Neural Speech Synthesis\"), \" - Not only because\\nthey cited \\uD83D\\uDC38TTS and our latest paper but they provide a very comprehensive survey of\\nmodels. Especially useful for people just starting to work in the TTS field.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.07889\"\n  }, \"UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity\\nWaveform Generation\"), \" - A new GAN based vocoder. As we\\u2019re\\nquick on the draw, it is already implemented in \\uD83D\\uDC38TTS!\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.09660\"\n  }, \"WaveGrad2\"), \" - WaveGrad2 proposes an end-to-end TTS model\\nbuilt on diffusion probabilistic models. You guessed it, we also have a WaveGrad vocoder\\nimplementation in \\uD83D\\uDC38TTS.\")), mdx(\"p\", null, \"\\uD83D\\uDC40 See our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/coqui-ai/TTS-papers\"\n  }, \"TTS-papers\"), \" list for even more TTS papers!\"), mdx(\"h3\", {\n    \"id\": \"coqui-inference-engine-a-sneak-peek\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#coqui-inference-engine-a-sneak-peek\",\n    \"aria-label\": \"coqui inference engine a sneak peek permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"Coqui Inference Engine: A Sneak Peek\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66.8%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAQDBQf/xAAWAQEBAQAAAAAAAAAAAAAAAAABBAX/2gAMAwEAAhADEAAAAclbmYzpaYfF/8QAGRAAAwEBAQAAAAAAAAAAAAAAAAECBAMR/9oACAEBAAEFAueGWPBKHkXvOx2Nn//EABYRAAMAAAAAAAAAAAAAAAAAAAABEf/aAAgBAwEBPwGsrP/EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABcQAAMBAAAAAAAAAAAAAAAAAAAQMQH/2gAIAQEABj8CcxQ//8QAGBABAQEBAQAAAAAAAAAAAAAAAQAxESH/2gAIAQEAAT8hkEjxwh+YXri//9oADAMBAAIAAwAAABCA7//EABURAQEAAAAAAAAAAAAAAAAAAABh/9oACAEDAQE/EKqP/8QAFxEBAQEBAAAAAAAAAAAAAAAAAQARIf/aAAgBAgEBPxBXbt//xAAbEAEAAgIDAAAAAAAAAAAAAAABABEhkTFhgf/aAAgBAQABPxBk41MRrUeEApk6i0L+Q27ZP//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/e14c1f8fc43a14aef0ffcea2ec716c96/dbdff/inference-engine-sneak-peek.jpg\",\n    \"srcSet\": [\"/static/e14c1f8fc43a14aef0ffcea2ec716c96/0988f/inference-engine-sneak-peek.jpg 250w\", \"/static/e14c1f8fc43a14aef0ffcea2ec716c96/d1f95/inference-engine-sneak-peek.jpg 500w\", \"/static/e14c1f8fc43a14aef0ffcea2ec716c96/dbdff/inference-engine-sneak-peek.jpg 1000w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/reuben\"\n  }, \"Reuben Morais\")), mdx(\"p\", null, \"From the very inception of the \\uD83D\\uDC38STT project, one of our goals was to build a speech-to-text system\\nthat is easy to integrate and deploy into any product, regardless of the platform or programming\\nlanguage of choice. \\uD83D\\uDC38STT was naturally divided between two main components: the training\\ninfrastructure and a lean deployment library meant to be integrated into speech-enabled products.\\nThe training code is built largely in Python using TensorFlow and other ML libraries. The deployment\\nlibrary, which in STT is called the \\u201Cnative client\\u201D, is a native library written in C++, focused\\nsolely on inference. It exposes a C API which is then bound to various programming languages.\\nThis architecture enabled us to make STT available universally, directly from your favorite package\\nmanager.\"), mdx(\"p\", null, \"Since then, we\\u2019ve learned a lot about how people use STT, and the technologies used to build machine\\nlearning pipelines have also evolved significantly. One disadvantage of the current architecture\\nis how fragile the connection between the training infrastructure and the deployment library is:\\nwe\\u2019ve managed to bend the TensorFlow tooling to our will in order to implement efficient model\\nexports, sometimes leveraging obscure functionality which can be undocumented, unstable, and\\nsometimes entirely deprecated. This meant that sometimes changing the model architecture would\\nunearth obscure problems, which required deep knowledge of both STT and TensorFlow internals to fix.\"), mdx(\"p\", null, \"Given these learnings, we at Coqui have been thinking about the future direction of \\uD83D\\uDC38STT and its\\ndeployment library. We want to keep the performance, simplicity, ease-of-use, and availability of\\nour libraries, while finding solutions for the problems described above. We also want to draw a\\npath towards a unified deployment tool that works for both \\uD83D\\uDC38STT and \\uD83D\\uDC38TTS, the latter being built\\nwith PyTorch, not TensorFlow. This foundation could then be expanded to work with any speech model.\"), mdx(\"p\", null, \"With all this in mind, we\\u2019ve started working on the next generation of our \\u201Cnative client\\u201D, the\\nCoqui Inference Engine. Built as an independent project, rather than as an STT submodule, and based\\non \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://onnx.ai\"\n  }, \"ONNX\"), \", a standard interchange format for machine learning models, the Coqui\\nInference Engine will be a unified solution for running speech models efficiently. We\\u2019re starting\\nwith \\uD83D\\uDC38STT and \\uD83D\\uDC38TTS, and in the future will support a variety of architectures, reducing the gap\\nbetween speech model architecture exploration and efficient deployment.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"75.6%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAFxGAABcRgEUlENBAAACfUlEQVQ4y3VTTXPaMBTk7/faQ3vrTA9tD+k0ZRLSEiBAJkAgBBtj4y8Z+QNbkk2nH39gK8kJoSQ97FhjP+3b93bd4JxB8BKbLMTYv8IyNMAZx5yM0LNbsIklvwvkeY44TpBlGRhjGpxzjcNzo2AFSlFhTZf4Mn+HG68vCzhu3As0rQ9YBHeaMAgDzGZ3sB0HRVE8I3o8N3Q3qVKR7qofyLMcRVbgZ/kHPCvxq/oNtuXI0kwTKdQK+V7p4bnx1KGAEAIRjdCRow79S1xZbXStb7iy2/BjD4IJXavqdpVAVSqUKOVTQ75vPEpVKlUhoQRdp4W2dYa+10ZPEUpil6z1brfbLWicwlxv4IYJfEIRkBhkE+sd7xXuIS/txA4s5yhZCVEIxFEC07Tq3clJ7q0Ar94P8fZkjHenI7w5ucXrj9doD+dPhI/7UWcaU6RpqlWrCajsniaJHLPSCpXTG5qBSoRSYbhJ4PgbkIjWI6v5SRRpFw3DxFQ+b6cz2LYti0OsiYOVR+C4oW4kRAk7NTF2B5hZSwxuHXhhJBuWh6YwnTWlUl2q88YxWd3gbNLEp9YQrc4I7MFlZdKarhBQKtXJ/SVZHZvD/QlRO6guxHEslZeyiVxFXjw03OqRFdSuVdSUy1VVO7zP4XE4q7KSJFKFF8D3A4QhQUxjqY79Y+BxDp8pVFDdVUQ86sL2V1hYBlzflbGIdKSSNMGzZBygcaxOOdxeNvHd/YyO+xUdp4m+f47L1Sm65hk84u7X8uK/fPwhkwrnto/e1Mb1vYuxscZgbqM7XWJiuEiS9EWil0eWLxP5L08WPi76C3RGK7QGBk67Bs77JnoT58FN9t+R/wLtYzfPW0rAaAAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/5c1039aa2349c2efef02a024489ec724/da8b6/inference-engine-sneak-peek-diagram.png\",\n    \"srcSet\": [\"/static/5c1039aa2349c2efef02a024489ec724/43fa5/inference-engine-sneak-peek-diagram.png 250w\", \"/static/5c1039aa2349c2efef02a024489ec724/c6e3d/inference-engine-sneak-peek-diagram.png 500w\", \"/static/5c1039aa2349c2efef02a024489ec724/da8b6/inference-engine-sneak-peek-diagram.png 1000w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"In the diagram above you can see an overview of how the components connect and how models flow.\\nFirst-party components (meaning usually maintained by Coqui) are colored green, third-party\\ncomponents (community maintained) are colored in blue, and cases where both Coqui and the\\ncommunity would maintain offerings are colored in both blue and green.\"), mdx(\"p\", null, \"These are the early days for the Coqui Inference Engine, and we want to invite all interested\\ndevelopers to collaborate on its design and implementation. Check out\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/coqui-ai/inference-engine\"\n  }, \"the repository\"), \" for more information and\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://gitter.im/coqui-ai/inference-engine\"\n  }, \"join the discussion on Gitter\"), \".\"), mdx(\"h3\", {\n    \"id\": \"coqui-appearance-at-l3-ai\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#coqui-appearance-at-l3-ai\",\n    \"aria-label\": \"coqui appearance at l3 ai permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"Coqui Appearance at L3-AI\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"50%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABx0lEQVQoz31STU8aURSdIB/DvDcfIAqIsqggMwyjMjMgrRqjsbZG1MQNYaebduuGuMO4aRpX3bjpz+l/6O85vfdNMFaJi5M7782559yPp1lOgOVKDKccwSIIu4O88GDI9rtIOD4MEYA1SsshTDuAVq31EcVD1Le/YoVgk2jecF8JeHNMPAjZIcEuams78IPPqjAtl3exkGkgm21Cz20QgYimT+T5VelkNkNiktylOZ+ixkQWMAgZEkxnG0hl1lWcJb0U4LZMZxPSCtR5VrkwE1PtpfuGe4h2+wvC7iV8/xTNtTEK9gCLS9vKdGdwicfHX3h4+Imnp9/49n2CrN76r4tnQW49jM4Qhhf49HGEuH8BSw4g5ZYaOAtGvSGm9z8wmUxxdzfF9c2tynsrKNpqYzxLRir9QUVdtObMLeEyWEwXDE/NnNvWVIJoImc05i7hNZ6FDQ856WLVjFGxI6SMFtKZJrRCMcJ6fYxS8RjSTobO74rfo4LFMTlLy6f/HQX+ZgPbpOXoLg6ORuj1z6EVSyEO/T842fyL6so+ytUuVusDOJUINsGi+Tm1HpxqjCItZ6kcEidCYXGLKqUNU5sL9CJ2965IcIh/F/QPtKqJincAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/d76069cc5cdf496292251efa21b118ac/da8b6/l3-ai.png\",\n    \"srcSet\": [\"/static/d76069cc5cdf496292251efa21b118ac/43fa5/l3-ai.png 250w\", \"/static/d76069cc5cdf496292251efa21b118ac/c6e3d/l3-ai.png 500w\", \"/static/d76069cc5cdf496292251efa21b118ac/da8b6/l3-ai.png 1000w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/JRMeyer\"\n  }, \"Josh Meyer\")), mdx(\"p\", null, \"This year Coqui appeared as a featured partner at \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://l3-ai.dev/\"\n  }, \"L3-AI: the conference for building next-level AI assistants\"), \".\\nJosh Meyer delivered a talk about deploying scalable, neural voice technologies at the enterprise\\nlevel. Soon the recordings will be made available to everyone who wasn\\u2019t able to attend the\\nconference virtually, so you can watch the talk and lively Q&A session.\"), mdx(\"p\", null, \"You can find our presentation slides \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.google.com/presentation/d/e/2PACX-1vQXtFe__a6P-r3lanv2CpZ0NzQzHDu_1E8uUhTaidnT-WtuPHPkKpiZsgc0gY4PmAZQ5d5CMw9fXAf9/pub?start=false&loop=false&delayms=3000\"\n  }, \"here\"), \",\\nand listen to us talk about related themes with Rasa on their podcast\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://podcasts.apple.com/us/podcast/open-source-speech-technology/id1533150162?i=1000518100336\"\n  }, \"here\"), \".\\nWe will keep you posted on when the new L3AI recordings become available.\"), mdx(\"p\", null, \"In addition to our featured presentation, Coqui had the most active company booth at the\\nconference! We want to thank all of you who showed up and participated in the lively\\ndiscussions!\"));\n}\n;\nMDXContent.isMDXComponent = true;","tableOfContents":{"items":[{"url":"#welcome","title":"Welcome"},{"url":"#tts-v010-is-out","title":"üê∏TTS v0.1.0 is out"},{"url":"#-monthly-tts-papers","title":"üî¨ Monthly TTS Papers"},{"url":"#coqui-inference-engine-a-sneak-peek","title":"Coqui Inference Engine: A Sneak Peek"},{"url":"#coqui-appearance-at-l3-ai","title":"Coqui Appearance at L3-AI"}]}}},"pageContext":{"frontmatter":{"title":"Coqui's Fourth Mondays Newsletter","date":"July 5, 2021"},"fileAbsolutePath":"/Users/kdavis/Code/coqui-ai/coqui-ai.github.io/src/pages/newsletter/05-07-2021.mdx"}},"staticQueryHashes":["1942088059","3709355695"]}