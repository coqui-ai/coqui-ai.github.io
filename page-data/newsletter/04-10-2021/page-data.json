{"componentChunkName":"component---src-pages-newsletter-04-10-2021-mdx","path":"/newsletter/04-10-2021","result":{"data":{"mdx":{"id":"a615ac93-b19a-5b0a-bb40-43d34d31b7fb","excerpt":"üë©‚ÄçüíªWork at Coqui By  Kelly Davis We're still hiring! An open source remote-friendly Berlin based startup founded by the creators of‚Ä¶","body":"var _excluded = [\"components\"];\n\nvar _templateObject;\n\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\nfunction _taggedTemplateLiteral(strings, raw) { if (!raw) { raw = strings.slice(0); } return Object.freeze(Object.defineProperties(strings, { raw: { value: Object.freeze(raw) } })); }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar pageQuery = graphql(_templateObject || (_templateObject = _taggedTemplateLiteral([\"\\n  query($fileAbsolutePath: String) {\\n    ...SidebarPageFragment\\n  }\\n\"])));\nvar _frontmatter = {\n  \"title\": \"Coqui's Seventh Mondays Newsletter\",\n  \"date\": \"October 4, 2021\"\n};\nvar layoutProps = {\n  pageQuery: pageQuery,\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"934px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"27.599999999999998%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAA3XAAAN1wFCKJt4AAABCElEQVQY042RQUsCcRDF/VB9g+59gk6eOhTRpaBbh5CgYCuiTkYGah6CSIwiyiRbiiyVFg+5EoS6LO1/XS0oXffXriC1atCDOcyDeW/mTQAXjuMwhFHcH/g9H/CaPqG/W5T0V1ShUTbqjDIb7L/abR/vE8y8KEjyMfv5NHuFS87kO0LhCBvxBOuxBPHTc0K7EVJZGV2YhI+SZAvF3qzd7f4I9h287WpNgfho8WzWWdjaZnFzh+DSMtMra0zMzTO7KjE2GewJj0/NcOKKe+jY9vCGWsvkvlom55ZqamhvBqnrG26fFDIPeYTVRIoecHiR5ir3iKJWMBqW/+TBbDynz46by/9/4sv1G2shujMHTg19AAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/c9103bc33c8add5ab1fa4fa1c49c90ef/ca463/logo-wordmark.png\",\n    \"srcSet\": [\"/static/c9103bc33c8add5ab1fa4fa1c49c90ef/43fa5/logo-wordmark.png 250w\", \"/static/c9103bc33c8add5ab1fa4fa1c49c90ef/c6e3d/logo-wordmark.png 500w\", \"/static/c9103bc33c8add5ab1fa4fa1c49c90ef/ca463/logo-wordmark.png 934w\"],\n    \"sizes\": \"(max-width: 934px) 100vw, 934px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"h3\", {\n    \"id\": \"work-at-coqui\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#work-at-coqui\",\n    \"aria-label\": \"work at coqui permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83D\\uDC69\\u200D\\uD83D\\uDCBBWork at Coqui\"), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/kdavis-coqui\"\n  }, \"Kelly Davis\")), mdx(\"p\", null, \"We\\u2019re still hiring!\"), mdx(\"p\", null, \"An open source remote-friendly Berlin based startup founded by the creators of Mozilla\\u2019s\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/mozilla/tts\"\n  }, \"text-to-speech\"), \" (TTS) and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/mozilla/deepspeech\"\n  }, \"speech-to-text\"), \"\\n(STT) engines (over \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://somsubhra.github.io/github-release-stats/?username=mozilla&repository=deepspeech&page=1&per_page=300\"\n  }, \"650K downloads\"), \"\\nand 23K GitHub stars), with the backing of top-flight investors \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"and\"), \" we\\u2019re hiring!\"), mdx(\"p\", null, \"What\\u2019s not to love?\"), mdx(\"p\", null, \"We\\u2019re hiring across-the-board for a number of roles; so, there\\u2019s something for everyone:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/job/head-of-product\"\n  }, \"Head of Product\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/job/senior-full-stack-engineer\"\n  }, \"Senior Full Stack Engineers\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/job/senior-stt-deep-learning-engineer\"\n  }, \"Senior STT Deep Learning Engineers\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/job/senior-tts-deep-learning-engineer\"\n  }, \"Senior TTS Deep Learning Engineers\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"/job/senior-developer-community-manager\"\n  }, \"Senior, Developer Community Managers\"))), mdx(\"p\", null, \"The full list of open positions is available on our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"/jobs\"\n  }, \"jobs page\"), \".\"), mdx(\"p\", null, \"We\\u2019d love to hear from you; so, if any roles pique your interest, reach out to\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"mailto:jobs@coqui.ai\"\n  }, \"jobs@coqui.ai\"), \". \\uD83D\\uDC38!\"), mdx(\"h3\", {\n    \"id\": \"hello-\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#hello-\",\n    \"aria-label\": \"hello  permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"Hello! \\uD83D\\uDC4B\\uD83D\\uDC38\"), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/kdavis-coqui\"\n  }, \"Kelly Davis\")), mdx(\"p\", null, \"We\\u2019ve got quite a month for you\\uD83D\\uDE80!\"), mdx(\"p\", null, \"The \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/coqui-ai/STT/releases/v1.0.0\"\n  }, \"1.0 release\"), \" of Coqui \\uD83D\\uDC38STT is here\\uD83C\\uDF8A!\\nIt\\u2019s been brewing for quite some time, but we feel it\\u2019s finally ready! 1.0 brings with it\\na ton of features:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Exclusive use of TensorFlow Lite\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Experimental iOS support\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Built-in support for transfer learning and fine tuning\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Support for using our training and evaluation tools from Jupyter Notebooks,\")), mdx(\"p\", null, \"and a lot more!\"), mdx(\"p\", null, \"Alongside the Coqui \\uD83D\\uDC38STT 1.0 release, we\\u2019re also releasing our best ever\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://coqui.ai/english/coqui/v1.0.0-huge-vocab\"\n  }, \"English STT model\"), \"!\\nIt was trained on almost 47,000 hours of English and can outperform humans\\uD83E\\uDD2F! We\\u2019ve come a\\nlong way!\"), mdx(\"p\", null, \"If that wasn\\u2019t enough, we\\u2019re also releasing a new version of our TTS engine\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/coqui-ai/TTS/releases/tag/v0.3.0\"\n  }, \"v0.3.0, \\uD83D\\uDC38TTS\"), \". The new version\\nintroduces a New \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://tts.readthedocs.io/en/latest/models/forward_tts.html\"\n  }, \"ForwardTTS API\"), \",\\nAn English \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.03802\"\n  }, \"SpeedySpeech\"), \" model trained on LJSpeech\\n(the most compact TTS model we\\u2019ve released to the date), and A fine-tuned\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2106.07889\"\n  }, \"UnivNet\"), \" vocoder, and a lot more TTS goodness.\"), mdx(\"p\", null, \"We\\u2019ve also doubled down on STT responsiveness. Latency matters a lot! For the Coqui \\uD83D\\uDC38STT 1.0\\nrelease we spent a ton of time optimizing the inference library that powers all \\uD83D\\uDC38STT packages,\\nand it shows. It\\u2019s lean, streamable, and loads from disk in the blink of an eye.\"), mdx(\"p\", null, \"Also, as always, over the last month we\\u2019ve been spreading the \\u201Cword of Coqui\\u201D. We spoken at the\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://voicelunch.com/\"\n  }, \"Voice Lunch\"), \", to the students of \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.rug.nl/masters/voice-technology/\"\n  }, \"University of Groningen\\u2019s new\\nMSc in Voice Technology\"), \", and at Hyde Park\\u2019s\\nSpeakers\\u2019 Corner soapbox. (Well, not really the Hyde Park bit.)\"), mdx(\"p\", null, \"Anyway, enjoy the newsletter!\"), mdx(\"h3\", {\n    \"id\": \"coqui-stt-10-released\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#coqui-stt-10-released\",\n    \"aria-label\": \"coqui stt 10 released permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"Coqui \\uD83D\\uDC38STT 1.0 Released\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"72%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wgARCAAOABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAQGAQP/xAAWAQEBAQAAAAAAAAAAAAAAAAAGBAX/2gAMAwEAAhADEAAAAX1ucmRTVxhLqf/EABkQAAMBAQEAAAAAAAAAAAAAAAMEBQIBIv/aAAgBAQABBQLPOMGVXC1o/glXpVk5Vgm7z9Pax//EABwRAAICAgMAAAAAAAAAAAAAAAECACESMSJR8P/aAAgBAwEBPwFODqrDHdDXqhJ7n//EAB4RAQABAwUBAAAAAAAAAAAAAAECAAMREiFBYbHh/9oACAECAQE/AWI2pysuQxvz37RqT61//8QAIhAAAgEEAgEFAAAAAAAAAAAAAQIDABESIQQxIiNBUWJx/9oACAEBAAY/ArxZABdtPpVH52aCxWSaLd3Hi9/kURLxuRl9DkKl5gl3Enpi3RrBjksyBDlWAQde1f/EAB4QAQEAAgICAwAAAAAAAAAAAAERACExUWFxkaHB/9oACAEBAAE/IdgmzaraPZ9GQJACHkHZe8kR+FPwn7vESWgGoyvq4dQxwLZb85JjBy1n/9oADAMBAAIAAwAAABC4/wD/xAAaEQEAAgMBAAAAAAAAAAAAAAABETEAUWGB/9oACAEDAQE/EGhqpBZIXvG3wTDn/8QAGxEBAAICAwAAAAAAAAAAAAAAAREhAIExcfD/2gAIAQIBAT8Qt8xKbAwvkjpW1ETxtz//xAAdEAEBAAMBAAMBAAAAAAAAAAABEQAhMUFhcYGR/9oACAEBAAE/EOPe1WRKjODEa3JPcYFeVAEOhBKMQQrykpBca06APcRkiFCLNGH5b9YR6aKQA4EP8+cWkFIu2xdl3L+5/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/1e77dc6fce06f5a577ab0e4d0674e779/dbdff/release.jpg\",\n    \"srcSet\": [\"/static/1e77dc6fce06f5a577ab0e4d0674e779/0988f/release.jpg 250w\", \"/static/1e77dc6fce06f5a577ab0e4d0674e779/d1f95/release.jpg 500w\", \"/static/1e77dc6fce06f5a577ab0e4d0674e779/dbdff/release.jpg 1000w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/reuben\"\n  }, \"Reuben Morais\")), mdx(\"p\", null, \"Today Coqui is proud to release \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/coqui-ai/STT/releases/v1.0.0\"\n  }, \"Coqui STT 1.0\"), \",\\nthe first stable release of our open source speech-to-text engine. Coqui STT offers high quality,\\noffline speech-to-text technology that\\u2019s simple to integrate into your applications, thanks to\\nour easy to use API which supports multiple architectures, platforms, and programming languages.\"), mdx(\"p\", null, \"We have continuously worked to make our speech-to-text engine faster, more capable and easier to\\nuse. Developers are already relying on our technology to build voice powered applications around\\nthe world (and maybe even on the moon!). Today, we are proud to announce our first stable release.\\nWhen you integrate Coqui STT 1.0 into your application, you\\u2019ll be able to easily upgrade to newer\\n1.x versions and take advantage of performance improvements and bug fixes without having to change\\nyour code.\"), mdx(\"p\", null, \"Coqui STT 1.0 is available for download from our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/coqui-ai/STT/releases/v1.0.0\"\n  }, \"release page\"), \".\\nSince our last release, 0.9.3, we\\u2019ve continued to work on performance, stability, flexibility and\\naccuracy. We\\u2019ve\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Moved exclusively to TensorFlow Lite to make sure our most important runtime variant receives full attention and care,\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Released experimental iOS support,\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Landed built-in support for transfer learning and fine tuning,\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Added support for using our training and evaluation tools from Jupyter Notebooks,\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Streamlined alphabet generation and dataset splitting,\")), mdx(\"p\", null, \"and more!\"), mdx(\"p\", null, \"Try Coqui STT today by following our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://stt.readthedocs.io/en/latest/\"\n  }, \"usage guide\"), \" for your\\nfavorite programming language. Our \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://coqui.ai/english/coqui/v1.0.0-huge-vocab\"\n  }, \"1.0 English model\"), \" has\\nbeen trained on over 47 thousands of hours of speech data, including the latest release of the\\nCommon Voice dataset with 2000 hours of speech. It is available for download in the\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://coqui.ai/english/coqui/v1.0.0\"\n  }, \"Coqui Model Zoo\"), \", where we also document all of the training\\nparameters that were used to create it. You can also find our latest release in your favorite package\\nmanager: we offer packages for Python, Node.JS, Electron, Java on Android, and C/C++.\"), mdx(\"h3\", {\n    \"id\": \"-best-ever-stt-english-model-\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#-best-ever-stt-english-model-\",\n    \"aria-label\": \" best ever stt english model  permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83D\\uDD25 Best EVER \\uD83D\\uDC38STT English model \\uD83D\\uDD25\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66.8%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAUEBgj/xAAVAQEBAAAAAAAAAAAAAAAAAAADBP/aAAwDAQACEAMQAAABzU9T2ML0xBED/8QAGxAAAwACAwAAAAAAAAAAAAAAAgMEAAEFBhH/2gAIAQEAAQUC0O9ZJxdVwOkNDDP0I+wVQyuoNzf/xAAXEQEAAwAAAAAAAAAAAAAAAAACEBEx/9oACAEDAQE/AUKyP//EABYRAQEBAAAAAAAAAAAAAAAAAAIQUf/aAAgBAgEBPwErZ//EAB8QAAEDAwUAAAAAAAAAAAAAAAIAAQMREkEQEyExUf/aAAgBAQAGPwJXRREY+4TgbUJtNiJxYLrusopDKpFy7r//xAAaEAEAAgMBAAAAAAAAAAAAAAABABEhMUFR/9oACAEBAAE/ITr0RQDYSbeXO77FxqIkW+FYfA6x1n//2gAMAwEAAgADAAAAEJMf/8QAFxEBAAMAAAAAAAAAAAAAAAAAAQARMf/aAAgBAwEBPxA1TvNiAz//xAAXEQEBAQEAAAAAAAAAAAAAAAABACFx/9oACAECAQE/EFdzyFv/xAAcEAEBAAICAwAAAAAAAAAAAAABEQAhMVFBcZH/2gAIAQEAAT8QtpLz3jwL1IfBd8YbOXTZQeT3l6kADGgId0ABr1NY3rbm0auf/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/55dce4b9588d7066049d2557093dabd2/dbdff/best-stt-model.jpg\",\n    \"srcSet\": [\"/static/55dce4b9588d7066049d2557093dabd2/0988f/best-stt-model.jpg 250w\", \"/static/55dce4b9588d7066049d2557093dabd2/d1f95/best-stt-model.jpg 500w\", \"/static/55dce4b9588d7066049d2557093dabd2/dbdff/best-stt-model.jpg 1000w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/JRMeyer\"\n  }, \"Josh Meyer\")), mdx(\"p\", null, \"This is a very exciting day for us, because we are releasing our best ever Speech-to-Text model for\\nEnglish!\"), mdx(\"p\", null, \"We trained this model on almost 47,000 hours of English \\uD83E\\uDD2F \\u2026 And it shows\"), mdx(\"h4\", {\n    \"id\": \"-accurate\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#-accurate\",\n    \"aria-label\": \" accurate permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83D\\uDC49 Accurate\"), mdx(\"p\", null, \"\\u2714\\uFE0F Huge improvement in accuracy over all past versions\"), mdx(\"p\", null, \"With this new model, we get 4.5% word error rate on Librispeech clean (better than humans!). Our\\nprevious v0.9.3 model has a 7.1% WER, so you should upgrade as soon as possible to feel the\\ndifference:)\"), mdx(\"p\", null, \"More diverse voices in the training data means better demographic representation, and better\\nrepresentation means better Speech-to-Text for everyone!\"), mdx(\"h4\", {\n    \"id\": \"-fast--local--small\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#-fast--local--small\",\n    \"aria-label\": \" fast  local  small permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83D\\uDC49 Fast && Local && Small\"), mdx(\"p\", null, \"\\u2714\\uFE0F It runs on your computer\"), mdx(\"p\", null, \"\\u2714\\uFE0F It runs on your phone\"), mdx(\"p\", null, \"\\u2714\\uFE0F It runs on your watch\"), mdx(\"p\", null, \"We\\u2019ve doubled down on making models go everywhere you go. For the first time, we\\u2019re releasing two\\nversions of the model ready for Tensorflow Lite, in two sizes: small and extra-small:)\"), mdx(\"p\", null, \"Don\\u2019t let the sizes trick you, both these models are ready for the big leagues. The extra-small\\nmodel has optimally quantized weights, bringing this (open vocabulary!) speech recognizer down\\nto just 46 Megabytes. Oftentimes your application will benefit from a language model, which\\ncomes with a size\\u2194\\uFE0Faccuracy tradeoff. We are releasing a few language models so you can try out\\nfor yourself a language model under a kilobyte versus one in the order of Gigs. Depending on your\\napplication, you can choose the right model for you\\u2026 or you can build your own!\"), mdx(\"h4\", {\n    \"id\": \"-easy-to-customize\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#-easy-to-customize\",\n    \"aria-label\": \" easy to customize permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83D\\uDC49 Easy to Customize\"), mdx(\"p\", null, \"STT is built so that you can easily improve performance for your application, no matter how\\nspecific or how rare the vocabulary.\"), mdx(\"p\", null, \"If you\\u2019ve got doctors talking about doctor things, no problem! Lawyers talking about lawyer\\nthings? No sweat \\uD83D\\uDE0E No human knows all the jargon in all domains, but anyone can learn\\u2026\\nAnd the same goes for Coqui STT!\"), mdx(\"p\", null, \"This kind of customization happens at the language model, and you can easily (and quickly!)\\ncreate custom language models for your custom applications.\"), mdx(\"h4\", {\n    \"id\": \"-download-it-yourself\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#-download-it-yourself\",\n    \"aria-label\": \" download it yourself permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83D\\uDC49 Download it yourself\"), mdx(\"p\", null, \"\\u2714\\uFE0F Newest member of Model Zoo\"), mdx(\"p\", null, \"\\u2714\\uFE0F Apache 2.0 licensed\"), mdx(\"p\", null, \"We love open source, and we\\u2019re releasing this new v1.0.0 model under the Apache 2.0 license \\uD83C\\uDF89\"), mdx(\"p\", null, \"Download this new model from the Coqui model zoo, and check out all the other community models!\"), mdx(\"h3\", {\n    \"id\": \"v030-tts-delivered-fresh\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#v030-tts-delivered-fresh\",\n    \"aria-label\": \"v030 tts delivered fresh permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"v0.3.0, \\uD83D\\uDC38TTS Delivered Fresh\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"72%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wgARCAAOABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAQGAQP/xAAWAQEBAQAAAAAAAAAAAAAAAAAGBAX/2gAMAwEAAhADEAAAAX1ucmRTVxhLqf/EABkQAAMBAQEAAAAAAAAAAAAAAAMEBQIBIv/aAAgBAQABBQLPOMGVXC1o/glXpVk5Vgm7z9Pax//EABwRAAICAgMAAAAAAAAAAAAAAAECACESMSJR8P/aAAgBAwEBPwFODqrDHdDXqhJ7n//EAB4RAQABAwUBAAAAAAAAAAAAAAECAAMREiFBYbHh/9oACAECAQE/AWI2pysuQxvz37RqT61//8QAIhAAAgEEAgEFAAAAAAAAAAAAAQIDABESIQQxIiNBUWJx/9oACAEBAAY/ArxZABdtPpVH52aCxWSaLd3Hi9/kURLxuRl9DkKl5gl3Enpi3RrBjksyBDlWAQde1f/EAB4QAQEAAgICAwAAAAAAAAAAAAERACExUWFxkaHB/9oACAEBAAE/IdgmzaraPZ9GQJACHkHZe8kR+FPwn7vESWgGoyvq4dQxwLZb85JjBy1n/9oADAMBAAIAAwAAABC4/wD/xAAaEQEAAgMBAAAAAAAAAAAAAAABETEAUWGB/9oACAEDAQE/EGhqpBZIXvG3wTDn/8QAGxEBAAICAwAAAAAAAAAAAAAAAREhAIExcfD/2gAIAQIBAT8Qt8xKbAwvkjpW1ETxtz//xAAdEAEBAAMBAAMBAAAAAAAAAAABEQAhMUFhcYGR/9oACAEBAAE/EOPe1WRKjODEa3JPcYFeVAEOhBKMQQrykpBca06APcRkiFCLNGH5b9YR6aKQA4EP8+cWkFIu2xdl3L+5/9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/1e77dc6fce06f5a577ab0e4d0674e779/dbdff/release.jpg\",\n    \"srcSet\": [\"/static/1e77dc6fce06f5a577ab0e4d0674e779/0988f/release.jpg 250w\", \"/static/1e77dc6fce06f5a577ab0e4d0674e779/d1f95/release.jpg 500w\", \"/static/1e77dc6fce06f5a577ab0e4d0674e779/dbdff/release.jpg 1000w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/erogol\"\n  }, \"Eren G\\xF6lge\")), mdx(\"p\", null, \"This new version introduces a new \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://tts.readthedocs.io/en/latest/models/forward_tts.html\"\n  }, \"ForwardTTS API\"), \"\\nand 2 pre-trained models, an English \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.03802\"\n  }, \"SpeedySpeech\"), \" model\\ntrained on LJSpeech and a fine-tuned \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2106.07889\"\n  }, \"UnivNet\"), \" vocoder.\"), mdx(\"p\", null, \"Forward TTS API provides a unified interface for all the current and future feed-forward TTS\\nmodels. We currently support \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2008.03802\"\n  }, \"SpeedySpeech\"), \",\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/2006.06873\"\n  }, \"FastPitch\"), \", \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://arxiv.org/abs/1905.09263\"\n  }, \"FastSpeech\"), \"\\narchitectures through this API. You can also create your own custom architectures by defining\\nyour own Encoder, Decoder networks without any other fine-grained changes.\"), mdx(\"p\", null, \"We are also releasing the following pre-trained models:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"English \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2008.03802\"\n  }, \"SpeedySpeech\"), \" model trained on the LJSpeech dataset.\\nThis is the most compact TTS model we\\u2019ve released to the date.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"tts --text \\\"This is a sample text for my model to speak.\\\" --model_name tts_models/en/ljspeech/speedy-speech\\n\")), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://arxiv.org/abs/2106.07889\"\n  }, \"UnivNet\"), \" vocoder fine-tuned for the above model.\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"tts --text \\\"This is how it is.\\\" --model_name tts_models/en/ljspeech/tacotron2-DDC_ph\\n\")), mdx(\"p\", null, \"Check the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/coqui-ai/TTS/releases/tag/v0.3.0\"\n  }, \"release notes\"), \" for all the details\\nof the release and \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/coqui-ai/TTS/issues/378\"\n  }, \"dev plans\"), \" to see what is next.\"), mdx(\"h3\", {\n    \"id\": \"tts-papers-picks-of-the-month\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#tts-papers-picks-of-the-month\",\n    \"aria-label\": \"tts papers picks of the month permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83D\\uDCCETTS papers picks of the month\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66.8%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wgARCAANABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAUGA//EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAG8fTjqGJiV/8QAGhAAAgMBAQAAAAAAAAAAAAAAAAECAxEhIv/aAAgBAQABBQKjsYYnqRTLzWzT/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGBAAAgMAAAAAAAAAAAAAAAAAABABETH/2gAIAQEABj8CKULD/8QAHRAAAgIBBQAAAAAAAAAAAAAAAREAITEQUXGhsf/aAAgBAQABPyHIa9jhO4KABXMVUMCFR30P/9oADAMBAAIAAwAAABCMz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EAB0QAQEAAgMAAwAAAAAAAAAAAAERACExQWFRgfD/2gAIAQEAAT8QE79Ycp9ayZ+Irb85V2jkm+5fmpmEui4RejKd/pkoKGl5c//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/ee7ae83975f5a8e36a44fa9649c1ad37/dbdff/monthly-papers.jpg\",\n    \"srcSet\": [\"/static/ee7ae83975f5a8e36a44fa9649c1ad37/0988f/monthly-papers.jpg 250w\", \"/static/ee7ae83975f5a8e36a44fa9649c1ad37/d1f95/monthly-papers.jpg 500w\", \"/static/ee7ae83975f5a8e36a44fa9649c1ad37/dbdff/monthly-papers.jpg 1000w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/erogol\"\n  }, \"Eren G\\xF6lge\")), mdx(\"h4\", {\n    \"id\": \"towards-universal-text-to-speech-pdf\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#towards-universal-text-to-speech-pdf\",\n    \"aria-label\": \"towards universal text to speech pdf permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"Towards Universal Text-to-Speech (\", mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"http://www.interspeech2020.org/uploadfile/pdf/Wed-3-4-3.pdf\"\n  }, \"PDF\"), \")\"), mdx(\"p\", null, \"This paper presents a multilingual TTS framework that can be trained on 1250 hours of professional recordings\\nfrom multiple languages and then fine-tuned with new speakers and languages with only 5-6 minutes of recordings.\"), mdx(\"p\", null, \"The model proposed in the paper comprises an encoder-decoder Transformer model with a speaker and language\\nconditioning networks and a WaveNet vocoder. The conditioning networks take one-hot vectors representing\\nthe speaker or language ID and project to a hidden conditioning representation that is concatenated to\\nthe encoder output.\"), mdx(\"p\", null, \"This show that this model can learn low-resource languages that cannot be learned by single speaker models\\ndue to insufficient data. In their experiments, a single speaker model needs at least 3 hours of recordings\\nwhereas the proposed model is able to learn with only 6 minutes.\"), mdx(\"h4\", {\n    \"id\": \"adaspeech-adaptive-text-to-speech-for-custom-voice-pdf\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"#adaspeech-adaptive-text-to-speech-for-custom-voice-pdf\",\n    \"aria-label\": \"adaspeech adaptive text to speech for custom voice pdf permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"AdaSpeech: Adaptive Text to Speech for Custom Voice (\", mdx(\"a\", {\n    parentName: \"h4\",\n    \"href\": \"https://openreview.net/pdf?id=Drynvt7gg4L\"\n  }, \"PDF\"), \")\"), mdx(\"p\", null, \"This paper presents a way to learn new speakers with a single backbone architecture while keeping the number\\nof new parameters introduced to the system small.\"), mdx(\"p\", null, \"The overall architecture is based on the FastSpeech2 model with Pitch and Variance predictors. They also\\nintroduce 3 more conditioning networks for better understanding the acoustic properties of a speaker.\"), mdx(\"p\", null, \"All the networks use Layer Normalisation at different stages. They proposed Conditional Layer Normalisation\\nas a means to reduce the complexity required for fine-tuning with each new speaker.\"), mdx(\"p\", null, \"They propose to train separate Speaker Conditioning modules to predict the scale and bias values for each\\nLayer Normalisation layer. This way, they are able to store only these Speaker Conditioning modules for\\neach speaker and keep the rest of the model the same as they add more speakers to the system\"), mdx(\"h3\", {\n    \"id\": \"-building-coqui-stt-for-responsiveness\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#-building-coqui-stt-for-responsiveness\",\n    \"aria-label\": \" building coqui stt for responsiveness permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83C\\uDFC3\\uD83C\\uDFFF Building Coqui STT for responsiveness\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66.8%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wgARCAANABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABQAG/8QAFwEAAwEAAAAAAAAAAAAAAAAAAQIEBf/aAAwDAQACEAMQAAABMJzziY5Njo2//8QAGxAAAgMAAwAAAAAAAAAAAAAAAwQCBQYBByX/2gAIAQEAAQUC6/qRWZec/wCkXOGaNlbNgTtZObgnyRgz/8QAGBEAAwEBAAAAAAAAAAAAAAAAAAEhAjH/2gAIAQMBAT8B32CUP//EABYRAQEBAAAAAAAAAAAAAAAAAAERAP/aAAgBAgEBPwFJdHf/xAAjEAACAQMEAQUAAAAAAAAAAAABAgMAERIEISIxFDJBUWKx/9oACAEBAAY/AtRJqI0OmVSCCw4/a1L4jCSI7qrG2R9xUrI0YAa3OZQf2hDEyoswxe63yHxTrHI0GJJv6t8rUy4ddm/df//EABsQAQACAwEBAAAAAAAAAAAAAAERIQAxQWHw/9oACAEBAAE/Ib/j1VOlx7jhSNBYVb9eJ0gwEnjh8h42jtjvAmWyBO1L3B8pUdDrqs//2gAMAwEAAgADAAAAECA//8QAGREBAAMBAQAAAAAAAAAAAAAAAQARIbFh/9oACAEDAQE/EA1TW76JnOxwFz//xAAZEQADAAMAAAAAAAAAAAAAAAAAAREhoeH/2gAIAQIBAT8QZQUcPXT/xAAbEAEBAAMBAQEAAAAAAAAAAAABEQAhMVFBgf/aAAgBAQABPxAMTJpYdlAJHFmH2ghTIjbyD2JrDpTfiKNWqH5h14UEaQYxnxMloq0AKAAGirQpMd0YrlWBwfKz1z//2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/2d77532e872dd695eb55f2495fa33512/dbdff/stt-responsiveness.jpg\",\n    \"srcSet\": [\"/static/2d77532e872dd695eb55f2495fa33512/0988f/stt-responsiveness.jpg 250w\", \"/static/2d77532e872dd695eb55f2495fa33512/d1f95/stt-responsiveness.jpg 500w\", \"/static/2d77532e872dd695eb55f2495fa33512/dbdff/stt-responsiveness.jpg 1000w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/reuben\"\n  }, \"Reuben Morais\")), mdx(\"p\", null, \"One of the most exciting aspects of working on speech technology is the promise of a future where interactions\\nwith devices can be as fluid and effortless as telling someone what you\\u2019re trying to achieve. To be understood\\nby devices rather than needing to learn many languages.\"), mdx(\"p\", null, \"In everyday usage, we usually start off with a very clear task in mind: check the shipping status of the thing\\nyou ordered last week, try to find a good day and time to fit a coffee and catch-up with a friend, make sure\\nyou\\u2019re not forgetting any of the documents you\\u2019re supposed to bring for the visa application. But before you\\ncan accomplish those tasks, you have to convert them into sequences of steps in a language that your phone\\ncan understand.\"), mdx(\"p\", null, \"We\\u2019re all essentially programming our devices, and not in a fun, playful way: we still have to work to get\\nthem to do very simple tasks. As the technical capabilities of consumer devices grow more and more, so does\\nthe complexity of the languages we use to control them. As these devices become more ubiquitous and more\\ninteractive, from wearables to virtual reality to brain-computer interfaces, we need better ways to interact\\nwith and control our devices, if we want to explore all their potential.\"), mdx(\"p\", null, \"At Coqui we believe conversational interfaces are the key to solving many of these user experience problems\\nand multiplying the potential of what devices can do for all people, even those who aren\\u2019t great fans of\\nprogramming. Speech technology has made great strides in the past few years: we\\u2019ve built systems that learn\\nlanguages by themselves, and that often perform better than humans. But there\\u2019s also still a lot to do:\\nspeech AI needs to speak many more languages, it needs to be more intelligent and adaptable, and it needs to\\nbe more responsive.\"), mdx(\"p\", null, \"We\\u2019re hard at work making this a reality: a key focus of our speech-to-text engine Coqui STT has been\\nresponsiveness, from the conception of the project. Latency in user interactions matters. A lot. Ask a user\\nexperience designer. Ask someone who works on optimizing conversions. Or just remember what it feels like to\\nhave a weird conversation filled with awkward silences. This is why we spent a ton of time optimizing the\\ninference library that powers all \\uD83D\\uDC38STT packages: keeping the core library lean, making it end-to-end\\nstreamable, using efficient data structures that can be loaded quickly from disk, and testing it extensively.\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"50%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABcRAAAXEQHKJvM/AAACBElEQVQoz32T63KbMBCFef/36Rv0Fk8y6aSp41twMBiDDQiExE3A1yXpTH+1Z0ajRVqdvZzFs8GROvCp6pqqLNFaY62FeaapNbqqqK5HVHahUgqtCt7hNPR/bMHc3nAmxnt7XvH69J0wOhMGAVEYvhMvGPoe50aG6sTYlrjB4frug6FLoTn/JdQ+fb7BS8uE8y3k185nE4SsdweO54SittyfFKvI8Hn9yuaScxfWfDl+nCWSsS5CcuG3C2N/Zshe8LqmlSwctlA02x2tlFv7PiY4oSWAOV04hy9UWUrph5RBhAoS8u2KPNvRXQv6IEavPpElj3j9UtY4UhVyIauutPQspZWyizjGZhnB6SDniuTtSFcqqlTI85j4Folfhb1lxMcNyuZ4szT/X+i6lqLIMSKUkmCFCGJMzf/g6abDdo7M9OSNo7DLPlC2jqsZKNqJa91T95PYI5n45HagcRO9CNaNE05y6oaBcRrxbrolqTru9lfufp54ChU/9gnrt4zHQ8rDNubrPmMTKe63Cd/WZx72KZerjJMELZShqQxOSh+nWUTpOqZ5YpDS5tcDY2MZwjf6S0QTBYyytLoxGy1i7ZjTC81yH4c0TUOfyLd/oHz+KYQT3iiCTGIYUXuQHljZrQjVivJGelgaiy9ipNcbR5nRpbxKJqGXN8sP0Ilf44b3Nwt+A6Qn+HYezBrAAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/6b9f563c961d7e0a23c19ddf5d944531/da8b6/stt-latancy.png\",\n    \"srcSet\": [\"/static/6b9f563c961d7e0a23c19ddf5d944531/43fa5/stt-latancy.png 250w\", \"/static/6b9f563c961d7e0a23c19ddf5d944531/c6e3d/stt-latancy.png 500w\", \"/static/6b9f563c961d7e0a23c19ddf5d944531/da8b6/stt-latancy.png 1000w\", \"/static/6b9f563c961d7e0a23c19ddf5d944531/2e9ed/stt-latancy.png 1500w\", \"/static/6b9f563c961d7e0a23c19ddf5d944531/9fabd/stt-latancy.png 2000w\", \"/static/6b9f563c961d7e0a23c19ddf5d944531/6f79e/stt-latancy.png 2100w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"We\\u2019ve previously talked about some of this work, such as the changes needed to make the entire inference\\nprocess streamable. The diagram above shows the latency gains from this change alone. You can read more\\nabout it in \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://coqui.ai/blog/stt/deepspeech-0-6-speech-to-text-engine\"\n  }, \"our blog post\"), \".\"), mdx(\"p\", null, \"We think responsiveness is crucial for building engaging, enjoyable user experiences with speech. We will\\ncontinue to push the boundaries of performance for speech AI, creating more accurate and more efficient\\nmodels, moving processing as close as possible to end users. We\\u2019ll make it as easy as calling a SaaS\\nendpoint on a datacenter half a continent away, but with snappy responses for engaged conversations without\\nawkward silences.\"), mdx(\"p\", null, \"If this sounds like something you\\u2019d like to work on, \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://coqui.ai/jobs\"\n  }, \"we\\u2019re hiring\"), \"! Coqui is looking\\nfor talented engineers with experience in speech AI, MLOps and full stack web development. Come help us\\nmake this future a reality!\"), mdx(\"h3\", {\n    \"id\": \"-voice-lunch\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#-voice-lunch\",\n    \"aria-label\": \" voice lunch permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83C\\uDF71 Voice Lunch\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66.8%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wgARCAANABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAMCBQYH/8QAFQEBAQAAAAAAAAAAAAAAAAAAAwT/2gAMAwEAAhADEAAAAe1QtFEulFFAf//EABoQAAMBAAMAAAAAAAAAAAAAAAMEBQACEhP/2gAIAQEAAQUCqvlQWn1SEJvLiyNOKsmXtv/EABgRAQEAAwAAAAAAAAAAAAAAAAIBEBEx/9oACAEDAQE/AShBq9x//8QAGBEBAQADAAAAAAAAAAAAAAAAAQIDECH/2gAIAQIBAT8BuMjYjzX/xAAgEAACAgEDBQAAAAAAAAAAAAABAgMREgAQMRMhMmGR/9oACAEBAAY/AlMCZyuaHy9RM0yywyt06ruG9bYuLHOlkUFnUsy5HxJ52//EABwQAQACAwADAAAAAAAAAAAAAAEAESExUUFxgf/aAAgBAQABPyHEaXSwyV/CEH4CRYpY2Yd37gDE3OKdHpGj4F3kg7WL5Lk//9oADAMBAAIAAwAAABA7/wD/xAAZEQADAAMAAAAAAAAAAAAAAAAAAUERIcH/2gAIAQMBAT8QeEVOzZk//8QAGhEAAQUBAAAAAAAAAAAAAAAAQQABESFh8P/aAAgBAgEBPxATIdujLcVDr//EABsQAQEAAwADAAAAAAAAAAAAAAERACExQXGR/9oACAEBAAE/EAucHiUFLt1T2Zo6rDogOgQRLw4DTjkcYEGD4nhK/cjpuf0JwC6KiQguCUl3n//Z')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/26e280c36695e2d0c351ef812239d70f/dbdff/voice-lunch.jpg\",\n    \"srcSet\": [\"/static/26e280c36695e2d0c351ef812239d70f/0988f/voice-lunch.jpg 250w\", \"/static/26e280c36695e2d0c351ef812239d70f/d1f95/voice-lunch.jpg 500w\", \"/static/26e280c36695e2d0c351ef812239d70f/dbdff/voice-lunch.jpg 1000w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/JRMeyer\"\n  }, \"Josh Meyer\")), mdx(\"p\", null, \"Coqui made its first appearance on \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://voicelunch.com/\"\n  }, \"Voice Lunch\"), \". Our co-founder, Josh Meyer, walked a\\nvirtual room full of linguists (many of whom don\\u2019t usually write code) through one of our beginner-friendly\\nPython notebooks. Each participant was able to train a speech-to-text model for the Serbian language, on their\\nvery own!\"), mdx(\"p\", null, \"Check out the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://colab.research.google.com/github/coqui-ai/STT/blob/main/notebooks/train_with_common_voice.ipynb\"\n  }, \"notebook\"), \"\\nfor yourself and train your own model\\u2026 you don\\u2019t have to know how to code, and it\\u2019s fun!\"), mdx(\"h3\", {\n    \"id\": \"-university-of-groningen\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", {\n    parentName: \"h3\",\n    \"href\": \"#-university-of-groningen\",\n    \"aria-label\": \" university of groningen permalink\",\n    \"className\": \"anchor before\"\n  }, mdx(\"svg\", {\n    parentName: \"a\",\n    \"xmlns\": \"http://www.w3.org/2000/svg\",\n    \"width\": \"16\",\n    \"height\": \"16\",\n    \"focusable\": \"false\",\n    \"viewBox\": \"0 0 16 16\"\n  }, \"\\n  \", mdx(\"path\", {\n    parentName: \"svg\",\n    \"fill\": \"currentColor\",\n    \"d\": \"M4.441 7.38l.095.083.939.939-.708.707-.939-.939-2 2-.132.142a2.829 2.829 0 003.99 3.99l.142-.132 2-2-.939-.939.707-.708.94.94a1 1 0 01.083 1.32l-.083.094-2 2A3.828 3.828 0 01.972 9.621l.15-.158 2-2A1 1 0 014.34 7.31l.101.07zm7.413-3.234a.5.5 0 01.057.638l-.057.07-7 7a.5.5 0 01-.765-.638l.057-.07 7-7a.5.5 0 01.708 0zm3.023-3.025a3.829 3.829 0 01.15 5.257l-.15.158-2 2a1 1 0 01-1.32.083l-.094-.083-.94-.94.708-.707.939.94 2-2 .132-.142a2.829 2.829 0 00-3.99-3.99l-.142.131-2 2 .939.939-.707.708-.94-.94a1 1 0 01-.082-1.32l.083-.094 2-2a3.828 3.828 0 015.414 0z\"\n  }))), \"\\uD83C\\uDF93 University of Groningen\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1000px\"\n    }\n  }, \"\\n      \", mdx(\"span\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"18.8%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wgARCAAEABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAEDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAT/2gAMAwEAAhADEAAAAYuCs1QZ3//EABkQAQACAwAAAAAAAAAAAAAAAAMCBQABEf/aAAgBAQABBQKVYSFXnqKR4ef/xAAYEQACAwAAAAAAAAAAAAAAAAAAAgEiMf/aAAgBAwEBPwFJsLh//8QAFhEAAwAAAAAAAAAAAAAAAAAAAhAy/9oACAECAQE/ATlf/8QAGxAAAgMAAwAAAAAAAAAAAAAAAQIAAxExQoH/2gAIAQEABj8CpbXBXjGlFPUQqFHs/8QAGBABAAMBAAAAAAAAAAAAAAAAAQARITH/2gAIAQEAAT8hYFd4utwMaVW9cgNAC7pn/9oADAMBAAIAAwAAABD8P//EABgRAAMBAQAAAAAAAAAAAAAAAAABESHw/9oACAEDAQE/EGVvYM4P/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAEhMf/aAAgBAgEBPxCEHp//xAAZEAEAAwEBAAAAAAAAAAAAAAABABEhQaH/2gAIAQEAAT8Qp8tTGsSBusEhqmpDx55MkWwpvW5//9k=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"IMAGE\",\n    \"title\": \"IMAGE\",\n    \"src\": \"/static/586b2ac858f0026a7e8a17be070cd150/dbdff/groningen.jpg\",\n    \"srcSet\": [\"/static/586b2ac858f0026a7e8a17be070cd150/0988f/groningen.jpg 250w\", \"/static/586b2ac858f0026a7e8a17be070cd150/d1f95/groningen.jpg 500w\", \"/static/586b2ac858f0026a7e8a17be070cd150/dbdff/groningen.jpg 1000w\"],\n    \"sizes\": \"(max-width: 1000px) 100vw, 1000px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n    \")), mdx(\"p\", null, \"By \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/JRMeyer\"\n  }, \"Josh Meyer\")), mdx(\"p\", null, \"Coqui has already made its way into the curriculum of the next generation of Speech Tech developers. Josh Meyer\\ngave \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://docs.google.com/presentation/d/1nz0PAFfApny3rfZM3v_BUOIlJRy4XR1Jys3TOWNllPY/edit?usp=sharing\"\n  }, \"an invited lecture\"), \"\\nto the inaugural class of Masters students at the \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.rug.nl/masters/voice-technology/\"\n  }, \"University of Groningen\\u2019s new MSc in Voice Technology\"), \".\\nThese students will be building the future of voice, and they\\u2019re starting their journey with Coqui in their\\ntoolbox.\"), mdx(\"p\", null, \"The presentation covered both STT and TTS, with a walk-through of one of our\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://colab.research.google.com/github/coqui-ai/STT/blob/main/notebooks/train_with_common_voice.ipynb\"\n  }, \"Python notebooks\"), \".\\nThe University of Groningen is located in a Frisian-speaking region of the Netherlands, and there\\u2019s a keen\\ninterest in traditionally under-served languages among students and faculty. Coqui\\u2019s fine-tuning capabilities\\nand multilingual lean make it a great fit for this next generation of language technologists.\"));\n}\n;\nMDXContent.isMDXComponent = true;","tableOfContents":{"items":[{"url":"#work-at-coqui","title":"üë©‚ÄçüíªWork at Coqui"},{"url":"#hello-","title":"Hello! üëãüê∏"},{"url":"#coqui-stt-10-released","title":"Coqui üê∏STT 1.0 Released"},{"url":"#-best-ever-stt-english-model-","title":"üî• Best EVER üê∏STT English model üî•"},{"url":"#v030-tts-delivered-fresh","title":"v0.3.0, üê∏TTS Delivered Fresh"},{"url":"#tts-papers-picks-of-the-month","title":"üìéTTS papers picks of the month"},{"url":"#-building-coqui-stt-for-responsiveness","title":"üèÉüèø Building Coqui STT for responsiveness"},{"url":"#-voice-lunch","title":"üç± Voice Lunch"},{"url":"#-university-of-groningen","title":"üéì University of Groningen"}]}}},"pageContext":{"frontmatter":{"title":"Coqui's Seventh Mondays Newsletter","date":"October 4, 2021"},"fileAbsolutePath":"/home/runner/work/coqui-ai.github.io/coqui-ai.github.io/src/pages/newsletter/04-10-2021.mdx"}},"staticQueryHashes":["1942088059","3709355695","932324783"]}