{"componentChunkName":"component---src-templates-model-card-template-tsx","path":"/portuguese/itml/v0.1.1","result":{"data":{"allGithubData":{"nodes":[{"data":{"repository":{"releases":{"nodes":[{"description":"# Ukrainian STT v0.4 (Yurii Paniv)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Yurii Paniv](https://github.com/robinhad) and released under the [voice-recognition-ua](https://github.com/robinhad/voice-recognition-ua) project.\r\n- Model language: Ukrainian / —É–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –º–æ–≤–∞ / `uk`\r\n- Model date: Accessed from [Github](https://github.com/robinhad/voice-recognition-ua/releases/tag/v0.4) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.4`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [voice-recognition-ua](https://github.com/robinhad/voice-recognition-ua)\r\n- License: CC BY-NC 4.0\r\n- Citation details: `@misc{ukrainian-stt-paniv,\r\nauthor = {Paniv,Yurii},\r\ntitle = {Ukrainian STT},\r\npublisher = {voice-recognition-ua},\r\njournal = {Github},\r\nhowpublished = {\\url{https://github.com/robinhad/voice-recognition-ua/releases/tag/v0.4}},\r\ncommit={1252a9e9337ceeff52fe9772dc8802f4337ccff3}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Ukrainian Language](https://en.wikipedia.org/wiki/Ukrainian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Github](https://github.com/robinhad/voice-recognition-ua/releases/tag/v0.4).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|57.2\\%|16.3\\%|\r\n\t\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.76`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model is trained on a total of 1,230 hours from the Ukrainian Dataset at Academic torrents and Common Voice Ukrainian 6.1.\r\n\r\n## Evaluation data\r\n\r\nThis model was tested on Common Voice Ukrainian 6.1.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be misused to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Ukrainian STT v0.4","tagName":"ukrainian/robinhad/v0.4","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/ukrainian/robinhad/v0.4/alphabet.txt","name":"alphabet.txt","size":378},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/ukrainian/robinhad/v0.4/LICENSE","name":"LICENSE","size":57},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/ukrainian/robinhad/v0.4/model.pbmm","name":"model.pbmm","size":188973767},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/ukrainian/robinhad/v0.4/model.tflite","name":"model.tflite","size":47346544},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/ukrainian/robinhad/v0.4/MODEL_CARD","name":"MODEL_CARD","size":4464},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/ukrainian/robinhad/v0.4/kenlm.scorer","name":"kenlm.scorer","size":420827024}]}},{"description":"# Welsh STT v21.03 (Dewi Bryn Jones)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Dewi Bryn Jones](https://github.com/DewiBrynJones) and released by the [Techiaith Language Technologies Unit](https://github.com/techiaith)\r\n- Model language: Welsh / Cymraeg / `cy`\r\n- Model date: Accessed from [Github](https://github.com/techiaith/docker-deepspeech-cy/releases/tag/21.03) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v21.03`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [docker-deepspeech-cy](https://github.com/techiaith/docker-deepspeech-cy)\r\n- License: MIT\r\n- Citation details: `@misc{welsh-stt-dewibrynjones,\r\nauthor = {Dewi Bryn Jones},\r\ntitle = {Docker DeepSpeech Cymraeg},\r\npublisher = {Techiaith},\r\njournal = {docker-deepspeech-cy},\r\nhowpublished = {\\url{https://github.com/techiaith/docker-deepspeech-cy/releases/tag/21.03}}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Welsh Language](https://en.wikipedia.org/wiki/Welsh_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nWord Error Rates and Character Error Rates were not reported for this model.\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.76`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThese models were trained with the Welsh dataset from the [Common Voice Corpus 6.1](https://commonvoice.mozilla.org/datasets) in addition to a small dataset of validated recordings donated by the first users of Bangor University's Language Technology Unit's online automatic transcription website service: [Trawsgrifiwr Ar-lein](https://trawsgrifiwr.techiaith.cymru). [Detailed release notes here](https://github.com/techiaith/docker-deepspeech-cy/releases/tag/21.03).\r\n\r\n## Evaluation data\r\n\r\nWith a language model, the Welsh STT model had a Word Error Rate of 11\\%. [Detailed release notes here](https://github.com/techiaith/docker-deepspeech-cy/releases/tag/21.03).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Welsh STT v21.03","tagName":"welsh/techiaith/v21.03","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/welsh/techiaith/v21.03/alphabet.txt","name":"alphabet.txt","size":100},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/welsh/techiaith/v21.03/LICENSE","name":"LICENSE","size":1067},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/welsh/techiaith/v21.03/model.pbmm","name":"model.pbmm","size":189039018},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/welsh/techiaith/v21.03/model.tflite","name":"model.tflite","size":47362992},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/welsh/techiaith/v21.03/MODEL_CARD","name":"MODEL_CARD","size":4723},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/welsh/techiaith/v21.03/techiaith_bangor_transcribe_21.03.scorer","name":"techiaith_bangor_transcribe_21.03.scorer","size":51242608}]}},{"description":"# Catalan STT v0.14.0 (Ciaran O'Reilly)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained and released by [Ciaran O'Reilly](https://github.com/ccoreilly)\r\n- Model language: Catalan / Catal√† / `ca`\r\n- Model date: Accessed from [Github](https://github.com/ccoreilly/deepspeech-catala/releases/tag/0.14.0) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.14.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [deepspeech-catala](https://github.com/ccoreilly/deepspeech-catala)\r\n- License: MIT\r\n- Citation details: `@misc{catalan-ccoreilly,\r\nauthor = {O'Reilly,Ciaran},\r\ntitle = {Deepspeech Catal√†},\r\npublisher = {Github},\r\njournal = {deepspeech-catala},\r\nhowpublished = {\\url{https://github.com/ccoreilly/deepspeech-catala}}\r\ncommit = {21da2be7cace9f87ac2445e51b82703d1fee0849}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Catalan Language](https://en.wikipedia.org/wiki/catalan_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Github](https://github.com/ccoreilly/deepspeech-catala#wer-del-dataset-test-de-cada-model).\r\n\r\n|Test Dataset | WER|\r\n|-------------|----|\r\n|Common Voice 6.1 + ParlamentParla | 13,29\\%|\r\n|Google Crowdsourced | 9,05\\%|\r\n|Sant Jordi | 18,84\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.71`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on [Catalan Common Voice 6.1](commonvoice.mozilla.org/datasets) and [ParlamentParla Clean](https://www.openslr.org/59/).\r\n\r\n## Evaluation data\r\n\r\nThe model was tested on [Catalan Common Voice 6.1](commonvoice.mozilla.org/datasets), [ParlamentParla Clean](https://www.openslr.org/59/), the [Catalan Google Crowdsourced Corpus](https://www.openslr.org/69/), and a private corpus ([Sant Jordi](https://github.com/ccoreilly/deepspeech-catala#corpus-emprats)).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Catalan STT v0.14.0","tagName":"catalan/ccoreilly/v0.14.0","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/catalan/ccoreilly/v0.14.0/LICENSE","name":"LICENSE","size":1067},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/catalan/ccoreilly/v0.14.0/model.pbmm","name":"model.pbmm","size":189014748},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/catalan/ccoreilly/v0.14.0/model.tflite","name":"model.tflite","size":47356808},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/catalan/ccoreilly/v0.14.0/alphabet.txt","name":"alphabet.txt","size":364},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/catalan/ccoreilly/v0.14.0/MODEL_CARD","name":"MODEL_CARD","size":4678},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/catalan/ccoreilly/v0.14.0/kenlm-aina-3-p10.scorer","name":"kenlm-aina-3-p10.scorer","size":304365616}]}},{"description":"# German STT v0.9.0 (Aashish Agarwal)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Aashish Agarwal](https://github.com/AASHISHAG) and released under the [deepspeech-german](https://github.com/AASHISHAG/deepspeech-german) project.\r\n- Model date: Accessed from [deepspeech-german](https://github.com/AASHISHAG/deepspeech-german) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.9.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [deepspeech-german](https://github.com/AASHISHAG/deepspeech-german)\r\n- License: Apache 2.0\r\n- Citation details: `@inproceedings{agarwal-zesch-2019-german,\r\nauthor = \"Aashish Agarwal and Torsten Zesch\",\r\ntitle = \"German End-to-end Speech Recognition based on DeepSpeech\",\r\nbooktitle = \"Preliminary proceedings of the 15th Conference on Natural Language Processing (KONVENS 2019): Long Papers\",\r\nyear = \"2019\",\r\naddress = \"Erlangen, Germany\",\r\npublisher = \"German Society for Computational Linguistics \\& Language Technology\",\r\npages = \"111--119\"\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [German Language](https://en.wikipedia.org/wiki/German_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nNo exact statistics on transcription accuracy, however, Word Error Rate was in the range of 10% to 20% on Mozilla and Tuda-De test set. Relevant discussion [here](https://github.com/AASHISHAG/deepspeech-german/issues/39#issuecomment-812829812).\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.69`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis German STT model was bootstrapped from a pre-trained English model, and fine-tuned to German via the following datasets: Common Voice 5.1 (750 hours) + SWC (248 hours) + MAILABS (233 hours) + Tuda-De (184 hours) + Voxforge (57 hours).\r\n\r\n## Evaluation data\r\n\r\nThis German STT model was evaluated on the following datasets: Common Voice 5.1 and Tuda-De.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"German STT v0.9.0","tagName":"german/AASHISHAG/v0.9.0","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/LICENSE","name":"LICENSE","size":11358},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/model.pbmm","name":"model.pbmm","size":188940932},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/model.tflite","name":"model.tflite","size":47338296},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/MODEL_CARD","name":"MODEL_CARD","size":4718},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/alphabet.txt","name":"alphabet.txt","size":338},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/de-aashishag-1-prune-kenlm.scorer","name":"de-aashishag-1-prune-kenlm.scorer","size":564845728},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/AASHISHAG/v0.9.0/scorer.LICENSE","name":"scorer.LICENSE","size":543}]}},{"description":"# Kinyarwanda STT v0.0.1 (Digital Umuganda)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally released by [Digital Umuganda](https://digitalumuganda.com/).\r\n- Model date: Accessed from [Github](https://github.com/Digital-Umuganda/Deepspeech-Kinyarwanda/tree/master/jan-8-2021-best-kinya-deepspeech) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [deepspeech-kinyarwanda](https://github.com/Digital-Umuganda/Deepspeech-Kinyarwanda)\r\n- License: MPL 2.0\r\n- Citation details: `@misc{deepspeech-kinyarwanda, author = {Digital Umuganda}, title = {Kinyarwanda STT}, publisher = {Digital Umuganda}, journal = {Github}, howpublished = {\\url{https://github.com/Digital-Umuganda/Deepspeech-Kinyarwanda}}, commit = {7dbf6705ee38d87138f3558a21f045c40b93f083}}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Kinyarwanda Language](https://en.wikipedia.org/wiki/Kinyarwanda_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|60.1\\%|23.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.69`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nTrain on approximately 1,200 hours from the Common Voice corpus.\r\n\r\n## Evaluation data\r\n\r\nEvaluated on the test set from the Common Voice corpus.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Kinyarwanda STT v0.0.1","tagName":"kinyarwanda/digital-umuganda/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kinyarwanda/digital-umuganda/v0.0.1/alphabet.txt","name":"alphabet.txt","size":329},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kinyarwanda/digital-umuganda/v0.0.1/LICENSE","name":"LICENSE","size":16726},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kinyarwanda/digital-umuganda/v0.0.1/model.pbmm","name":"model.pbmm","size":188916323},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kinyarwanda/digital-umuganda/v0.0.1/model.tflite","name":"model.tflite","size":47332120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kinyarwanda/digital-umuganda/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4160}]}},{"description":"# Spanish STT v0.0.1 (Jaco-Assistant)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [DANBER](https://gitlab.com/DANBER) and released under the [Jaco-Assistant](https://gitlab.com/Jaco-Assistant/Scribosermo) project.\r\n- Model date: Accessed from [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [scribosermo](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master/#old-experiments)\r\n- License: GNU Lesser General Public License\r\n- Citation details: `@misc{spanish-jaco,\r\nauthor = {DANBER},\r\ntitle = {Spanish Jaco-Assistant},\r\npublisher = {Jaco-Assistant},\r\njournal = {Gitlab},\r\nhowpublished = {\\url{https://gitlab.com/Jaco-Assistant/Scribosermo}},\r\ncommit = {dfc541d2}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Spanish Language](https://en.wikipedia.org/wiki/Spanish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|16.5\\%|7.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: CommonVoice + CssTen + LinguaLibre + Mailabs + Tatoeba + Voxforge.\r\n\r\n## Evaluation data\r\n\r\nThe model was tested on the Common Voice corpus.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Spanish STT v0.0.1","tagName":"spanish/jaco-assistant/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/alphabet.txt","name":"alphabet.txt","size":332},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/LICENSE","name":"LICENSE","size":7652},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/model.pbmm","name":"model.pbmm","size":188973740},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/model.tflite","name":"model.tflite","size":47346520},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4324},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/spanish/jaco-assistant/v0.0.1/kenlm_es.scorer","name":"kenlm_es.scorer","size":279655392}]}},{"description":"# French STT v0.6 (commonvoice-fr)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained and released by the [commonvoice-fr](https://github.com/common-voice/commonvoice-fr) project\r\n- Model date: Accessed from [Github](https://github.com/common-voice/commonvoice-fr/releases/tag/fr-v0.6) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.6`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [commonvoice-fr](https://github.com/common-voice/commonvoice-fr)\r\n- License: MPL 2.0\r\n- Citation details: `@misc{commonvoice-fr,\r\nauthor = {commonvoice-fr Contributors},\r\ntitle = {Common Voice STT Model},\r\npublisher = {Github},\r\njournal = {GitHub repository},\r\nhowpublished = {\\url{https://github.com/common-voice/commonvoice-fr/releases/tag/fr-v0.6}},\r\ncommit = {5a0f61baf112620286b30319eb7000c57d8a20d0}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [French Language](https://en.wikipedia.org/wiki/French_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Github](https://github.com/common-voice/commonvoice-fr/releases/tag/fr-v0.6).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|African_Accented_French_test.csv|44.9\\%|24.2\\%|\r\n|M-AILABS|9.7\\%|2.7\\%|\r\n|trainingspeech|20.0\\%|6.0\\%|\r\n|Common Voice|30.1\\%|14.3\\%|\r\n|LinguaLibre|5.9\\%|1.8\\%|\r\n|CCPMF|48.7\\%|30.4\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis French STT model was trained on the following corpora:\r\n\r\n1. Lingua Libre (~40h)\r\n2. Common Voice FR (v2) (~490h, en autorisant jusqu'√† 32 duplicatas)\r\n3. Training Speech (~180h)\r\n4. African Accented French (~15h)\r\n5. M-AILABS French (~315h)\r\n6. Centre de Conf√©rence Pierre Mend√®s France (~300h)\r\n\r\nTotal : ~1340h\r\n\r\n## Evaluation data\r\n\r\nThe model was tested on the following corpora.\r\n\r\n1. Lingua Libre\r\n2. Common Voice FR (v2)\r\n3. Training Speech\r\n4. African Accented French\r\n5. M-AILABS French\r\n6. Centre de Conf√©rence Pierre Mend√®s France\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"French STT v0.6","tagName":"french/commonvoice-fr/v0.6","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/alphabet.txt","name":"alphabet.txt","size":248},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/LICENSE","name":"LICENSE","size":16726},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/model.pbmm","name":"model.pbmm","size":189408121},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/model.tflite","name":"model.tflite","size":47455616},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/MODEL_CARD","name":"MODEL_CARD","size":4818},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/fr-cvfr-2-prune-kenlm.scorer","name":"fr-cvfr-2-prune-kenlm.scorer","size":1007565072},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.6/scorer.LICENSE","name":"scorer.LICENSE","size":543}]}},{"description":"# French STT v0.0.1 (Jaco-Assistant)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [DANBER](https://gitlab.com/DANBER) and released under the [Jaco-Assistant](https://gitlab.com/Jaco-Assistant) project.\r\n- Model date: Accessed from [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [scribosermo](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master/#old-experiments)\r\n- License: GNU Lesser General Public License\r\n- Citation details: `@misc{french-jaco,\r\nauthor = {DANBER},\r\ntitle = {French DeepSpeech for Jaco-Assistant},\r\npublisher = {Jaco-Assistant},\r\njournal = {Gitlab},\r\nhowpublished = {\\url{https://gitlab.com/Jaco-Assistant/Scribosermo}},\r\ncommit = {dfc541d2}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [French Language](https://en.wikipedia.org/wiki/French_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|19.5\\%|9.2\\%|\r\n\t\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis French STT model was trained on approximately 787 hours of Common Voice + CssTen + LinguaLibre + Mailabs + Tatoeba + Voxforge. [Read more about training here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Evaluation data\r\n\r\nThis French STT model was tested on approximately 25 hours of Common Voice. [Read more about testing here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"French STT v0.0.1","tagName":"french/jaco-assistant/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/jaco-assistant/v0.0.1/alphabet.txt","name":"alphabet.txt","size":329},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/jaco-assistant/v0.0.1/LICENSE","name":"LICENSE","size":7652},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/jaco-assistant/v0.0.1/model.pbmm","name":"model.pbmm","size":189047557},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/jaco-assistant/v0.0.1/model.tflite","name":"model.tflite","size":47365040},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/jaco-assistant/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4586},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/jaco-assistant/v0.0.1/kenlm_fr.scorer","name":"kenlm_fr.scorer","size":254972864}]}},{"description":"# German STT v0.0.1 (Jaco-Assistant)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [DANBER](https://gitlab.com/DANBER) and released under the [Jaco-Assistant](https://gitlab.com/Jaco-Assistant) project.\r\n- Model date: Accessed from [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [scribosermo](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master/#old-experiments)\r\n- License: GNU Lesser General Public License\r\n- Citation details: `@misc{german-jaco,\r\nauthor = {DANBER},\r\ntitle = {German STT for Jaco-Assistant},\r\npublisher = {Jaco-Assistant},\r\njournal = {Gitlab},\r\nhowpublished = {\\url{https://gitlab.com/Jaco-Assistant/Scribosermo}},\r\ncommit = {dfc541d2}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [German Language](https://en.wikipedia.org/wiki/German_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [Jaco-Assistant](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|12.8\\%|5.6\\%|\r\n|Tuda | 24.6\\%| 10.1\\%|\r\n|CommonVoice + Tuda + Voxforge |16.2\\%|6.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: BasFormtask, BasSprecherinnen, Common Voice, CssTen, Gothic, LinguaLibre, Kurzgesagt, Mailabs, MussteWissen, PulsReportage, SWC, Tatoeba, TerraX, Tuda, Voxforge, YKollektiv, ZamiaSpeech, and Common Voice Single Words. Read more about training [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Tuda and Common Voice. Read more about evaluation [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"German STT v0.0.1","tagName":"german/jaco-assistant/v0.0.1","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/jaco-assistant/v0.0.1/LICENSE","name":"LICENSE","size":7652},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/jaco-assistant/v0.0.1/model.pbmm","name":"model.pbmm","size":188916323},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/jaco-assistant/v0.0.1/model.tflite","name":"model.tflite","size":47332112},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/jaco-assistant/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4788},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/jaco-assistant/v0.0.1/alphabet.txt","name":"alphabet.txt","size":329},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/german/jaco-assistant/v0.0.1/kenlm_de.scorer","name":"kenlm_de.scorer","size":279121440}]}},{"description":"# Italian STT v0.0.1 (Jaco-Assistant)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [DANBER](https://gitlab.com/DANBER) and released under the [Jaco-Assistant](https://gitlab.com/Jaco-Assistant/Scribosermo) project.\r\n- Model date: Accessed from [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [scribosermo](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master/#old-experiments)\r\n- License: GNU Lesser General Public License\r\n- Citation details: `@misc{italian-jaco,\r\nauthor = {DANBER},\r\ntitle = {Italian Jaco-Assistant},\r\npublisher = {Jaco-Assistant},\r\njournal = {Gitlab},\r\nhowpublished = {\\url{https://gitlab.com/Jaco-Assistant/Scribosermo}},\r\ncommit = {dfc541d2}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Italian Language](https://en.wikipedia.org/wiki/Italian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|24.9\\%|9.4\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on approximately ~257 hours from the following corpora: Common Voice + LinguaLibre + Mailabs + Voxforge. Read more about training [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Evaluation data\r\n\r\nThe model was tested on approximately ~21 hours from Common Voice. Read more about testing [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Italian STT v0.0.1","tagName":"italian/jaco-assistant/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/jaco-assistant/v0.0.1/alphabet.txt","name":"alphabet.txt","size":329},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/jaco-assistant/v0.0.1/LICENSE","name":"LICENSE","size":7652},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/jaco-assistant/v0.0.1/model.pbmm","name":"model.pbmm","size":188916323},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/jaco-assistant/v0.0.1/model.tflite","name":"model.tflite","size":47332112},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/jaco-assistant/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4573},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/jaco-assistant/v0.0.1/kenlm_it.scorer","name":"kenlm_it.scorer","size":7746880}]}},{"description":"# Polish STT v0.0.1 (Jaco-Assistant)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [DANBER](https://gitlab.com/DANBER) and released under the [Jaco-Assistant](https://gitlab.com/Jaco-Assistant) project.\r\n- Model date: Accessed from [Gitlab](https://gitlab.com/Jaco-Assistant/Scribosermo) on March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- Code: [scribosermo](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master/#old-experiments)\r\n- License: GNU Lesser General Public License\r\n- Citation details: `@misc{polish-jaco,\r\nauthor = {DANBER},\r\ntitle = {Polish Jaco-Assistant},\r\npublisher = {Jaco-Assistant},\r\njournal = {Gitlab},\r\nhowpublished = {\\url{https://gitlab.com/Jaco-Assistant/Scribosermo}},\r\ncommit = {dfc541d2}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Polish Language](https://en.wikipedia.org/wiki/Polish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [Jaco-Assistant](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|3.4\\%|2.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: Common Voice + LinguaLibre + Mailabs. Read more about training [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on the Common Voice corpus. Read more about evaluation [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Polish STT v0.0.1","tagName":"polish/jaco-assistant/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/polish/jaco-assistant/v0.0.1/alphabet.txt","name":"alphabet.txt","size":354},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/polish/jaco-assistant/v0.0.1/LICENSE","name":"LICENSE","size":7652},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/polish/jaco-assistant/v0.0.1/model.pbmm","name":"model.pbmm","size":188981942},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/polish/jaco-assistant/v0.0.1/model.tflite","name":"model.tflite","size":47348576},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/polish/jaco-assistant/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4531},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/polish/jaco-assistant/v0.0.1/kenlm_pl.scorer","name":"kenlm_pl.scorer","size":4856464}]}},{"description":"# Komi-Zyrian STT v0.0.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Nils Hjortn√¶s](https://github.com/hjortnaes) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model date: March 31, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@inproceedings{hjortnaes-etal-2020-towards,\r\ntitle = \"Towards a Speech Recognizer for {K}omi, an Endangered and Low-Resource Uralic Language\",\r\nauthor = \"Hjortnaes, Nils and Partanen, Niko and Rie{\\ss}ler, Michael and M. Tyers, Francis\",\r\nbooktitle = \"Proceedings of the Sixth International Workshop on Computational Linguistics of Uralic Languages\",\r\nmonth = \"1\",\r\nyear = \"2020\",\r\naddress = \"Wien, Austria\",\r\npublisher = \"Association for Computational Linguistics\",\r\nurl = \"https://www.aclweb.org/anthology/2020.iwclul-1.5\",\r\npages = \"31--37\"\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Komi-Zyryan Language](https://en.wikipedia.org/wiki/Komi_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported in the [paper](https://www.aclweb.org/anthology/2020.iwclul-1.5.pdf).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|70.9\\%|100\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.95`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: BasFormtask, BasSprecherinnen, Common Voice, CssTen, Gothic, LinguaLibre, Kurzgesagt, Mailabs, MussteWissen, PulsReportage, SWC, Tatoeba, TerraX, Tuda, Voxforge, YKollektiv, ZamiaSpeech, and Common Voice Single Words. Read more about training [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Tuda and Common Voice. Read more about evaluation [here](https://gitlab.com/Jaco-Assistant/Scribosermo/-/tree/master#old-experiments).\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Komi-Zyrian STT v0.0.1","tagName":"komi/itml/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/komi/itml/v0.0.1/alphabet.txt","name":"alphabet.txt","size":439},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/komi/itml/v0.0.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/komi/itml/v0.0.1/model.pbmm","name":"model.pbmm","size":189146005},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/komi/itml/v0.0.1/model.tflite","name":"model.tflite","size":47389768},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/komi/itml/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4837}]}},{"description":"# Chuvash STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Chuvash / –ß”ë–≤–∞—à–ª–∞ / `cv`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{chuvash-stt, author = {Tyers,Francis}, title = {Chuvash STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-CV-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Chuvash Language](https://en.wikipedia.org/wiki/Chuvash_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|97.0\\%|36.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Chuvash STT v0.1.0","tagName":"chuvash/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":115},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189006573},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.0/model.tflite","name":"model.tflite","size":47354776},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4129},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.0/Chuvash-digits-yesno.scorer","name":"Chuvash-digits-yesno.scorer","size":3232}]}},{"description":"# Basque STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Basque / Euskara / `eu`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{basque-stt, author = {Tyers,Francis}, title = {Basque STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-EU-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Basque Language](https://en.wikipedia.org/wiki/Basque_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/eu/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|81.0\\%|19.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Basque STT v0.1.0","tagName":"basque/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":57},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188916324},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.0/model.tflite","name":"model.tflite","size":47332120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4116}]}},{"description":"# Luganda STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Luganda / Lugdanda / `lg`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{luganda-stt, author = {Tyers,Francis}, title = {Luganda STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-LG-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Luganda Language](https://en.wikipedia.org/wiki/Luganda_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/lg/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|97.7\\%|33.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Luganda STT v0.1.0","tagName":"luganda/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":54},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188908121},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.0/model.tflite","name":"model.tflite","size":47330064},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4123}]}},{"description":"# Breton STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Breton / Brezhoneg / `br`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{breton-stt, author = {Tyers,Francis}, title = {Breton STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-BR-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Breton Language](https://en.wikipedia.org/wiki/Breton_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|94.9\\%|41.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Breton STT v0.1.0","tagName":"breton/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":82},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188990142},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.0/model.tflite","name":"model.tflite","size":47350640},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4118},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.0/Breton-digits-yesno.scorer","name":"Breton-digits-yesno.scorer","size":2976}]}},{"description":"# Dhivehi STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Dhivehi / ﬁãﬁ®ﬁàﬁ¨ﬁÄﬁ® / `dv`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{dhivehi-stt, author = {Tyers,Francis}, title = {Dhivehi STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-DV-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Dhivehi Language](https://en.wikipedia.org/wiki/Dhivehi_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|94.7\\%|33.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Dhivehi STT v0.1.0","tagName":"dhivehi/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":149},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189096796},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.0/model.tflite","name":"model.tflite","size":47377424},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4127}]}},{"description":"# Greek STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Greek / ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨ / `el`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{greek-stt, author = {Tyers,Francis}, title = {Greek STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-EL-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Greek Language](https://en.wikipedia.org/wiki/Greek_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|88.1\\%|36.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Greek STT v0.1.0","tagName":"greek/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":107},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188981968},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.0/model.tflite","name":"model.tflite","size":47348616},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4119},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.0/Greek-digits-yesno.scorer","name":"Greek-digits-yesno.scorer","size":3056}]}},{"description":"# Estonian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Estonian / Eesti / `et`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{estonian-stt, author = {Tyers,Francis}, title = {Estonian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-ET-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Estonian Language](https://en.wikipedia.org/wiki/Estonian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|92.2\\%|29.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Estonian STT v0.1.0","tagName":"estonian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":75},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188965538},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47344472},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4126},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.0/Estonian-digits-yesno.scorer","name":"Estonian-digits-yesno.scorer","size":2816}]}},{"description":"# Finnish STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Finnish / Suomi / `fi`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{finnish-stt, author = {Tyers,Francis}, title = {Finnish STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-FI-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Finnish Language](https://en.wikipedia.org/wiki/Finnish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|99.7\\%|39.1\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Finnish STT v0.1.0","tagName":"finnish/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":58},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188916325},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.0/model.tflite","name":"model.tflite","size":47332120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.0/Finnish-digits-yesno.scorer","name":"Finnish-digits-yesno.scorer","size":3424}]}},{"description":"# Frisian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Frisian / Frysk / `fy-NL`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{frisian-stt, author = {Tyers,Francis}, title = {Frisian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-FY_NL-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Chuvash Language](https://en.wikipedia.org/wiki/Chuvash_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|79.6.\\%|29.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Frisian STT v0.1.0","tagName":"frisian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":74},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188965537},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47344472},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4127},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.0/Frisian-digits-yesno.scorer","name":"Frisian-digits-yesno.scorer","size":2912}]}},{"description":"# Georgian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Georgian / ·É•·Éê·É†·Éó·É£·Éö·Éò ·Éî·Éú·Éê / `ka`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{georgian-stt, author = {Tyers,Francis}, title = {Georgian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-KA-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Georgian Language](https://en.wikipedia.org/wiki/Georgian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ka/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|98.1\\%|34.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Georgian STT v0.1.0","tagName":"georgian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":134},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188965597},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47344528},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4152}]}},{"description":"# Hakha Chin STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Hakha Chin / Hakha Lai / `cnh`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{hakhachin-stt, author = {Tyers,Francis}, title = {Hakha Chin STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-CNH-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Hakha Chin Language](https://en.wikipedia.org/wiki/Hakha_Chin_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cnh/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|77.8\\%|32.1\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Hakha Chin STT v0.1.0","tagName":"hakha-chin/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":56},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188908123},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.0/model.tflite","name":"model.tflite","size":47330064},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4144}]}},{"description":"# Hungarian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Hungarian / Magyar nyelv / `hu`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{hungarian-stt, author = {Tyers,Francis}, title = {Hungarian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-HU-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Hungarian Language](https://en.wikipedia.org/wiki/Chuvash_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/hu/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|89.2\\%|32.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Hungarian STT v0.1.0","tagName":"hungarian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":81},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188981942},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47348584},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4137},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.0/Hungarian-digits-yesno.scorer","name":"Hungarian-digits-yesno.scorer","size":2832}]}},{"description":"# Indonesian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Indonesian / Bahasa indonesia / `id`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{indonesian-stt, author = {Tyers,Francis}, title = {Indonesian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-ID-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Indonesian Language](https://en.wikipedia.org/wiki/Indonesian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/id/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|89.7\\%|30.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Indonesian STT v0.1.0","tagName":"indonesian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":52},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188899920},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47328008},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4149},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.0/Indonesian-digits-yesno.scorer","name":"Indonesian-digits-yesno.scorer","size":3088}]}},{"description":"# Irish STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Irish / Gaeilge / `ga-IE`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{irish-stt, author = {Tyers,Francis}, title = {Irish STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-GA_IE-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Irish Language](https://en.wikipedia.org/wiki/Irish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ga-IE/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|94.3\\%|57.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Irish STT v0.1.0","tagName":"irish/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":69},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188949134},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.0/model.tflite","name":"model.tflite","size":47340352},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4119},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.0/Irish-digits-yesno.scorer","name":"Irish-digits-yesno.scorer","size":2832}]}},{"description":"# Kyrgyz STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Kyrgyz / –ö—ã—Ä–≥—ã–∑—á–∞ / `ky`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{kyrgyz-stt, author = {Tyers,Francis}, title = {Kyrgyz STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-KY-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Kyrgyz Language](https://en.wikipedia.org/wiki/Kyrgyz_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ky/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|94.1\\%|36.8\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Kyrgyz STT v0.1.0","tagName":"kyrgyz/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":110},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188990170},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.0/model.tflite","name":"model.tflite","size":47350672},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4125}]}},{"description":"# Latvian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Latvian / Latvie≈°u valoda / `lv`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{latvian-stt, author = {Tyers,Francis}, title = {Latvian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-LV-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Latvian Language](https://en.wikipedia.org/wiki/Latvian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/lv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|88.3\\%|31.1\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Latvian STT v0.1.0","tagName":"latvian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":81},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188973743},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47346528},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4131},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.0/Latvian-digits-yesno.scorer","name":"Latvian-digits-yesno.scorer","size":3008}]}},{"description":"# Lithuanian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Lithuanian / Lietuvi≈≥ kalba / `lt`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{lithuanian-stt, author = {Tyers,Francis}, title = {Lithuanian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-LT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Lithuanian Language](https://en.wikipedia.org/wiki/Lithuanian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/lt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|98.9\\%|36.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Lithuanian STT v0.1.0","tagName":"lithuanian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":81},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188981942},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47348584},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4148},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.0/Lithuanian-digits-yesno.scorer","name":"Lithuanian-digits-yesno.scorer","size":3152}]}},{"description":"# Maltese STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Maltese / Malti / `mt`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{maltese-stt, author = {Tyers,Francis}, title = {Maltese STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-MT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Maltese Language](https://en.wikipedia.org/wiki/Maltese_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/mt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|93.6\\%|33.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Maltese STT v0.1.0","tagName":"maltese/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":85},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188998344},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.0/model.tflite","name":"model.tflite","size":47352704},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.0/Maltese-digits-yesno.scorer","name":"Maltese-digits-yesno.scorer","size":3152}]}},{"description":"# Mongolian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Mongolian / –ú–æ–Ω–≥–æ–ª —Ö—ç–ª / `mn`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{mongolian-stt, author = {Tyers,Francis}, title = {Mongolian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-MN-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Mongolian Language](https://en.wikipedia.org/wiki/Mongolian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/mn/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|96.7\\%|45.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Mongolian STT v0.1.0","tagName":"mongolian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":104},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188973766},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47346552},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4146},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.0/Mongolian-digits-yesno.scorer","name":"Mongolian-digits-yesno.scorer","size":2944}]}},{"description":"# Odia STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Odia / ‡¨ì‡¨°‡¨º‡¨ø‡¨Ü / `or`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{odia-stt, author = {Tyers,Francis}, title = {Odia STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-OR-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Odia Language](https://en.wikipedia.org/wiki/Odia_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/or/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|98.9\\%|55.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Odia STT v0.1.0","tagName":"odia/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":326},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189359341},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.0/model.tflite","name":"model.tflite","size":47443360},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4112},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.0/Odia-digits-yesno.scorer","name":"Odia-digits-yesno.scorer","size":2688}]}},{"description":"# Portuguese STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Portuguese / Portugu√™s / `pt`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{portuguese-stt, author = {Tyers,Francis}, title = {Portuguese STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-PT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Portuguese Language](https://en.wikipedia.org/wiki/Portuguese_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/pt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|84.1\\%|32.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Portuguese STT v0.1.0","tagName":"portuguese/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":97},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189031152},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.0/model.tflite","name":"model.tflite","size":47360936},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4143},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.0/pt-itml-0-prune-kenlm.scorer","name":"pt-itml-0-prune-kenlm.scorer","size":242241040}]}},{"description":"# English STT v0.9.3 (Coqui)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Maintained by [Coqui](https://coqui.ai/).\r\n- Model language: English / English / `en`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.9.3`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: MPL\r\n- Citation details: `@techreport{english-stt, author = {Coqui}, title = {English STT 0.9.3}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-EN-0.9.3} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [English Language](https://en.wikipedia.org/wiki/English_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nMore detail on model training and evaluation can be found in the [release notes](https://github.com/coqui-ai/STT/releases/tag/v0.9.3).\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `0.66`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: Fisher, LibriSpeech, Switchboard, Common Voice English, and 1,700 hours of transcribed NPR (WAMU) radio shows explicitly licensed to use as training corpora.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on the LibriSpeech clean dev corpus as validation data, and LibriSpeech clean test as testing data.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"English STT v0.9.3","tagName":"english/coqui/v0.9.3","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v0.9.3/alphabet.txt","name":"alphabet.txt","size":329},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v0.9.3/LICENSE","name":"LICENSE","size":16725},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v0.9.3/model.pbmm","name":"model.pbmm","size":188915987},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v0.9.3/model.tflite","name":"model.tflite","size":47331784},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v0.9.3/MODEL_CARD","name":"MODEL_CARD","size":4139},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v0.9.3/coqui-stt-0.9.3-models.scorer","name":"coqui-stt-0.9.3-models.scorer","size":953363776}]}},{"description":"# Romanian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Romanian / Rom√¢ne»ôte / `ro`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{romanian-stt, author = {Tyers,Francis}, title = {Romanian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-RO-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Romanian Language](https://en.wikipedia.org/wiki/Romanian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ro/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|92.9\\%|34.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Romanian STT v0.1.0","tagName":"romanian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":69},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188949134},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47340352},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4132},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.0/Romanian-digits-yesno.scorer","name":"Romanian-digits-yesno.scorer","size":2832}]}},{"description":"# Sakha STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Sakha / –°–∞—Ö–∞ —Ç—ã–ª–∞ / `sah`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{sakha-stt, author = {Tyers,Francis}, title = {Sakha STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-SAH-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Sakha Language](https://en.wikipedia.org/wiki/Sakha_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/sah/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|96.3\\%|37.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Sakha STT v0.1.0","tagName":"sakha/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":110},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188990170},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.0/model.tflite","name":"model.tflite","size":47350672},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4123}]}},{"description":"# Slovenian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Slovenian / Sloven≈°ƒçina / `sl`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{slovenian-stt, author = {Tyers,Francis}, title = {Slovenian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-SL-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Slovenian Language](https://en.wikipedia.org/wiki/Slovenian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/sl/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|90.2\\%|31.1\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Slovenian STT v0.1.0","tagName":"slovenian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":61},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188924528},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47334184},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4140},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.0/Slovenian-digits-yesno.scorer","name":"Slovenian-digits-yesno.scorer","size":2624}]}},{"description":"# Czech STT v0.1.0 (Vojtƒõch Dr√°bek)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Vojtƒõch Dr√°bek](https://github.com/comodoro).\r\n- Model language: Czech / ƒçe≈°tina / `cs`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: CC-BY-NC\r\n- Citation details: `@techreport{chuvash-stt, author = {Dr√°bek,Vojtƒõch}, title = {Czech STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CS-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Czech Language](https://en.wikipedia.org/wiki/Czech_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nMore information reported on [Github](https://github.com/comodoro/deepspeech-cs/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|44.6\\%|11.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora:\r\n\r\n1. Vystadial 2016 ‚Äì Czech data\r\n2. OVM ‚Äì Ot√°zky V√°clava Moravce\r\n3. Czech Parliament Meetings\r\n4. Large Corpus of Czech Parliament Plenary Hearings\r\n5. Common Voice Czech\r\n6. Some private recordings and parts of audioboooks\r\n\r\n## Evaluation data\r\n\r\nThe model was evaluated on Common Voice Czech.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Comodoro STT v0.1.0","tagName":"czech/comodoro/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.1.0/alphabet.txt","name":"alphabet.txt","size":114},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.1.0/LICENSE","name":"LICENSE","size":57},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.1.0/model.pbmm","name":"model.pbmm","size":189088562},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.1.0/model.tflite","name":"model.tflite","size":47375328},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4181}]}},{"description":"# Italian STT 2020.8.7 (Mozilla Italia)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained and released by the [Mozilla Italia](https://github.com/MozillaItalia) Community.\r\n- Model language: Italian / italiano / `it`\r\n- Model date: August 7, 2020\r\n- Model type: `Speech-to-Text`\r\n- Model version: `2020.8.7`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: CC0\r\n- Citation details: `@techreport{italian-stt, author = {Mozilla Italia}, title = {Italian STT 2020.8.7}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-IT-2020.8.7} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Italian Language](https://en.wikipedia.org/wiki/Italian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported by [Mozilla Italia](https://github.com/MozillaItalia/DeepSpeech-Italian-Model/releases/tag/2020.08.07) (the transfer learning model).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|28.7\\%|11.8\\%|\r\n|M-AILABS|15.0\\%|4.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `1.0`\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on:\r\n\r\n1. ~130 hours of the Common Voice Italian dataset\r\n2. ~127 hours of the M-AILABS Italian dataset\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice and M-AILABS.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Italian STT 2020.8.7","tagName":"italian/mozillaitalia/2020.8.7","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/alphabet.txt","name":"alphabet.txt","size":86},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/LICENSE","name":"LICENSE","size":60},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/model.pbmm","name":"model.pbmm","size":188998006},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/model.tflite","name":"model.tflite","size":47352376},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/MODEL_CARD","name":"MODEL_CARD","size":4230},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/it-mzit-1-prune-kenlm.scorer","name":"it-mzit-1-prune-kenlm.scorer","size":390117712},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/italian/mozillaitalia/2020.8.7/scorer.LICENSE","name":"scorer.LICENSE","size":543}]}},{"description":"# Breton STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Breton / Brezhoneg / `br`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{breton-stt, author = {Tyers,Francis}, title = {Breton STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-BR-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Breton Language](https://en.wikipedia.org/wiki/Breton_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/br/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|89.1\\%|37.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Breton STT v0.1.1","tagName":"breton/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":82},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188990142},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.1/model.tflite","name":"model.tflite","size":47350632},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4119},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/breton/itml/v0.1.1/Breton-digits-yesno.scorer","name":"Breton-digits-yesno.scorer","size":2976}]}},{"description":"# Chuvash STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Chuvash / –ß”ë–≤–∞—à–ª–∞ / `cv`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{chuvash-stt, author = {Tyers,Francis}, title = {Chuvash STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-CV-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Chuvash Language](https://en.wikipedia.org/wiki/Chuvash_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|95.4\\%|33.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Chuvash STT v0.1.1","tagName":"chuvash/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":115},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":189006573},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.1/model.tflite","name":"model.tflite","size":47354776},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4130},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chuvash/itml/v0.1.1/Chuvash-digits-yesno.scorer","name":"Chuvash-digits-yesno.scorer","size":3232}]}},{"description":"# Dhivehi STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Dhivehi / ﬁãﬁ®ﬁàﬁ¨ﬁÄﬁ® / `dv`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{dhivehi-stt, author = {Tyers,Francis}, title = {Dhivehi STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-DV-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Dhivehi Language](https://en.wikipedia.org/wiki/Dhivehi_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|91.2\\%|29.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Dhivehi STT v0.1.1","tagName":"dhivehi/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":149},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":189096796},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.1/model.tflite","name":"model.tflite","size":47377416},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dhivehi/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4128}]}},{"description":"# Estonian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Estonian / Eesti / `et`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{estonian-stt, author = {Tyers,Francis}, title = {Estonian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-ET-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Estonian Language](https://en.wikipedia.org/wiki/Estonian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|89.1\\%|27.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Estonian STT v0.1.1","tagName":"estonian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":75},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188965538},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47344464},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4127},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/estonian/itml/v0.1.1/Estonian-digits-yesno.scorer","name":"Estonian-digits-yesno.scorer","size":2816}]}},{"description":"# Finnish STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Finnish / Suomi / `fi`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{finnish-stt, author = {Tyers,Francis}, title = {Finnish STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-FI-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Finnish Language](https://en.wikipedia.org/wiki/Finnish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|96.6\\%|30.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Finnish STT v0.1.1","tagName":"finnish/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":58},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188916325},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.1/model.tflite","name":"model.tflite","size":47332112},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4121},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/finnish/itml/v0.1.1/Finnish-digits-yesno.scorer","name":"Finnish-digits-yesno.scorer","size":3424}]}},{"description":"# Frisian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Frisian / Frysk / `fy-NL`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{frisian-stt, author = {Tyers,Francis}, title = {Frisian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-FY_NL-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Frisian Language](https://en.wikipedia.org/wiki/Frisian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|74.0\\%|26.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Frisian STT v0.1.1","tagName":"frisian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":74},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188965537},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47344464},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4127},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/frisian/itml/v0.1.1/Frisian-digits-yesno.scorer","name":"Frisian-digits-yesno.scorer","size":2912}]}},{"description":"# Georgian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Georgian / ·É•·Éê·É†·Éó·É£·Éö·Éò ·Éî·Éú·Éê / `ka`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{georgian-stt, author = {Tyers,Francis}, title = {Georgian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-KA-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Georgian Language](https://en.wikipedia.org/wiki/Georgian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ka/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|95.8\\%|31.1\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Georgian STT v0.1.1","tagName":"georgian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":134},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188965597},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47344520},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4153},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/georgian/itml/v0.1.1/Georgian-digits-yesno.scorer","name":"Georgian-digits-yesno.scorer","size":2768}]}},{"description":"# Greek STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Greek / ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨ / `el`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{greek-stt, author = {Tyers,Francis}, title = {Greek STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-EL-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Greek Language](https://en.wikipedia.org/wiki/Greek_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|80.2\\%|31.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Greek STT v0.1.1","tagName":"greek/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":107},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188981968},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.1/model.tflite","name":"model.tflite","size":47348608},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/greek/itml/v0.1.1/Greek-digits-yesno.scorer","name":"Greek-digits-yesno.scorer","size":3056}]}},{"description":"# Hakha Chin STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Hakha Chin / Hakha Lai / `cnh`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{hakhachin-stt, author = {Tyers,Francis}, title = {Hakha Chin STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-CNH-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Hakha Chin Language](https://en.wikipedia.org/wiki/Hakha_Chin_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/cnh/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|67.4\\%|26.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Hakha Chin STT v0.1.1","tagName":"hakha-chin/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":56},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188908123},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.1/model.tflite","name":"model.tflite","size":47330056},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hakha-chin/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4145}]}},{"description":"# Hungarian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Hungarian / Magyar nyelv / `hu`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{hungarian-stt, author = {Tyers,Francis}, title = {Hungarian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-HU-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Hungarian Language](https://en.wikipedia.org/wiki/Chuvash_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/hu/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|87.1\\%|31.8\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Hungarian STT v0.1.1","tagName":"hungarian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":81},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188981942},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47348576},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4138},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hungarian/itml/v0.1.1/Hungarian-digits-yesno.scorer","name":"Hungarian-digits-yesno.scorer","size":2832}]}},{"description":"# Indonesian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Indonesian / Bahasa indonesia / `id`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{indonesian-stt, author = {Tyers,Francis}, title = {Indonesian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-ID-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Indonesian Language](https://en.wikipedia.org/wiki/Indonesian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/id/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|80.1\\%|25.8\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Indonesian STT v0.1.1","tagName":"indonesian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":52},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188899920},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47328000},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4150},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/indonesian/itml/v0.1.1/Indonesian-digits-yesno.scorer","name":"Indonesian-digits-yesno.scorer","size":3088}]}},{"description":"# Irish STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Irish / Gaeilge / `ga-IE`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{irish-stt, author = {Tyers,Francis}, title = {Irish STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-GA_IE-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Irish Language](https://en.wikipedia.org/wiki/Irish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ga-IE/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|86.9\\%|40.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Irish STT v0.1.1","tagName":"irish/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":69},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188949134},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.1/model.tflite","name":"model.tflite","size":47340344},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/irish/itml/v0.1.1/Irish-digits-yesno.scorer","name":"Irish-digits-yesno.scorer","size":2832}]}},{"description":"# Kyrgyz STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Kyrgyz / –ö—ã—Ä–≥—ã–∑—á–∞ / `ky`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{kyrgyz-stt, author = {Tyers,Francis}, title = {Kyrgyz STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-KY-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Kyrgyz Language](https://en.wikipedia.org/wiki/Kyrgyz_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ky/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|87.1\\%|30.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Kyrgyz STT v0.1.1","tagName":"kyrgyz/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":110},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188990170},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.1/model.tflite","name":"model.tflite","size":47350664},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4126},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/kyrgyz/itml/v0.1.1/Kyrgyz-digits-yesno.scorer","name":"Kyrgyz-digits-yesno.scorer","size":2912}]}},{"description":"# Latvian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Latvian / Latvie≈°u valoda / `lv`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{latvian-stt, author = {Tyers,Francis}, title = {Latvian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-LV-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Latvian Language](https://en.wikipedia.org/wiki/Latvian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/lv/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|82.8\\%|28.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Latvian STT v0.1.1","tagName":"latvian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":81},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188973743},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47346520},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4132},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/latvian/itml/v0.1.1/Latvian-digits-yesno.scorer","name":"Latvian-digits-yesno.scorer","size":3008}]}},{"description":"# Lithuanian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Lithuanian / Lietuvi≈≥ kalba / `lt`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{lithuanian-stt, author = {Tyers,Francis}, title = {Lithuanian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-LT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Lithuanian Language](https://en.wikipedia.org/wiki/Lithuanian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/lt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|94.6\\%|31.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Lithuanian STT v0.1.1","tagName":"lithuanian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":81},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188981942},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47348576},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4149},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/lithuanian/itml/v0.1.1/Lithuanian-digits-yesno.scorer","name":"Lithuanian-digits-yesno.scorer","size":3152}]}},{"description":"# Luganda STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Luganda / Lugdanda / `lg`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{luganda-stt, author = {Tyers,Francis}, title = {Luganda STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-LG-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Luganda Language](https://en.wikipedia.org/wiki/Luganda_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/lg/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|93.1\\%|30.5\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Luganda STT v0.1.1","tagName":"luganda/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":54},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188908121},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.1/model.tflite","name":"model.tflite","size":47330056},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4124},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/luganda/itml/v0.1.1/Luganda-digits-yesno.scorer","name":"Luganda-digits-yesno.scorer","size":3232}]}},{"description":"# Maltese STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Maltese / Malti / `mt`\r\n- Model date: April 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{maltese-stt, author = {Tyers,Francis}, title = {Maltese STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-MT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Maltese Language](https://en.wikipedia.org/wiki/Maltese_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/mt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|86.4\\%|27.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Maltese STT v0.1.1","tagName":"maltese/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":85},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188998344},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.1/model.tflite","name":"model.tflite","size":47352696},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/maltese/itml/v0.1.1/Maltese-digits-yesno.scorer","name":"Maltese-digits-yesno.scorer","size":3152}]}},{"description":"# Mongolian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Mongolian / –ú–æ–Ω–≥–æ–ª —Ö—ç–ª / `mn`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{mongolian-stt, author = {Tyers,Francis}, title = {Mongolian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-MN-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Mongolian Language](https://en.wikipedia.org/wiki/Mongolian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/mn/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|90.8\\%|38.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Mongolian STT v0.1.1","tagName":"mongolian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":104},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188973766},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47346544},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4147},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mongolian/itml/v0.1.1/Mongolian-digits-yesno.scorer","name":"Mongolian-digits-yesno.scorer","size":2944}]}},{"description":"# Odia STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Odia / ‡¨ì‡¨°‡¨º‡¨ø‡¨Ü / `or`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{odia-stt, author = {Tyers,Francis}, title = {Odia STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-OR-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Odia Language](https://en.wikipedia.org/wiki/Odia_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/or/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|95.0\\%|35.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Odia STT v0.1.1","tagName":"odia/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":326},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":189359341},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.1/model.tflite","name":"model.tflite","size":47443352},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4113},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/odia/itml/v0.1.1/Odia-digits-yesno.scorer","name":"Odia-digits-yesno.scorer","size":2688}]}},{"description":"# Portuguese STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Portuguese / Portugu√™s / `pt`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{portuguese-stt, author = {Tyers,Francis}, title = {Portuguese STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-PT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Portuguese Language](https://en.wikipedia.org/wiki/Portuguese_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/pt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|73.2\\%|26.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Portuguese STT v0.1.1","tagName":"portuguese/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":97},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":189031152},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/model.tflite","name":"model.tflite","size":47360928},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4144},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/pt-itml-0-prune-kenlm.scorer","name":"pt-itml-0-prune-kenlm.scorer","size":242241040},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/scorer.LICENSE","name":"scorer.LICENSE","size":543}]}},{"description":"# Romanian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Romanian / Rom√¢ne»ôte / `ro`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{romanian-stt, author = {Tyers,Francis}, title = {Romanian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-RO-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Romanian Language](https://en.wikipedia.org/wiki/Romanian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ro/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|85.3\\%|29.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Romanian STT v0.1.1","tagName":"romanian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":69},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188949134},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47340344},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4133},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romanian/itml/v0.1.1/Romanian-digits-yesno.scorer","name":"Romanian-digits-yesno.scorer","size":2832}]}},{"description":"# Sakha STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Sakha / –°–∞—Ö–∞ —Ç—ã–ª–∞ / `sah`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{sakha-stt, author = {Tyers,Francis}, title = {Sakha STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-SAH-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Sakha Language](https://en.wikipedia.org/wiki/Sakha_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/sah/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|94.5\\%|36.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Sakha STT v0.1.1","tagName":"sakha/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":110},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188990170},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.1/model.tflite","name":"model.tflite","size":47350664},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/sakha/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4124}]}},{"description":"# Slovenian STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Slovenian / Sloven≈°ƒçina / `sl`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{slovenian-stt, author = {Tyers,Francis}, title = {Slovenian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-SL-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Slovenian Language](https://en.wikipedia.org/wiki/Slovenian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/sl/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|82.4\\%|26.8\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Slovenian STT v0.1.1","tagName":"slovenian/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":61},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188924528},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.1/model.tflite","name":"model.tflite","size":47334176},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4141},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/slovenian/itml/v0.1.1/Slovenian-digits-yesno.scorer","name":"Slovenian-digits-yesno.scorer","size":2624}]}},{"description":"# Tamil STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Tamil / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç / `ta`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{tamil-stt, author = {Tyers,Francis}, title = {Tamil STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-TA-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Tamil Language](https://en.wikipedia.org/wiki/Tamil_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ta/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|99.9\\%|46.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Tamil STT v0.1.0","tagName":"tamil/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tamil/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":194},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tamil/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tamil/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189088642},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tamil/itml/v0.1.0/model.tflite","name":"model.tflite","size":47375408},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tamil/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4119},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tamil/itml/v0.1.0/Tamil-digits-yesno.scorer","name":"Tamil-digits-yesno.scorer","size":3088}]}},{"description":"# Tatar STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Tatar / –¢–∞—Ç–∞—Ä—á–∞ / `tt`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{tatar-stt, author = {Tyers,Francis}, title = {Tatar STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-TT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Tatar Language](https://en.wikipedia.org/wiki/Tatar_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/tt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|85.8\\%|31.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Tatar STT v0.1.0","tagName":"tatar/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tatar/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":119},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tatar/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tatar/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189014776},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tatar/itml/v0.1.0/model.tflite","name":"model.tflite","size":47356840},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tatar/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4118},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/tatar/itml/v0.1.0/Tatar-digits-yesno.scorer","name":"Tatar-digits-yesno.scorer","size":2912}]}},{"description":"# Thai STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Thai / ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ / `th`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{thai-stt, author = {Tyers,Francis}, title = {Thai STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-TH-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Thai Language](https://en.wikipedia.org/wiki/Thai_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ta/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|100\\%|36.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Thai STT v0.1.0","tagName":"thai/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/thai/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":270},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/thai/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/thai/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189244499},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/thai/itml/v0.1.0/model.tflite","name":"model.tflite","size":47414528},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/thai/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4118}]}},{"description":"# Turkish STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Turkish / T√ºrk√ße / `tr`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{turkish-stt, author = {Tyers,Francis}, title = {Turkish STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-TR-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Turkish Language](https://en.wikipedia.org/wiki/Turkish_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/tr/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|89.3\\%|30.8\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Turkish STT v0.1.0","tagName":"turkish/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/turkish/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":75},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/turkish/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/turkish/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188965538},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/turkish/itml/v0.1.0/model.tflite","name":"model.tflite","size":47344464},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/turkish/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4124},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/turkish/itml/v0.1.0/Turkish-digits-yesno.scorer","name":"Turkish-digits-yesno.scorer","size":2912}]}},{"description":"# Basque STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Basque / Euskara / `eu`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{basque-stt, author = {Tyers,Francis}, title = {Basque STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-EU-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Basque Language](https://en.wikipedia.org/wiki/Basque_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/eu/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|68.7\\%|15.6\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Basque STT v0.1.1","tagName":"basque/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":57},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":188916324},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.1/model.tflite","name":"model.tflite","size":47332112},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/basque/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4117}]}},{"description":"# Romansh Vallader STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language:  Romansh Vallader / Rumantsch / `rm-vallader`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{rm-vallader-stt, author = {Tyers,Francis}, title = {Romansh Vallader STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-RM_VALLADER-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Romansh Vallader Language](https://en.wikipedia.org/wiki/Vallader_dialect) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|84.0\\%|26.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Romansh Vallader STT v0.1.0","tagName":"romansh-vallader/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-vallader/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":92},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-vallader/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-vallader/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189014749},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-vallader/itml/v0.1.0/model.tflite","name":"model.tflite","size":47356808},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-vallader/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4181}]}},{"description":"# Upper Sorbian STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Upper Sorbian / Hornjoserb≈°ƒáina / `hsb`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{upper-sorbian-stt, author = {Tyers,Francis}, title = {Upper Sorbian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-HSB-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Upper Sorbian Language](https://en.wikipedia.org/wiki/Upper_Sorbian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/ta/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|92.3\\%|32.4\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Upper Sorbian STT v0.1.0","tagName":"upper-sorbian/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/upper-sorbian/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":99},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/upper-sorbian/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/upper-sorbian/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":189031154},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/upper-sorbian/itml/v0.1.0/model.tflite","name":"model.tflite","size":47360928},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/upper-sorbian/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4171}]}},{"description":"# Romansh Sursilvan STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language:  Romansh Sursilvan / romontsch sursilvan / `rm-sursilvan`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{rm-sursilvan-stt, author = {Tyers,Francis}, title = {Romansh Sursilvan STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-RM_SURSILVAN-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Romansh Sursilvan Language](https://en.wikipedia.org/wiki/Sursilvan) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|79.6\\%|23.9\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Romansh Sursilvan STT v0.1.1","tagName":"romansh-sursilvan/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-sursilvan/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":80},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-sursilvan/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-sursilvan/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188981941},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-sursilvan/itml/v0.1.0/model.tflite","name":"model.tflite","size":47348576},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/romansh-sursilvan/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4190}]}},{"description":"# Amharic STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Amharic / ·ä†·àõ·à≠·äõ / `am`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{amharic-stt, author = {Tyers,Francis}, title = {Amharic STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-ALFFA-AM-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Amharic Language](https://en.wikipedia.org/wiki/Amharic_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/am/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|ALFFA|75.1\\%|29.4\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the Amharic subset of the [ALFFA](http://openslr.org/25/) corpus.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on the Amharic subset of the [ALFFA](http://openslr.org/25/) corpus.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Amharic STT v0.1.0","tagName":"amharic/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/amharic/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":1150},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/amharic/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/amharic/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":191049162},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/amharic/itml/v0.1.0/model.tflite","name":"model.tflite","size":47867504},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/amharic/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4206}]}},{"description":"# Wolof STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Wolof / Wolof / `wo`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{wolof-stt, author = {Tyers,Francis}, title = {Wolof STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-ALFFA-WO-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Wolof Language](https://en.wikipedia.org/wiki/Wolof_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/am/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|ALFFA|57.1\\%|18.1\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the Wolof subset of the [ALFFA](http://openslr.org/25/) corpus.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on the Wolof subset of the [ALFFA](http://openslr.org/25/) corpus.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Wolof STT v0.1.0","tagName":"wolof/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/wolof/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":66},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/wolof/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/wolof/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188932732},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/wolof/itml/v0.1.0/model.tflite","name":"model.tflite","size":47336232},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/wolof/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4183}]}},{"description":"# Yoruba STT v0.1.0 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Yoruba / √àd√® Yor√πb√° / `yo`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{yoruba-stt, author = {Tyers,Francis}, title = {Yoruba STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-ALFFA-YO-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Yoruba Language](https://en.wikipedia.org/wiki/Yoruba_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/am/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|ALFFA|71.6\\%|23.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the Yoruba subset of the [ALFFA](http://openslr.org/25/) corpus.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on the Yoruba subset of the [ALFFA](http://openslr.org/25/) corpus.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Yoruba STT v0.1.0","tagName":"yoruba/itml/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/yoruba/itml/v0.1.0/alphabet.txt","name":"alphabet.txt","size":64},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/yoruba/itml/v0.1.0/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/yoruba/itml/v0.1.0/model.pbmm","name":"model.pbmm","size":188916331},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/yoruba/itml/v0.1.0/model.tflite","name":"model.tflite","size":47332120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/yoruba/itml/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4200}]}},{"description":"# Dutch STT v0.0.1 (acabunoc)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally released by [Abigail Cabunoc Mayes](https://github.com/acabunoc).\r\n- Model language: Dutch / Nederlands / `nl`\r\n- Model date: July 12, 2020\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: MPL\r\n- Citation details: `@techreport{dutch-stt, author = {Cabunoc Mayes,Abigail}, title = {Dutch STT 0.0.1}, institution = {Coqui}, address = {\\url{https://coqui.ai/models}} year = {2020}, month = {July}, number = {STT-CV-NL-0.0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Dutch Language](https://en.wikipedia.org/wiki/Dutch_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported *using a language model*: [Github](https://github.com/acabunoc/Tutorial-train-dutch-model).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice 5.1|87.8\\%|65.3\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 660K\r\n`model.tflite`: 221K\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 5.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 5.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Dutch STT v0.0.1","tagName":"dutch/acabunoc/v0.0.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/alphabet.txt","name":"alphabet.txt","size":472},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/LICENSE","name":"LICENSE","size":16725},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/model.pbmm","name":"model.pbmm","size":675757},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/model.tflite","name":"model.tflite","size":225512},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4039},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/nl-acabunoc-1-prune-kenlm.scorer","name":"nl-acabunoc-1-prune-kenlm.scorer","size":323345856},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/dutch/acabunoc/v0.0.1/scorer.LICENSE","name":"scorer.LICENSE","size":543}]}},{"description":"# Russian STT v0.1.0 (Joe Meyer)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Joe Meyer](https://www.linkedin.com/in/joe-meyer-25753951/).\r\n- Model language: Russian / —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ / `ru`\r\n- Model date: May 12, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: CC-0 \r\n- Citation details: `@techreport{russian-stt, author = {Meyer,Joe}, title = {Russian STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {May}, number = {STT-CV6.1-RU-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Russian Language](https://en.wikipedia.org/wiki/Russian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported for a non-official held-out test set from Common Voice 6.1 *with the use of an external language model*. The official `validated.tsv` was re-processed by [CorporaCreator](https://github.com/mozilla/corporacreator) to include all repeat sentences.\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|32.3\\%|12.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on a non-official training set from Common Voice 6.1. The official `validated.tsv` was re-processed by [CorporaCreator](https://github.com/mozilla/corporacreator) to include all repeat sentences.\r\n\r\n## Evaluation data\r\n\r\nThis model was evaluated on a non-official testing set from Common Voice 6.1. The official `validated.tsv` was re-processed by [CorporaCreator](https://github.com/mozilla/corporacreator) to include all repeat sentences.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Russian STT v0.1.0","tagName":"russian/jemeyer/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/alphabet.txt","name":"alphabet.txt","size":101},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/LICENSE","name":"LICENSE","size":60},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":4562},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/model.tflite","name":"model.tflite","size":47344496},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/model.pbmm","name":"model.pbmm","size":188965564},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/wiki-ru-6gram.scorer","name":"wiki-ru-6gram.scorer","size":719764672},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/russian/jemeyer/v0.1.0/scorer.LICENSE","name":"scorer.LICENSE","size":235}]}},{"description":"# Bengali STT v0.1.0 (Alp √ñktem)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Training parameters](#training-parameters)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person and organization developing model: [Alp √ñktem](https://alpoktem.github.io/) @ [Clear Global/Translators without Borders](https://clearglobal.org/).\r\n- Model language: Bengali / ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ / `bn` / `ben`\r\n- Model date: June 9, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v0.10.0a6`\r\n- License: Custom\r\n- Citation details: `@techreport{bengali-stt, author = {\\\"Oktem, Alp}, title = {Bengali STT 0.1}, institution = {Translators without Borders}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {June}, number = {STT-BN-0.1} }`\r\n- Official page: [https://gamayun.translatorswb.org/data/](https://gamayun.translatorswb.org/data/)\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Bengali Language](https://en.wikipedia.org/wiki/Bengali_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [Large Bengali ASR training data set](https://www.openslr.org/53/). \r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Large Bengali ASR training data set|30.6\\%|11.0\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ` `\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 189.3M\r\n`general-bn.scorer`: 71.9M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nAcoustic model was trained on top of English STT model using the [Large Bengali ASR training data set](https://www.openslr.org/53/). It was converted to 16kHz WAV before training. \r\n\r\nTrain size: 203,067 samples, 199.99 hours\r\nDev size: 10,690 samples, 10.55 hours\r\n\r\nLanguage model was trained on OSCAR and Bengali portions of English-Bengali parallel corpora available from [OPUS](https://opus.nlpl.eu/). \r\n\r\nLines: 782,827 \r\nTokens: 13,953,256\r\n\r\n## Training parameters\r\n\r\n|Parameter|Value|\r\n|---------|-----|\r\n|Epochs|200|\r\n|Drop source layers|2|\r\n|Learning rate|0.001|\r\n|Dropout rate|0.2|\r\n|augment frequency_mask|[p=0.8,n=2:4,size=2:4]|\r\n|augment time_mask|[p=0.8,n=2:4,size=10:50,domain=spectrogram] |\r\n|Train/test/dev batch size|32|\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on a 2000 sample subset (1.84 hours) of [Large Bengali ASR training data set](https://www.openslr.org/53/). Testing set filenames and transcriptions are included with the model.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Bengali STT v0.1.0","tagName":"bengali/twb/v0.1.0","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/bengali/twb/v0.1.0/LICENSE","name":"LICENSE","size":9341},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/bengali/twb/v0.1.0/alphabet.txt","name":"alphabet.txt","size":298},{"contentType":"text/csv","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/bengali/twb/v0.1.0/corpus_wav-test.csv","name":"corpus_wav-test.csv","size":225921},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/bengali/twb/v0.1.0/model.pbmm","name":"model.pbmm","size":189301920},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/bengali/twb/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":5102},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/bengali/twb/v0.1.0/general-bn.scorer","name":"general-bn.scorer","size":71904512}]}},{"description":"# Czech STT v0.2.0 (Vojtƒõch Dr√°bek)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Vojtƒõch Dr√°bek](https://github.com/comodoro).\r\n- Model language: Czech / ƒçe≈°tina / `cs`\r\n- Model date: July 21, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.2.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: CC-BY-NC\r\n- Citation details: `@techreport{czech-stt, author = {Dr√°bek,Vojtƒõch}, title = {Czech STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {July}, number = {STT-CS-0.2} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [the model release page](https://github.com/comodoro/deepspeech-cs) or [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Czech Language](https://en.wikipedia.org/wiki/Czech_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nMore information reported on [Github](https://github.com/comodoro/deepspeech-cs/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|42.3\\%|11.2\\%|\r\n|Vystadial 2016|50.8\\%|19.6\\%|\r\n|Parliament Plenary Hearings|21.5\\%|5.2\\%|\r\n\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora:\r\n\r\n1. Vystadial 2016 ‚Äì Czech data\r\n2. OVM ‚Äì Ot√°zky V√°clava Moravce\r\n3. Czech Parliament Meetings\r\n4. Large Corpus of Czech Parliament Plenary Hearings\r\n5. Common Voice Czech\r\n6. Some private recordings and parts of audioboooks\r\n\r\n## Evaluation data\r\n\r\nThe model was evaluated on Common Voice Czech, Large Corpus of Czech Parliament Plenary Hearings and Vystadial 2016 ‚Äì Czech data test sets.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in many countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Czech STT v0.2.0","tagName":"czech/comodoro/v0.2.0","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.2.0/o4-500k-wnc-2011.scorer","name":"o4-500k-wnc-2011.scorer","size":539766416},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.2.0/o3-100k-wnc-2011.scorer","name":"o3-100k-wnc-2011.scorer","size":80233440},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.2.0/model.tflite","name":"model.tflite","size":47360928},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.2.0/model.pbmm","name":"model.pbmm","size":189031154},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.2.0/MODEL_CARD","name":"MODEL_CARD","size":4419},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.2.0/alphabet.txt","name":"alphabet.txt","size":99},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.2.0/LICENSE","name":"LICENSE","size":57}]}},{"description":"# English STT yesno-v0.0.1 (Coqui)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Maintained by [Coqui](https://coqui.ai/).\r\n- Model language: English / English / `en`\r\n- Model date: July 26, 2021\r\n- Model type: `Speech-to-Text` / `constrained vocabulary` / `yesno`\r\n- Model version: `v0.0.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: Apache 2.0\r\n- Citation details: `@techreport{english-yesno-stt, author = {Coqui}, title = {English yesno STT v0.0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {July}, number = {STT-EN-YESNO-0.0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text `yesno` model for the [English Language](https://en.wikipedia.org/wiki/English_language) on 16kHz, mono-channel audio. This model has been trained to only recognize the two words \"yes\" and \"no\" in English.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe model was trained and evaluted on the Common Voice Target Segments Corpus, specifically, only on \"yes\" and \"no\" audio clips.\r\n\r\n|Test Corpus|Word Error Rate|\r\n|-------|----------|\r\n|Common Voice 6.1 (Target Segments Corpus \"yes\" and \"no\") | 1.6\\% |\r\n\r\n#### Model Size\r\n\r\n`yesno.pbmm`: 319K\r\n`yesno.scorer`: 1.7K\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThe model was trained and evaluted on the Common Voice Target Segments Corpus, specifically, only on \"yes\" and \"no\" audio clips.\r\n\r\n## Evaluation data\r\n\r\nThe model was trained and evaluted on the Common Voice Target Segments Corpus, specifically, only on \"yes\" and \"no\" audio clips.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"English STT yesno-v0.0.1","tagName":"english/coqui/yesno-v0.0.1","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/yesno-v0.0.1/MODEL_CARD","name":"MODEL_CARD","size":4091},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/yesno-v0.0.1/LICENSE","name":"LICENSE","size":11358},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/yesno-v0.0.1/alphabet.txt","name":"alphabet.txt","size":12},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/yesno-v0.0.1/yesno.pbmm","name":"yesno.pbmm","size":326298},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/yesno-v0.0.1/yesno.scorer","name":"yesno.scorer","size":1664},{"contentType":"application/gzip","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/yesno-v0.0.1/coqui-yesno-checkpoints.tar.gz","name":"coqui-yesno-checkpoints.tar.gz","size":1160502},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/yesno-v0.0.1/yesno.tflite","name":"yesno.tflite","size":371716}]}},{"description":"# Swahili (Congo) STT v0.3.0 (Alp √ñktem)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Training parameters](#training-parameters)\r\n- [Language models](#language-models)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person and organization developing model: [Alp √ñktem](https://alpoktem.github.io/) @[Clear Global/Translators without Borders](https://clearglobal.org/).\r\n- Model language: Swahili (Congo) / `swc` / `sw-cd`\r\n- Model date: August 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.3.0`\r\n- Compatible with üê∏ STT version: `v0.10.0a13`\r\n- License: Custom (`LICENSE.txt`)\r\n- Citation details: `@techreport{swc-stt, author = {\\\"Oktem, Alp}, title = {SWC STT 0.3}, institution = {Translators without Borders}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {June}, number = {STT-SWC-0.3} }`\r\n- Official page: [https://gamayun.translatorswb.org/data/](https://gamayun.translatorswb.org/data/swc-stt-model)\r\n- Where to send questions or comments about the model: Directly to [Alp √ñktem](mailto:alp.oktem@clearglobal.org) or you can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the Congolese dialect of [Swahili Language](https://en.wikipedia.org/wiki/Swahili_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [Congolese Swahili Commands dataset](https://gamayun.translatorswb.org/data/). \r\n\r\n|Test Corpus|Scorer|WER|CER|\r\n|-----------|---|---|---|\r\n|TICO-19 devset|swc-general|18.31\\%|6.15\\%|\r\n|Congolese Swahili Commands|swc-commands|21.08\\%|20.82\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ` `\r\n\r\n#### Model Size\r\n\r\n`swc-stt-0.3.pbmm`: 188.9 Mb\r\n`swc-stt-0.3.tflite`:47.3 Mb\r\n`swc-general.scorer`: 158.6 Mb\r\n`swc-commands.scorer`: 2.9 Kb\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nAcoustic model was trained on top of English STT model using portions of [Congolese Swahili audio mini-kit](https://gamayun.translatorswb.org/download/congolese-swahili-audio-mini-kit/) and [TICO-19 Congolese Swahili testing set](https://gamayun.translatorswb.org/download/congolese-swahili-tico-19-audio-test-set/). It was converted to 16kHz WAV before training. \r\n\r\nTotal train size: 8.93 (mini-kit) + 3.27 (TICO-19 testset) = 12.2 hours\r\nDev size: 0.49 hours (mini-kit)\r\nTest size: 1.71 hours (TICO-19 devset) \r\n\r\n## Training parameters\r\n\r\n|Parameter|Value|\r\n|---------|-----|\r\n|Epochs|200|\r\n|Drop source layers|2|\r\n|Learning rate|0.001|\r\n|Dropout rate|0.2|\r\n|augment frequency_mask|[p=0.8,n=2:4,size=2:4]|\r\n|augment time_mask|[p=0.8,n=2:4,size=10:50,domain=spectrogram] |\r\n|Train/test/dev batch size|32|\r\n\r\n## Language models\r\n\r\nModel is packaged with two language models (scorers):\r\n- *General purpose language model* (`swc-general.scorer`) is trained on a 37.7M word mixed Swahili text corpus\r\n- *Commands language model* (`swc-commands.scorer`) is trained on 12 commands (numbers from 1 to 10 and yes/no) which are listed in `vocab-commands.txt`.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on two different sets: \r\n- [Congolese Swahili audio commands corpus](https://gamayun.translatorswb.org/download/swc-audio-commands/): 185 sample subset (1.8 minutes) consisting of 5 speakers uttering numbers 1 to 10 and yes/no in Congolese Swahili. For this evaluation, the `swc-commands` language model was used.\r\n- [Congolese Swahili TICO-19 audio development set](https://gamayun.translatorswb.org/download/swc-tico-19-audio-devset/): 536 sample subset (1.71 hours) consisting of TICO-19 domain sentences spoken by a male and female speaker (listed in `swc-tico-test.csv`). For this evaluation, the `swc-general` language model was used.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Swahili (Congo) STT v0.3.0","tagName":"swahili-congo/twb/v0.3.0","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili-congo/twb/v0.3.0/MODEL_CARD","name":"MODEL_CARD","size":6267},{"contentType":"text/csv","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili-congo/twb/v0.3.0/swc-tico-test.csv","name":"swc-tico-test.csv","size":66680},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili-congo/twb/v0.3.0/alphabet.txt","name":"alphabet.txt","size":54},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili-congo/twb/v0.3.0/LICENSE.txt","name":"LICENSE.txt","size":9341},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili-congo/twb/v0.3.0/swc-commands.scorer","name":"swc-commands.scorer","size":2944},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili-congo/twb/v0.3.0/vocab-commands.txt","name":"vocab-commands.txt","size":65},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili-congo/twb/v0.3.0/swc-general.scorer","name":"swc-general.scorer","size":158613360},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili-congo/twb/v0.3.0/model.tflite","name":"model.tflite","size":47330064},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili-congo/twb/v0.3.0/model.pbmm","name":"model.pbmm","size":188908121}]}},{"description":"# English STT v1.0.0 (digits)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Maintained by [Coqui](https://coqui.ai/).\r\n- Model language: English / English / `en`\r\n- Model date: October 3, 2021\r\n- Model type: `Small vocabulary Speech-to-Text`\r\n- Model version: `v1.0.0-digits`\r\n- Compatible with üê∏ STT version: `v1.0.0`\r\n- License: Apache 2.0\r\n- Citation details: `@techreport{english-stt, author = {Coqui}, title = {English STT v1.0.0}, institution = {Coqui}, address = {\\url{https://coqui.ai/models}} year = {2021}, month = {October}, number = {STT-EN-1.0.0} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT` issues](https://github.com/coqui-ai/STT/issues), open a new discussion on [`STT` discussions](https://github.com/coqui-ai/STT/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nClosed vocabulary (digits \"zero\" through \"nine\") Speech-to-Text for the [English Language](https://en.wikipedia.org/wiki/English_language) on 16kHz, mono-channel audio. This acoustic model and language model pair will only be able to recognize the words {\"zero\",\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\" and \"nine\"}, which is a common use case in IVR systems.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\n#### Model Size\r\n\r\nFor STT, you always must deploy an acoustic model, and it is often the case you also will want to deploy an application-specific language model. The acoustic model comes in two forms: quantized and unquantized. There is a size<->accuracy trade-off for acoustic model quantization. For this combination of acoustic model and language model, we optimize for small size.\r\n\r\n|Model type|Vocabulary|Filename|Size|\r\n----------------|-----|----------------|-----|\r\n|Acoustic model | open | `model_quantized.tflite` | 46M||\r\n|Language model | small| `digits.scorer` |1.7K| \r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: Common Voice 7.0 English (custom Coqui train/dev/test splits), LibriSpeech, and Multilingual Librispeech. In total approximately ~47,000 hours of data.\r\n\r\n## Evaluation data\r\n\r\nThe validation (\"dev\") sets came from CV, Librispeech, and MLS. Testing accuracy is reported for MLS and Librispeech.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"English STT v1.0.0-digits","tagName":"english/coqui/v1.0.0-digits","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-digits/MODEL_CARD","name":"MODEL_CARD","size":4352},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-digits/model_quantized.tflite","name":"model_quantized.tflite","size":47332120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-digits/LICENSE","name":"LICENSE","size":11358},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-digits/digits.scorer","name":"digits.scorer","size":1648}]}},{"description":"# English STT v1.0.0 (yesno)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Maintained by [Coqui](https://coqui.ai/).\r\n- Model language: English / English / `en`\r\n- Model date: October 3, 2021\r\n- Model type: `Small vocabulary Speech-to-Text`\r\n- Model version: `yesno-v1.0.0`\r\n- Compatible with üê∏ STT version: `v1.0.0`\r\n- License: Apache 2.0\r\n- Citation details: `@techreport{english-stt, author = {Coqui}, title = {English STT v1.0.0}, institution = {Coqui}, address = {\\url{https://coqui.ai/models}} year = {2021}, month = {October}, number = {STT-EN-1.0.0} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT` issues](https://github.com/coqui-ai/STT/issues), open a new discussion on [`STT` discussions](https://github.com/coqui-ai/STT/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nClosed vocabulary (\"yes\" and \"no\") Speech-to-Text for the [English Language](https://en.wikipedia.org/wiki/English_language) on 16kHz, mono-channel audio. This acoustic model and language model pair will only be able to recognize the words \"yes\" and \"no\", which is a common use case in IVR systems.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\n#### Model Size\r\n\r\nFor STT, you always must deploy an acoustic model, and it is often the case you also will want to deploy an application-specific language model. The acoustic model comes in two forms: quantized and unquantized. There is a size<->accuracy trade-off for acoustic model quantization. For this combination of acoustic model and language model, we optimize for small size.\r\n\r\n|Model type|Vocabulary|Filename|Size|\r\n----------------|-----|----------------|-----|\r\n|Acoustic model | open | `model_quantized.tflite` | 46M||\r\n|Language model | small| `yesno.scorer` |640B| \r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: Common Voice 7.0 English (custom Coqui train/dev/test splits), LibriSpeech, and Multilingual Librispeech. In total approximately ~47,000 hours of data.\r\n\r\n## Evaluation data\r\n\r\nThe validation (\"dev\") sets came from CV, Librispeech, and MLS. Testing accuracy is reported for MLS and Librispeech.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"English STT v1.0.0-yesno","tagName":"english/coqui/v1.0.0-yesno","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-yesno/MODEL_CARD","name":"MODEL_CARD","size":4275},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-yesno/model_quantized.tflite","name":"model_quantized.tflite","size":47332120},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-yesno/LICENSE","name":"LICENSE","size":11358},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-yesno/yesno.scorer","name":"yesno.scorer","size":640}]}},{"description":"# English STT v1.0.0 (Large Vocabulary)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Maintained by [Coqui](https://coqui.ai/).\r\n- Model language: English / English / `en`\r\n- Model date: October 3, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v1.0.0`\r\n- Compatible with üê∏ STT version: `v1.0.0`\r\n- License: Apache 2.0\r\n- Citation details: `@techreport{english-stt, author = {Coqui}, title = {English STT v1.0.0}, institution = {Coqui}, address = {\\url{https://coqui.ai/models}} year = {2021}, month = {October}, number = {STT-EN-1.0.0} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT` issues](https://github.com/coqui-ai/STT/issues), open a new discussion on [`STT` discussions](https://github.com/coqui-ai/STT/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [English Language](https://en.wikipedia.org/wiki/English_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nUsing the language model with settings `lm_alpha=0.49506138236732433` and `lm_beta=0.11939819449850608` (found via `lm_optimizer.py` with Common Voice):\r\n\r\n- Librispeech clean: WER: 5.2\\%, CER: 1.9\\%\r\n- Librispeech other: WER: 15.0\\%, CER: 7.3\\%\r\n\r\n#### Model Size\r\n\r\nFor STT, you always must deploy an acoustic model, and it is often the case you also will want to deploy an application-specific language model.\r\n\r\n|Model type|Vocabulary|Filename|Size|\r\n----------------|-----|----------------|-----|\r\n|Acoustic model | open | `model.tflite` | 181M|\r\n|Language model | large  | `large_vocabulary.scorer` |127M|\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: Common Voice 7.0 English (custom Coqui train/dev/test splits), LibriSpeech, and Multilingual Librispeech. In total approximately ~47,000 hours of data.\r\n\r\n## Evaluation data\r\n\r\nThe validation (\"dev\") sets came from CV, Librispeech, and MLS.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"English STT v1.0.0-large-vocab","tagName":"english/coqui/v1.0.0-large-vocab","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/MODEL_CARD","name":"MODEL_CARD","size":4244},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/LOG_TESTING","name":"LOG_TESTING","size":25391},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/LICENSE","name":"LICENSE","size":11358},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/large_vocabulary.scorer","name":"large_vocabulary.scorer","size":132644544},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/alphabet.txt","name":"alphabet.txt","size":329},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/model.tflite","name":"model.tflite","size":47332120}]}},{"description":"# English STT v1.0.0 (Huge Vocabulary)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Maintained by [Coqui](https://coqui.ai/).\r\n- Model language: English / English / `en`\r\n- Model date: October 3, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v1.0.0`\r\n- Compatible with üê∏ STT version: `v1.0.0`\r\n- License: Apache 2.0\r\n- Citation details: `@techreport{english-stt, author = {Coqui}, title = {English STT v1.0.0}, institution = {Coqui}, address = {\\url{https://coqui.ai/models}} year = {2021}, month = {October}, number = {STT-EN-1.0.0} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT` issues](https://github.com/coqui-ai/STT/issues), open a new discussion on [`STT` discussions](https://github.com/coqui-ai/STT/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [English Language](https://en.wikipedia.org/wiki/English_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nUsing the `huge-vocabulary.scorer` language model:\r\n\r\n- Librispeech clean: WER: 4.5\\%, CER: 1.6\\%\r\n- Librispeech other: WER: 13.6\\%, CER: 6.4\\%\r\n\r\n#### Model Size\r\n\r\nFor STT, you always must deploy an acoustic model, and it is often the case you also will want to deploy an application-specific language model.\r\n\r\n|Model type|Vocabulary|Filename|Size|\r\n----------------|-----|----------------|-----|\r\n|Acoustic model | open | `model.tflite` | 181M|\r\n|Language model | large  | `huge-vocabulary.scorer` |923M|\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: Common Voice 7.0 English (custom Coqui train/dev/test splits), LibriSpeech, and Multilingual Librispeech. In total approximately ~47,000 hours of data.\r\n\r\n## Evaluation data\r\n\r\nThe validation (\"dev\") sets came from CV, Librispeech, and MLS.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"English STT v1.0.0-huge-vocab","tagName":"english/coqui/v1.0.0-huge-vocab","releaseAssets":{"nodes":[{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-huge-vocab/MODEL_CARD","name":"MODEL_CARD","size":4097},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-huge-vocab/LOG_TESTING","name":"LOG_TESTING","size":21021},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-huge-vocab/huge-vocabulary.scorer","name":"huge-vocabulary.scorer","size":978407904},{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-huge-vocab/alphabet.txt","name":"alphabet.txt","size":329},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-huge-vocab/model.tflite","name":"model.tflite","size":47332120}]}},{"description":"# French STT v0.8 (commonvoice-fr)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained and released by the [commonvoice-fr](https://github.com/common-voice/commonvoice-fr) project, revived by [Waser Technologies](https://github.com/wasertech/commonvoice-fr/tree/coqui-stt)\r\n- Model date: Accessed from [Github](https://github.com/wasertech/commonvoice-fr/releases/tag/v0.8.0-fr-0.3) on February 9, 2022\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.8`\r\n- Compatible with üê∏ STT version: `v1.2.0`\r\n- Code: [commonvoice-fr](https://github.com/wasertech/commonvoice-fr)\r\n- License: MPL 2.0\r\n- Citation details: `@misc{commonvoice-fr,\r\nauthor = {commonvoice-fr Contributors},\r\ntitle = {Common Voice STT Model},\r\npublisher = {Github},\r\njournal = {GitHub repository},\r\nhowpublished = {\\url{https://github.com/wasertech/commonvoice-fr/releases/tag/v0.8.0-fr-0.3}},\r\ncommit = {0a2d028b124691bbee656f43aa02251169dce69b}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [French Language](https://en.wikipedia.org/wiki/French_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Github](https://github.com/wasertech/commonvoice-fr/releases/tag/v0.8.0-fr-0.3).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|African_Accented_French_test.csv|43.6\\%|24.8\\%|\r\n|Att-HACK|12.8\\%|6.0\\%|\r\n|M-AILABS|12.2\\%|3.7\\%|\r\n|trainingspeech|12.1\\%|4.0\\%|\r\n|Common Voice|37.0\\%|19.4\\%|\r\n|LinguaLibre|59.3\\%|21.3\\%|\r\n|MLS|26.8\\%|12.2\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.tflite`: 46M\r\n`kenlm.scorer`: 689M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis French STT model was trained on the following corpora:\r\n\r\n1. Lingua Libre (~40h)\r\n2. Common Voice FR (v8) (~826h, by allowing up to 32 duplicates)\r\n3. Training Speech (~180h)\r\n4. African Accented French (~15h)\r\n5. M-AILABS French (~315h)\r\n6. Multilingual LibriSpeech (~1,100h)\r\n7. Att-HACK (~75h)\r\n\r\nTotal : ~2,551h \r\n(~1,903h by default)\r\n\r\n## Evaluation data\r\n\r\nThe model was tested on the following corpora.\r\n\r\n1. Lingua Libre\r\n2. Common Voice FR (v8)\r\n3. Training Speech\r\n4. African Accented French\r\n5. M-AILABS French\r\n6. Multilingual LibriSpeech\r\n7. Att-HACK\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"French STT v0.8","tagName":"french/commonvoice-fr/v0.8","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.8/alphabet.txt","name":"alphabet.txt","size":328},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.8/kenlm.scorer","name":"kenlm.scorer","size":722370432},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.8/LICENSE","name":"LICENSE","size":16726},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.8/MODEL_CARD","name":"MODEL_CARD","size":4959},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.8/model.tflite","name":"model.tflite","size":47504696}]}},{"description":"# Swahili STT v8.0 (Coqui)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Maintained by [Coqui](https://coqui.ai/).\r\n- Model language: Swahili / kiswahili / `sw`\r\n- Model date: March 8, 2022\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v8.0`\r\n- Compatible with üê∏ STT version: `v1.3.0`\r\n- License: Apache 2.0\r\n- Citation details: `@techreport{swahili-stt, author = {Coqui}, title = {Swahili STT v8.0}, institution = {Coqui}, address = {\\url{https://coqui.ai/models}} year = {2022}, month = {March}, number = {STT-SW-8.0} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT` issues](https://github.com/coqui-ai/STT/issues), open a new discussion on [`STT` discussions](https://github.com/coqui-ai/STT/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Swahili Language](https://en.wikipedia.org/wiki/Swahili_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nUsing the language model with settings `lm_alpha=0.898202045251655` and `lm_beta=2.2684674938753755` (found via `lm_optimizer.py`):\r\n\r\n- Swahili Common Voice 8.0 Test: WER: 15.8\\%, CER: 6.6\\%\r\n\r\n#### Model Size\r\n\r\nFor STT, you always must deploy an acoustic model, and it is often the case you also will want to deploy an application-specific language model.\r\n\r\n|Model type|Vocabulary|Filename|Size|\r\n----------------|-----|----------------|-----|\r\n|Acoustic model | open | `model.tflite` | 45M|\r\n|Language model | large  | `large-vocabulary.scorer` |321M|\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: Common Voice 8.0 Swahili.\r\n\r\n## Evaluation data\r\n\r\nThe validation (\"dev\") sets came from Common Voice 8.0.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Swahili STT v0.8","tagName":"swahili/coqui/v8.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili/coqui/v8.0/alphabet.txt","name":"alphabet.txt","size":334},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili/coqui/v8.0/large-vocabulary.scorer","name":"large-vocabulary.scorer","size":336411664},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili/coqui/v8.0/LICENSE","name":"LICENSE","size":11358},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili/coqui/v8.0/MODEL_CARD","name":"MODEL_CARD","size":4000},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili/coqui/v8.0/model.tflite","name":"model.tflite","size":47332120},{"contentType":"application/x-gzip","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/swahili/coqui/v8.0/swahili-checkpoints-cv8.tar.gz","name":"swahili-checkpoints-cv8.tar.gz","size":648004030}]}},{"description":"# Western Highland Chatino STT\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [B√ºlent √ñzden](https://twitter.com/bulentozden), a member of [Common Voice T√ºrk√ße](https://twitter.com/CVTurkce).\r\n- Model language: Western Highland Chatino / `ctp`\r\n- Model date: 12th April, 2022\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v1.0.0`\r\n- Compatible with  STT version: `v1.3.0`\r\n- License: CC-BY-SA 4.0\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for [Western Highland Chatino](https://en.wikipedia.org/wiki/https://en.wikipedia.org/wiki/Highland_Chatino) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|GORILLA |77.2\\%|30.9\\%|\r\n\r\n#### Model Size\r\n\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on [GORILLA `ctp`](https://gorilla.linguistlist.org/code/ctp/)\r\n\r\n### Citation\r\n\r\n* Malgorzata E. Cavar, Damir Cavar, Hilaria Cruz (2016) \"Endangered Language Documentation: Bootstrapping a Chatino Speech Corpus, Forced Aligner, ASR\". Pages 4004-4011 Of N. Calzolari (et al. eds) *Proceedings of the Tenth International Conference on Language Resources and Evaluation* (LREC 2016) in Portoro≈æ, Slovenia, European Language Resources Association (ELRA), Paris, France. \r\n\r\n## Evaluation data\r\n\r\nThis model was evaluated on [GORILLA `ctp`](https://gorilla.linguistlist.org/code/ctp/)\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyse private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":" Western Highland Chatino STT","tagName":"chatino/bozden/v1.0.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chatino/bozden/v1.0.0/alphabet.txt","name":"alphabet.txt","size":351},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chatino/bozden/v1.0.0/model.tflite","name":"model.tflite","size":47346520},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chatino/bozden/v1.0.0/LICENSE","name":"LICENSE","size":48},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/chatino/bozden/v1.0.0/MODEL_CARD","name":"MODEL_CARD","size":3973}]}},{"description":"# Sierra Totonac STT\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [B√ºlent √ñzden](https://twitter.com/bulentozden), a member of [Common Voice T√ºrk√ße](https://twitter.com/CVTurkce).\r\n- Model language: Totonac / Sierra Totonac / `tos`\r\n- Model date: April 12, 2022\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v1.0.0`\r\n- Compatible with üê∏ STT version: `v1.3.0`\r\n- License: CC BY-NC-SA 3.0\r\n- Citation details: `@techreport{totonac-stt, author = {B√ºlent √ñzden}, title = {Totonac STT 1.0}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2022}, month = {April}, number = {STT-TOS-1.0} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Sierra Totonac Language](https://en.wikipedia.org/wiki/Sierra_Totonac_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|OpenSLR 107|87.5\\%|25.8\\%|\r\n\r\n#### Model Size\r\n\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on [Totonac Speech with transcription](http://openslr.org/107/) corpus. \r\n\r\n## Evaluation data\r\n\r\nThis model was evaluated on [Totonac Speech with transcription](http://openslr.org/107/) corpus. \r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Sierra Totonac STT","tagName":"totonac/bozden/v1.0.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/totonac/bozden/v1.0.0/alphabet.txt","name":"alphabet.txt","size":353},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/totonac/bozden/v1.0.0/LICENSE","name":"LICENSE","size":51},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/totonac/bozden/v1.0.0/model.tflite","name":"model.tflite","size":47344472},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/totonac/bozden/v1.0.0/MODEL_CARD","name":"MODEL_CARD","size":3807}]}},{"description":"# Yolox√≥chitl Mixtec STT\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Joe Meyer](https://www.linkedin.com/in/joe-meyer-25753951/).\r\n- Model language: Yolox√≥chitl Mixtec / / `xty`\r\n- Model date: April 17, 2022\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v1.0.0`\r\n- License: CC BY-NC-SA 3.0 \r\n- Citation details: `@techreport{xty-stt, author = {Meyer,Joe}, title = {Yolox√≥chitl Mixtec STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2022}, month = {April}, number = {STT-SLR89-XTY-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Yolox√≥chitl Mixtec Language](https://en.wikipedia.org/wiki/Yolox%C3%B3chitl_Mixtec) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported for a modified data set from OpenSLR [SLR89](https://www.openslr.org/89/). The official `validated.tsv` had rows removed which had errors processing, and the data was re-processed by [Cmmon Voice Utils](https://github.com/ftyers/commonvoice-utils) to convert to 16kHz mono-channel PCM .wav files.\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|OpenSLR|48.85\\%|18.04\\%|\r\n\r\n#### Model Size\r\n\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on a modified data set from OpenSLR [SLR89](https://www.openslr.org/89/). The official `validated.tsv` had rows removed which had errors processing, and the data was re-processed by [Cmmon Voice Utils](https://github.com/ftyers/commonvoice-utils) to convert to 16kHz mono-channel PCM .wav files.\r\n\r\n## Evaluation data\r\n\r\nThis model was evaluated on a modified data set from OpenSLR [SLR89](https://www.openslr.org/89/). The official `validated.tsv` had rows removed which had errors processing, and the data was re-processed by [Cmmon Voice Utils](https://github.com/ftyers/commonvoice-utils) to convert to 16kHz mono-channel PCM .wav files.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Yolox√≥chitl Mixtec STT","tagName":"mixtec/jemeyer/v1.0.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mixtec/jemeyer/v1.0.0/alphabet.txt","name":"alphabet.txt","size":359},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mixtec/jemeyer/v1.0.0/LICENSE","name":"LICENSE","size":50},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mixtec/jemeyer/v1.0.0/MODEL_CARD","name":"MODEL_CARD","size":4849},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/mixtec/jemeyer/v1.0.0/model.tflite","name":"model.tflite","size":47348584}]}},{"description":"# French STT v0.9\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained and released by the [commonvoice-fr](https://github.com/common-voice/commonvoice-fr) project, revived by [Waser Technologies](https://github.com/wasertech/commonvoice-fr/tree/v0.9.0-fr-0.1)\r\n- Model date: Accessed from [Github](https://github.com/wasertech/commonvoice-fr/releases/tag/v0.9.0-fr-0.1) on Jun 10, 2022\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.9`\r\n- Compatible with üê∏ STT version: `v1.4.0`\r\n- Code: [commonvoice-fr](https://github.com/wasertech/commonvoice-fr/tree/v0.9.0-fr-0.1)\r\n- License: MPL 2.0\r\n- Citation details: `@misc{commonvoice-fr,\r\nauthor = {commonvoice-fr Contributors},\r\ntitle = {Common Voice Fr STT Model},\r\npublisher = {Github},\r\njournal = {GitHub repository},\r\nhowpublished = {\\url{https://github.com/wasertech/commonvoice-fr/releases/tag/v0.9.0-fr-0.1}},\r\ncommit = {0a2d028b124691bbee656f43aa02251169dce69b}\r\n}`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [French Language](https://en.wikipedia.org/wiki/French_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates (WER) are reported on [Github](https://github.com/wasertech/commonvoice-fr/releases/tag/v0.9.0-fr-0.1).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|African_Accented_French_test.csv|47.7\\%|6.6\\%|\r\n|Att-HACK|12.9\\%|7.1\\%|\r\n|M-AILABS|9.9\\%|3.3\\%|\r\n|trainingspeech|10.9\\%|4.1\\%|\r\n|Common Voice|31.5\\%|15.2\\%|\r\n|LinguaLibre|67.6\\%|21.6\\%|\r\n|MLS|22.6\\%|9.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `~0.3`\r\n\r\n#### Model Size\r\n\r\n`model.tflite`: 46M\r\n`kenlm.scorer`: 689M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis French STT model was trained on the following corpora:\r\n\r\n1. Lingua Libre (~40h)\r\n2. Common Voice FR (v8) (~850h, by allowing up to 32 duplicates)\r\n3. Training Speech (~180h)\r\n4. African Accented French (~15h)\r\n5. M-AILABS French (~315h)\r\n6. Multilingual LibriSpeech (~1,100h)\r\n7. Att-HACK (~75h)\r\n\r\nTotal : ~2,573h \r\n(~1,925h by default)\r\n\r\n## Evaluation data\r\n\r\nThe model was tested on the following corpora.\r\n\r\n1. Lingua Libre\r\n2. Common Voice FR (v9)\r\n3. Training Speech\r\n4. African Accented French\r\n5. M-AILABS French\r\n6. Multilingual LibriSpeech\r\n7. Att-HACK\r\n\r\nData was augmented with the following parameters.\r\n\r\n```\r\nParsed augmentations: [\r\n    Reverb(p=0.1, delay=ValueRange(start=50.0, end=50.0, r=30.0), decay=ValueRange(start=10.0, end=2.0, r=1.0)),\r\n    Resample(p=0.1, rate=ValueRange(start=12000, end=8000, r=4000)),\r\n    Codec(p=0.1, bitrate=ValueRange(start=48000, end=16000, r=0)),\r\n    Volume(p=0.1, dbfs=ValueRange(start=-10.0, end=-40.0, r=0.0)),\r\n    Pitch(p=0.1, pitch=ValueRange(start=1.0, end=1.0, r=0.2)),\r\n    Tempo(p=0.1, factor=ValueRange(start=1.0, end=1.0, r=0.5), max_time=-1.0), \r\n    FrequencyMask(p=0.1, n=ValueRange(start=1, end=3, r=0), size=ValueRange(start=1, end=5, r=0)), \r\n    TimeMask(p=0.1, domain='signal', n=ValueRange(start=3, end=10, r=2), size=ValueRange(start=50.0, end=100.0, r=40.0)),\r\n    Dropout(p=0.1, domain='spectrogram', rate=ValueRange(start=0.05, end=0.05, r=0.0)),\r\n    Add(p=0.1, domain='signal', stddev=ValueRange(start=0.0, end=0.0, r=0.5)),\r\n    Multiply(p=0.1, domain='features', stddev=ValueRange(start=0.0, end=0.0, r=0.5))\r\n]\r\n```\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"French STT v0.9","tagName":"french/commonvoice-fr/v0.9","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.9/alphabet.txt","name":"alphabet.txt","size":578},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.9/kenlm.scorer","name":"kenlm.scorer","size":722261584},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.9/LICENSE","name":"LICENSE","size":16726},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.9/MODEL_CARD","name":"MODEL_CARD","size":6001},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/french/commonvoice-fr/v0.9/model.tflite","name":"model.tflite","size":47486160}]}},{"description":"# Persian STT v0.1.0\r\n\r\nJump to section:\r\n\r\n- [Model card for Persian STT v0.1.0](#model-card-for-persian-stt-v010)\r\n  - [Model details](#model-details)\r\n  - [Intended use](#intended-use)\r\n  - [Performance Factors](#performance-factors)\r\n  - [Metrics](#metrics)\r\n    - [Transcription Accuracy](#transcription-accuracy)\r\n    - [Real-Time Factor](#real-time-factor)\r\n    - [Model Size](#model-size)\r\n    - [Approaches to uncertainty and variability](#approaches-to-uncertainty-and-variability)\r\n  - [Training data](#training-data)\r\n  - [Evaluation data](#evaluation-data)\r\n  - [Ethical considerations](#ethical-considerations)\r\n    - [Demographic Bias](#demographic-bias)\r\n    - [Surveillance](#surveillance)\r\n  - [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Maintained by [oct4pie](https://github.com/Oct4Pie).\r\n- Model language: Persian / Farsi / `fa`, `fa-IR`\r\n- Model date: June 21, 2022\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.0`\r\n- Compatible with üê∏ STT version: `v1.3.0`\r\n- License: GNU Lesser General Public License v3.0\r\n- Citation details: `@techreport{persian-stt, author = {Mehdi Hajmollaahmad Naraghi}, title = {Persian STT v0.1.0}, institution = {Coqui}, address = {\\url{https://coqui.ai/models}} year = {2022}, month = {June}, number = {STT-FA-0.1.0} }`\r\n- [persian-tts](https://github.com/Oct4Pie/persian-stt) GitHub Repo\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT` issues](https://github.com/coqui-ai/STT/issues), open a new discussion on [`STT` discussions](https://github.com/coqui-ai/STT/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Persian Language](https://en.wikipedia.org/wiki/Persian_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n### Transcription Accuracy\r\n\r\nUsing the language model with settings `lm_alpha=0.36669178512950323` and `lm_beta=0.3457913671678824` (found via `lm_optimizer.py`):\r\n\r\n- Common-Voice clean: WER: 10.81\\%, CER: 2.506\\%\r\n- More about the model at [persian-tts repo](https://github.com/Oct4Pie/persian-stt)\r\n\r\n### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `proccesing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `.65`\r\n\r\n\r\n### Model Size\r\n\r\nFor STT, you always must deploy an acoustic model, and it is often the case you also will want to deploy an application-specific language model.\r\n\r\n| Model type              | Filename               | Size   |\r\n| ----------------------- | ---------------------- | ------ |\r\n| Acoustic model (tflite) | `model.tflite`   | 45.3M  |\r\n| Language model          | `kenlm.scorer` | 1.63GB |\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: Common Voice 9.0 Persian (cleaned and with custom train/dev/test splits). In total approximately ~271 hours of data.\r\n\r\n## Evaluation data\r\n\r\nThe validation (\"dev\") sets were cleaned and generated from Common Voice 9.0 Persian.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Persian STT v0.1.0","tagName":"persian/oct4pie/v0.1.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/persian/oct4pie/v0.1.0/alphabet.txt","name":"alphabet.txt","size":570},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/persian/oct4pie/v0.1.0/kenlm.scorer","name":"kenlm.scorer","size":1753625792},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/persian/oct4pie/v0.1.0/LICENSE","name":"LICENSE","size":7651},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/persian/oct4pie/v0.1.0/MODEL_CARD","name":"MODEL_CARD","size":5172},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/persian/oct4pie/v0.1.0/model.tflite","name":"model.tflite","size":47455328}]}},{"description":"# Czech STT v0.3.0\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Trained by [Vojtƒõch Dr√°bek](https://www.draabek.cz).\r\n- Model language: Czech / ƒçe≈°tina / `cs`\r\n- Model date: May 31, 2022\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.3.0`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: CC-BY-NC 4.0\r\n- Citation details: `@misc{czech-stt, author = {Dr√°bek, Vojtƒõch}, title = {Czech STT 0.3}, publisher = {comodoro}, journal = {deepspeech-cs}, howpublished =  {\\url{https://github.com/comodoro/deepspeech-cs}} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [the model release page](https://github.com/comodoro/deepspeech-cs) or [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/) or Matrix channel coqui-ai/STT.\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Czech Language](https://en.wikipedia.org/wiki/Czech_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment, Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nMore information reported on [Github](https://github.com/comodoro/deepspeech-cs/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Acoustic model|\r\n|Czech Common voice 6.1|40.6%|10.7%|\r\n|Vystadial 2016|50.6%|19.6%|\r\n|Parliament Plenary Hearings|21.3%|5.3%|\r\n|ParCzech 3.0|21%|6.2%|\r\n||\r\n|With the attached scorer|\r\n|Czech Common voice 6.1|15.3%|6.8%|\r\n|Vystadial 2016|35.7%|20.1%|\r\n|Parliament Plenary Hearings|9.7%|3.7%|\r\n|ParCzech 3.0|10.1%|4.5%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: `0.73`\r\n\r\n#### Model Size\r\n\r\n`model.tflite`: 46M\r\n`scorer`: 461M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora:\r\n\r\n1. Vystadial 2016 ‚Äì Czech data\r\n2. OVM ‚Äì Ot√°zky V√°clava Moravce\r\n3. Czech Parliament Meetings\r\n4. Large Corpus of Czech Parliament Plenary Hearings\r\n5. Common Voice Czech\r\n6. Some private recordings and parts of audiobooks\r\n\r\n## Evaluation data\r\n\r\nThe model was evaluated on Common Voice Czech, Large Corpus of Czech Parliament Plenary Hearings, Vystadial 2016 ‚Äì Czech data and ParCzech 3.0 test sets.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in many countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Czech STT v0.3.0","tagName":"czech/comodoro/v0.3.0","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.3.0/alphabet.txt","name":"alphabet.txt","size":99},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.3.0/kenlm.scorer","name":"kenlm.scorer","size":484210096},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.3.0/LICENSE","name":"LICENSE","size":57},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.3.0/MODEL_CARD","name":"MODEL_CARD","size":4655},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/czech/comodoro/v0.3.0/model.tflite","name":"model.tflite","size":47360928}]}},{"description":"# Hindi STT v0.8.99\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Trained and released by [B√ºlent √ñzden](https://www.linkedin.com/in/b√ºlent-√∂zden-53869019/) a member of [Common Voice T√ºrk√ße](https://twitter.com/CVTurkce) for the [3D Voice Chess](https://github.com/HarikalarKutusu/3d-voice-chess) project by [Harikalar Kutusu](https://github.com/HarikalarKutusu).\r\n- Model language: Hindi / ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä / `hi`\r\n- Model date: March 13, 2022\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.8.99`\r\n- Compatible with üê∏ STT version: `v1.0.0`\r\n- License: CC-BY-SA 4.0\r\n- Citation details: `@misc{hindi-stt, author = {B√ºlent √ñzden}, title = {Hindi STT v0.8.99}, institution = {Harikalar Kutusu}, address = {\\url{https://coqui.ai/models}} year = {2022}, month = {March}, number = {STT-HI-0.8.99} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT` issues](https://github.com/coqui-ai/STT/issues), open a new discussion on [`STT` discussions](https://github.com/coqui-ai/STT/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Hindi Language](https://en.wikipedia.org/wiki/Hindi) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThis model only includes acoustic model, as it is developed for the special purpose low-vocabulary application. The following is the results from the Acoustic Model training.\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|82.2\\%|34.6\\%|\r\n\r\n#### Model Size\r\n\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on the following corpora: [Common Voice](https://commonvoice.mozilla.org/en/datasets) Corpus 8.0 for Hindi. Custom train/dev/test splits are created by [Common Voice Corpora Creator](https://github.com/common-voice/CorporaCreator) with --duplicate-sentence-count 99 parameter, which allowed us to use the whole dataset. The dataset contains approximately ~11 hours of voice data (276 distinct voices, 65% male, 4% female).\r\n\r\nNote: Our model numbering for Common Voice only data reflect Common Voice corpus version and Corpora Creator duplicate-sentence-count (dsc) setting (e.g. \"v0.corpus.dsc\").\r\n\r\n## Evaluation data\r\n\r\nThe validation (\"dev\") and test (\"test\") sets also came from CV as specified above.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.","name":"Hindi STT v0.8.99","tagName":"hindi/bozden/v0.8.99","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hindi/bozden/v0.8.99/alphabet.txt","name":"alphabet.txt","size":560},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hindi/bozden/v0.8.99/LICENSE","name":"LICENSE","size":50},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hindi/bozden/v0.8.99/MODEL_CARD","name":"MODEL_CARD","size":4594},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/hindi/bozden/v0.8.99/model.tflite","name":"model.tflite","size":47420384}]}}]}}}}]}},"pageContext":{"description":"# Portuguese STT v0.1.1 (ITML)\r\n\r\nJump to section:\r\n\r\n- [Model details](#model-details)\r\n- [Intended use](#intended-use)\r\n- [Performance Factors](#performance-factors)\r\n- [Metrics](#metrics)\r\n- [Training data](#training-data)\r\n- [Evaluation data](#evaluation-data)\r\n- [Ethical considerations](#ethical-considerations)\r\n- [Caveats and recommendations](#caveats-and-recommendations)\r\n\r\n## Model details\r\n\r\n- Person or organization developing model: Originally trained by [Francis Tyers](https://scholar.google.fr/citations?user=o5HSM6cAAAAJ) and the [Inclusive Technology for Marginalised Languages](https://itml.cl.indiana.edu/) group.\r\n- Model language: Portuguese / Portugu√™s / `pt`\r\n- Model date: April 26, 2021\r\n- Model type: `Speech-to-Text`\r\n- Model version: `v0.1.1`\r\n- Compatible with üê∏ STT version: `v0.9.3`\r\n- License: AGPL\r\n- Citation details: `@techreport{portuguese-stt, author = {Tyers,Francis}, title = {Portuguese STT 0.1}, institution = {Coqui}, address = {\\url{https://github.com/coqui-ai/STT-models}} year = {2021}, month = {April}, number = {STT-CV6.1-PT-0.1} }`\r\n- Where to send questions or comments about the model: You can leave an issue on [`STT-model` issues](https://github.com/coqui-ai/STT-models/issues), open a new discussion on [`STT-model` discussions](https://github.com/coqui-ai/STT-models/discussions), or chat with us on [Gitter](https://gitter.im/coqui-ai/).\r\n\r\n## Intended use\r\n\r\nSpeech-to-Text for the [Portuguese Language](https://en.wikipedia.org/wiki/Portuguese_language) on 16kHz, mono-channel audio.\r\n\r\n## Performance Factors\r\n\r\nFactors relevant to Speech-to-Text performance include but are not limited to speaker demographics, recording quality, and background noise. Read more about STT performance factors [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data).\r\n\r\n## Metrics\r\n\r\nSTT models are usually evaluated in terms of their transcription accuracy, deployment Real-Time Factor, and model size on disk.\r\n\r\n#### Transcription Accuracy\r\n\r\nThe following Word Error Rates and Character Error Rates are reported on [omnilingo](https://tepozcatl.omnilingo.cc/pt/).\r\n\r\n|Test Corpus|WER|CER|\r\n|-----------|---|---|\r\n|Common Voice|73.2\\%|26.7\\%|\r\n\r\n#### Real-Time Factor\r\n\r\nReal-Time Factor (RTF) is defined as `processing-time / length-of-audio`. The exact real-time factor of an STT model will depend on the hardware setup, so you may experience a different RTF.\r\n\r\nRecorded average RTF on laptop CPU: ``\r\n\r\n#### Model Size\r\n\r\n`model.pbmm`: 181M\r\n`model.tflite`: 46M\r\n\r\n### Approaches to uncertainty and variability\r\n\r\nConfidence scores and multiple paths from the decoding beam can be used to measure model uncertainty and provide multiple, variable transcripts for any processed audio.\r\n\r\n## Training data\r\n\r\nThis model was trained on Common Voice 6.1 train.\r\n\r\n## Evaluation data\r\n\r\nThe Model was evaluated on Common Voice 6.1 test.\r\n\r\n## Ethical considerations\r\n\r\nDeploying a Speech-to-Text model into any production setting has ethical implications. You should consider these implications before use.\r\n\r\n### Demographic Bias\r\n\r\nYou should assume every machine learning model has demographic bias unless proven otherwise. For STT models, it is often the case that transcription accuracy is better for men than it is for women. If you are using this model in production, you should acknowledge this as a potential issue.\r\n\r\n### Surveillance\r\n\r\nSpeech-to-Text may be mis-used to invade the privacy of others by recording and mining information from private conversations. This kind of individual privacy is protected by law in may countries. You should not assume consent to record and analyze private speech.\r\n\r\n## Caveats and recommendations\r\n\r\nMachine learning models (like this STT model) perform best on data that is similar to the data on which they were trained. Read about what to expect from an STT model with regard to your data [here](https://stt.readthedocs.io/en/latest/DEPLOYMENT.html#how-will-a-model-perform-on-my-data). \r\n\r\nIn most applications, it is recommended that you [train your own language model](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html) to improve transcription accuracy on your speech data.\r\n","name":"Portuguese STT v0.1.1","tagName":"portuguese/itml/v0.1.1","releaseAssets":{"nodes":[{"contentType":"text/plain","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/alphabet.txt","name":"alphabet.txt","size":97},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/LICENSE","name":"LICENSE","size":34523},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/model.pbmm","name":"model.pbmm","size":189031152},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/model.tflite","name":"model.tflite","size":47360928},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/MODEL_CARD","name":"MODEL_CARD","size":4144},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/pt-itml-0-prune-kenlm.scorer","name":"pt-itml-0-prune-kenlm.scorer","size":242241040},{"contentType":"application/octet-stream","downloadUrl":"https://github.com/coqui-ai/STT-models/releases/download/portuguese/itml/v0.1.1/scorer.LICENSE","name":"scorer.LICENSE","size":543}]},"slug":"portuguese/itml/v0.1.1"}},"staticQueryHashes":["1942088059","3709355695","932324783"]}